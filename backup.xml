<?xml version="1.0" encoding="ISO-8859-1"?>
<!-- $Header: /var/lib/cvs/pgsql-fr/sgml/backup.sgml,v 1.17 2005/09/15 07:03:14 guillaume Exp $ -->
<chapter id="backup">
 <title>Sauvegardes et restaurations</title>

 <indexterm zone="backup"><primary>backup</primary></indexterm>

 <para>
  Comme tout ce qui contient des données importantes, les bases de données
  <productname>PostgreSQL</productname> doivent être sauvegardées régulièrement.
  Bien que la procédure soit assez simple, il est important de comprendre les
  techniques et hypothèses sous-jacentes.
 </para>

 <para>
  Il y a trois approches fondamentalement différentes pour sauvegarder les 
  données de <productname>PostgreSQL</productname>&nbsp;:
  <itemizedlist>
   <listitem><para><acronym>La sauvegarde SQL&nbsp;;</acronym></para></listitem>
   <listitem><para>La sauvegarde au niveau du système de
    fichiers&nbsp;;</para></listitem>
   <listitem><para>L'archivage continue.</para></listitem>
  </itemizedlist>
  Chacune a ses avantages et inconvénients.
 </para>

 <sect1 id="backup-dump">
  <title>Sauvegarde <acronym>SQL</acronym></title>

  <para>
   Le principe est d'engendrer un fichier texte de commandes SQL (appelé 
   <quote>fichier dump</quote>), qui, si on le renvoie au serveur, recrée une
   base de données identique à celle sauvegardée.
   <productname>PostgreSQL</productname> propose pour cela le programme utilitaire
   <xref linkend="app-pgdump"/>. L'usage basique est&nbsp;:
<synopsis>pg_dump <replaceable class="parameter">base_de_donnees</replaceable> &gt; <replaceable class="parameter">fichier_de_sortie</replaceable></synopsis>
   <application>pg_dump</application> écrit son résultat sur la
   sortie standard. Son utilité est expliqué plus loin.
  </para>

  <para>
   <application>pg_dump</application> est un programme client <productname>PostgreSQL</productname>
   classique (mais plutôt intelligent). Ceci signifie que la 
   sauvegarde peut être effectuée depuis n'importe quel ordinateur ayant accès à la base.
   Mais <application>pg_dump</application> n'a pas de droits spéciaux.
   Il doit, en particulier, avoir accès en lecture à toutes les tables 
   à sauvegarder, si bien qu'il doit être lancé pratiquement
   toujours en tant que super-utilisateur de la base.
  </para>

  <para>
   Pour préciser quel serveur de bases de données <application>pg_dump</application> doit
   contacter, on utilise les options de ligne de commande <option>-h
   <replaceable>serveur</replaceable></option> et <option>-p <replaceable>port</replaceable></option>.
   Le serveur par défaut est le serveur local, ou bien celui spécifié par la 
   variable d'environnement <envar>PGHOST</envar>.
   De la même façon, le port par défaut est indiqué par la variable d'environnement
   <envar>PGPORT</envar> ou, en son absence, par la valeur par défaut précisée 
   à la compilation. Le serveur a normalement la même valeur par
   défaut à la compilation.
  </para>

  <para>
   Comme tout programme client <productname>PostgreSQL</productname>, <application>pg_dump</application>
   se connecte par défaut avec l'utilisateur de base de données de même nom que 
   l'utilisateur système courant. Pour passer outre, on utilise l'option 
   <option>-U</option> ou on donne une valeur à la variable d'environnement
   <envar>PGUSER</envar>. Les connexions de
   <application>pg_dump</application> sont soumises aux mécanismes normaux
   d'authentification des programmes clients (qui sont décrits dans le <xref
   linkend="client-authentication"/>).
  </para>

  <para>
   Les sauvegardes créées par <application>pg_dump</application> sont cohérentes, ce
   qui veut dire que les modifications effectuées alors que <application>pg_dump</application>
   est en cours de fonctionnement ne sont pas reprises dans le fichier de résultat.
   <application>pg_dump</application> ne bloque pas les autres opérations sur la base 
   lorsqu'il fonctionne (sauf celles qui nécessitent un verrou exclusif, comme 
   <command>VACUUM FULL</command>.)
  </para>

  <important>
   <para>
    Si la base de données repose sur les OID (par exemple en tant que clés 
    étrangères), il est impératif d'indiquer à
    <application>pg_dump</application> de sauvegarder
    aussi les OID. Pour cela, on utilise l'option <option>-o</option> sur la ligne
    de commande.
   </para>
  </important>

  <sect2 id="backup-dump-restore">
   <title>Restaurer la sauvegarde</title>

   <para>
    Les fichiers texte créés par <application>pg_dump</application> sont prévus pour être 
    lus par le programme <application>psql</application>. La syntaxe générale 
    d'une commande de restauration est
<synopsis>psql <replaceable class="parameter">base_de_donnees</replaceable> &lt; <replaceable class="parameter">fichier_d_entree</replaceable></synopsis>
    où <replaceable class="parameter">fichier_d_entree</replaceable> est
    celui précisé comme <replaceable class="parameter">fichier_de_sortie</replaceable>
    à la commande <application>pg_dump</application>. La base de données 
    <replaceable class="parameter">base_de_donnees</replaceable> n'est pas créée par cette 
    commande. Elle doit être créée à partir de <literal>template0</literal>
    avant d'exécuter <application>psql</application> (par exemple avec <literal>createdb -T
    template0 <replaceable class="parameter">base_de_donnees</replaceable></literal>).
    <application>psql</application> propose des options similaires à celles de
    <application>pg_dump</application> pour indiquer le serveur de bases de
    données sur lequel se connecter et le nom d'utilisateur à utiliser. La
    page de référence de <xref linkend="app-psql"/> donne plus d'informations.
    </para>

   <para>
    Tous les utilisateurs possédant des
    objets ou ayant certains droits sur les objets de la base sauvegardée
    doivent exister préalablement à la restauration de la sauvegarde. S'ils
    n'existent pas, la
    restauration échoue pour la création des objets dont ils sont
    propriétaires ou sur lesquels ils ont des droits (quelque fois, cela
    est souhaitable mais ce n'est pas le cas habituellement).
   </para>

   <para>
    Par défaut, le script <application>psql</application> continue de
    s'exécuter après la détection d'une erreur SQL. La commande suivante
    peut être placée au début du script pour modifier ce comportement.
    <application>psql</application> quitte alors avec un
    code d'erreur 3 si une erreur SQL survient&nbsp;:
<programlisting>\set ON_ERROR_STOP
</programlisting>
    Dans tous les cas, une sauvegarde partiellement restaurée est obtenue.
    Si cela n'est pas souhaitable, il est possible d'indiquer que la sauvegarde
    complète doit être
    restaurée au cours d'une transaction unique, pour que la restauration soit
    complètement terminée ou complètement annulée. Ce mode est choisi
    en passant l'option <option>-1</option> ou <option>--single-transaction</option>
    en ligne de commande à <application>psql</application>. Dans ce mode, 
    la plus petite erreur peut annuler une restauration en cours depuis
    plusieurs heures. Néanmoins, c'est probablement
    préférable au nettoyage manuel d'une base rendue complexe par une
    sauvegarde partiellement restaurée.
   </para>

   <para>
    La capacité de <application>pg_dump</application> et
    <application>psql</application> à écrire
    et à lire dans des tubes permet de sauvegarder une base de données 
    directement d'un serveur sur un autre. Par exemple&nbsp;:
<programlisting>pg_dump -h <replaceable>serveur1</replaceable> <replaceable>base_de_donnees</replaceable> | psql -h <replaceable>serveur2</replaceable> <replaceable>base_de_donnees</replaceable></programlisting>
   </para>

   <important>
    <para>
     Les fichiers de sauvegarde produits par <application>pg_dump</application> sont
     relatifs à <literal>template0</literal>. Cela signifie que chaque langage,
     procédure, etc. ajoutés à <literal>template1</literal> seront aussi sauvegardés
     par <application>pg_dump</application>. En conséquence, si une base
     <literal>template1</literal> modifiée est utilisée, il faut créer la base
     vide à partir de
     <literal>template0</literal>, comme dans l'exemple précédent.
    </para>
   </important>

   <para>
    Après la restauration d'une sauvegarde, il est conseillé d'exécuter <xref
    linkend="sql-analyze" endterm="sql-analyze-title"/> sur chaque base de
    données pour que l'optimiseur de requêtes dispose de statistiques utiles.
    Un moyen simple de le faire est d'exécuter <command>vacuumdb -a -z</command>&nbsp;;
    c'est équivalent à exécuter <command>VACUUM ANALYZE</command> sur chaque
    base manuellement.
    Pour plus de conseils sur le chargement efficace de grosses quantités de
    données dans <productname>PostgreSQL</productname>, on peut se référer à la
    <xref linkend="populate"/>.
   </para>
   
  </sect2>

  <sect2 id="backup-dump-all">
   <title>Utilisation de <application>pg_dumpall</application></title>

   <para>
    Le mécanisme précédent est peu pratique pour sauvegarder un serveur de bases
    de données complet. <xref linkend="app-pg-dumpall"/> est prévu pour cela.
    <application>pg_dumpall</application> sauvegarde toutes les bases de données d'un
    groupe de bases de données <productname>PostgreSQL</productname> (appelé cluster) et
    préserve les données communes au cluster, comme les utilisateurs et
    les groupes. L'utilisation basique de cette commande est&nbsp;:
<synopsis>pg_dumpall &gt; <replaceable>fichier_de_sortie</replaceable></synopsis>
    Le fichier de sauvegarde résultant peut être restauré avec
    <application>psql</application>&nbsp;:
<synopsis>psql -f <replaceable class="parameter">fichier_d_entree</replaceable> postgres</synopsis>
    (N'importe quelle base de données peut être utiliser pour la connexion 
    mais si le rechargement est exécuté sur un cluster vide, il est
    préférable d'utiliser <literal>postgres</literal>.)
    Il faut obligatoirement avoir un profil superutilisateur pour restaurer
    une sauvegarde faite avec <application>pg_dumpall</application>, afin de
    pouvoir restaurer les informations sur les utilisateurs et les groupes.
   </para>
  </sect2>

  <sect2 id="backup-dump-large">
   <title>Gérer les grosses bases de données</title>

   <para>
    Comme <productname>PostgreSQL</productname> autorise des tables plus
    volumineuses que la taille maximale d'un fichier sur le système de fichiers,
    sauvegarder une telle table en fichier peut poser des problèmes. 
    Puisque <application>pg_dump</application> peut écrire sur la sortie
    standard, les outils standard d'Unix peuvent être utiliser pour contourner
    ce problème éventuel.
   </para>

   <formalpara>
    <title>Compresser le fichier de sauvegarde</title>
    <para>
     Tout programme de compression habituel est utilisable. Par exemple
     <application>gzip</application>.

<programlisting>pg_dump <replaceable class="parameter">base_de_donnees</replaceable> | gzip &gt; <replaceable class="parameter">nom_fichier</replaceable>.gz</programlisting>

     Pour restaurer&nbsp;:

<programlisting>createdb <replaceable class="parameter">base_de_donnees</replaceable>
gunzip -c <replaceable class="parameter">nom_fichier</replaceable>.gz | psql <replaceable class="parameter">base_de_donnees</replaceable></programlisting>

     ou

<programlisting>cat <replaceable class="parameter">nom_fichier</replaceable>.gz | gunzip | psql <replaceable class="parameter">base_de_donnees</replaceable></programlisting>
    </para>
   </formalpara>

   <formalpara>
    <title>Couper le fichier avec <command>split</command></title>
    <para>
     La commande <command>split</command> permet de découper le fichier en
     morceaux de taille acceptable par le système de fichiers sous-jacent.
     Par exemple, pour faire des morceaux de 1&nbsp;Mo&nbsp;:
 
<programlisting>pg_dump <replaceable class="parameter">base_de_donnees</replaceable> | split -b 1m - <replaceable class="parameter">nom_fichier</replaceable></programlisting>

     Pour restaurer&nbsp;:

<programlisting>createdb <replaceable class="parameter">base_de_donnees</replaceable>
cat <replaceable class="parameter">nom_fichier</replaceable>* | psql <replaceable class="parameter">base_de_donnees</replaceable></programlisting>
    </para>
   </formalpara>

   <formalpara>
    <title>Utilisation du format de sauvegarde spécial</title>
    <para>
     Si <productname>PostgreSQL</productname> est installé sur un système où la 
     bibliothèque de compression <application>zlib</application> est disponible, ce format
     de sauvegarde spécial peut être utilisé. Pour les grandes bases de données,
     cela produit un fichier de sauvegarde d'une taille comparable à celle
     du fichier produit par
     <command>gzip</command>, avec l'avantage supplémentaire de permettre de
     restaurer des tables sélectivement. La commande qui suit sauvegarde une
     base de données en utilisant le format de sauvegarde spécial&nbsp;:
 
<programlisting>pg_dump -Fc <replaceable class="parameter">base_de_donnees</replaceable> &gt; <replaceable class="parameter">nom_fichier</replaceable></programlisting>

     Le format personnalisé de la sauvegarde ne produit pas un script
     utilisable par
     <application>psql</application>. Ce script doit être restauré avec
     <application>pg_restore</application>. Voir les pages de référence de <xref
     linkend="app-pgdump"/> et <xref linkend="app-pgrestore"/> pour plus de
     détails.
    </para>
   </formalpara>

  </sect2>
 </sect1>

 <sect1 id="backup-file">
  <title>Sauvegarde de niveau système de fichiers</title>

  <para>
   Une autre stratégie de sauvegarde est de copier les fichiers
   utilisés par <productname>PostgreSQL</productname> pour enregistrer les données.
   Dans la <xref linkend="creating-cluster"/>, l'emplacement de ces
   fichiers est précisé mais quiconque s'intéresse à cette méthode les a
   probablement déjà localisés. N'importe quelle
   méthode de sauvegarde peut être utilisée, par exemple&nbsp;:
 
<programlisting>tar -cf sauvegarde.tar /usr/local/pgsql/data</programlisting>
  </para>

  <para>
   Cependant, deux restrictions rendent cette méthode peu pratique
   ou en tout cas inférieure à la méthode <application>pg_dump</application>.
 
   <orderedlist>
    <listitem>
     <para>
      Le serveur de base de données <emphasis>doit</emphasis> être arrêté pour obtenir
      une sauvegarde utilisable. Toutes les demi-mesures, comme la
      suppression des connexions, ne fonctionnent <emphasis>pas</emphasis>
      (principalement parce que <command>tar</command> et les outils similaires
      ne font pas une image atomique de l'état du système de fichiers à un
      moment spécifique). Les informations concernant la façon d'arrêter
      le serveur <productname>PostgreSQL</productname> se trouvent dans la <xref
      linkend="server-shutdown"/>.
    </para>

     <para>
      Le serveur doit également être arrêté avant de restaurer les données.
      </para>
    </listitem>

    <listitem>
     <para>
      Qui s'est aventuré dans les détails de l'organisation de la 
      base de données peut être tenté de ne sauvegarder et 
      de ne restaurer que certaines tables ou bases de données particulières. 
      Ceci ne fonctionne <emphasis>pas</emphasis> parce que les informations
      contenues dans ces fichiers ne représentent que la moitité de la
      vérité. L'autre moitié est dans les fichiers journaux de validation
      <filename>pg_clog/*</filename>, qui 
      contiennent l'état de la validation de chaque transaction. Un fichier de 
      table n'est utilisable qu'avec cette information. Bien entendu, il est 
      impossible de ne restaurer qu'une table et les données <filename>pg_clog</filename>
      associées car cela rendrait toutes les autres tables du serveur 
      inutilisables. Les sauvegardes du système de fichiers fonctionnent,
      de ce fait, uniquement pour les restaurations complètes d'un cluster
      de bases de données.
     </para>
    </listitem>
   </orderedlist>
  </para>

  <para>
   Une autre approche à la sauvegarde du système de fichiers est de réaliser
   une <quote>image cohérente</quote> du répertoire des données si le système
   de fichiers supporte cette fonctionnalité (et qu'il peut lui être fait
   confiance). La procédure typique est de faire une
   <quote>image gelée</quote> du volume contenant la base de données, et enfin de
   copier entièrement le répertoire de données (pas uniquement quelques parties,
   voir ci-dessus) de l'image sur un périphérique de sauvegarde, puis de
   libérer l'image gelé. Ceci fonctionne même si le serveur de la base de
   données est en cours d'exécution. Néanmoins, une sauvegarde créée de cette
   façon sauvegarde les fichiers de la base de données dans un état où le
   serveur n'est pas correctement arrêté&nbsp;; du coup, au lancement du
   serveur à partir des données sauvegardées, PostgreSQL peut penser que le
   serveur s'est stoppé brutalement et rejouer les journaux WAL. Ceci n'est
   pas un problème, mais il faut en être conscient (et s'assurer d'inclure les
   fichiers WAL dans la sauvegarde).
  </para>

  <para>
   Si la base de données est répartie sur plusieurs systèmes de fichiers,
   il n'est peut-être pas possible d'obtenir des images gelées
   exactement simultanées de tous les disques. Si les fichiers 
   de données et les journaux WAL sont sur des disques différents, par
   exemple, ou si les
   espaces logiques sont sur des systèmes de fichiers différents, une
   sauvegarde par images n'est probablement pas utilisable parce que ces
   dernières doivent être simultanées.
   La documentation du système de fichiers doit être étudiée avec attention
   avant de faire confiance à la technique d'images
   cohérentes dans de telles situations. L'approche la plus sûre est d'arrêter
   le serveur de bases de données assez longtemps pour créer toutes les images
   gelées.
  </para>

  <para>
   Une autre option consiste à utiliser <application>rsync</application> pour réaliser une
   sauvegarde du système de fichiers. Ceci se fait tout d'abord en lançant
   <application>rsync</application> alors que le serveur de bases de données est en cours
   d'exécution, puis en arrêtant le serveur juste assez longtemps pour lancer
   <application>rsync</application> une deuxième fois. Le deuxième
   <application>rsync</application> est beaucoup plus rapide que le premier car il a
   relativement peu de données à transférer et le résultat final est
   cohérent, le serveur étant arrêté. Cette méthode permet de réaliser une
   sauvegarde du système de fichiers avec un arrêt minimal.
  </para>

  <para>
   Une sauvegarde des fichiers de données n'est pas forcément 
   moins volumineuse qu'une sauvegarde SQL. Au contraire, elle l'est très certainement
   plus (<application>pg_dump</application> ne sauvegarde pas le 
   contenu des index, mais la commande pour les recréer).
  </para>

 </sect1>

 <sect1 id="continuous-archiving">
  <title>Archivage en continue et récupération d'un instantané (PITR)</title>

  <indexterm zone="backup">
   <primary>archivage en continue</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>récupération d'un instantané</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>PITR</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname> maintient en permanence des journaux WAL
   (<firstterm>write ahead log</firstterm>) dans le sous-répertoire
   <filename>pg_xlog/</filename> du répertoire de données du cluster. Ces journaux
   décrivent chaque modification effectuée sur les fichiers de données des
   bases. Ils existent principalement pour se prémunir des suites d'un
   arrêt brutal&nbsp;: si le système s'arrête brutalement, la base de données
   peut être restaurée dans un état cohérent des données en
   <quote>rejouant</quote> les entrées des journaux enregistrées depuis le dernier
   point de vérification. Néanmoins, l'existence de ces journaux rend possible
   l'utilisation d'une troisième stratégie pour la sauvegarde des bases de
   données&nbsp;: la combinaison d'une sauvegarde de niveau système de
   fichiers avec la sauvegarde des fichiers WAL. Si la récupération est
   nécessaire, la sauvegarde est restaurée, puis les fichiers WAL sauvegardés
   sont rejoués pour amener la sauvegarde jusqu'à la date
   actuelle. Cette approche est plus complexe à administrer que toutes les
   autres approches mais elle apporte des bénéfices significatifs&nbsp;:
  <itemizedlist>
   <listitem>
    <para>
     il n'est pas nécessaire de faire une sauvegarde parfaitement cohérente
     comme point de départ. Toute incohérence dans la sauvegarde est corrigée
     par la ré-exécution des journaux (ceci n'est pas significativement
     différent de ce qu'il se passe lors d'une récupération après un arrêt
     brutal). La fonctionnalité d'image du système de fichiers n'est alors
     pas nécessaire, <application>tar</application> ou tout
     autre outil d'archivage est suffisant.
    </para>
   </listitem>
   <listitem>
    <para>
     Puisqu'une longue séquence de fichiers WAL peut être assemblée pour
     être rejouée, la sauvegarde continue est possible en continuant
     simplement à archiver les fichiers WAL. Ceci est particulièrement
     intéressant pour les grosses bases de données dont la fréquente
     sauvegarde complète est difficilement réalisable.
    </para>
   </listitem>
   <listitem>
    <para>
     Les entrées WAL ne doivent pas obligatoirement être rejouées
     intégralement. La ré-exécution peut être stoppée en tout point, tout en
     garantissant une image cohérente de la base de données telle qu'elle
     était à ce moment-là. Ainsi, cette technique
     supporte la <firstterm>récupération d'un instantané</firstterm> (PITR)&nbsp;: il est
     possible de restaurer l'état de la base de données telle qu'elle était 
     en tout point dans le temps depuis la dernière sauvegarde de base.
    </para>
   </listitem>
   <listitem>
    <para>
     Si la série de fichiers WAL est fournie en continu à une autre
     machine chargée avec le même fichier de sauvegarde de base,
     on obtient un système <quote>en veille active</quote>
     (<foreignphrase>hot standby</foreignphrase>)&nbsp;: à tout
     moment, la deuxième machine peut être montée et disposer d'une copie
     quasi-complète de la base de données.
    </para>
   </listitem>
  </itemizedlist>
  </para>

  <para>
   Tout comme la technique de sauvegarde standard du système de fichiers,
   cette méthode ne supporte que la restauration d'un cluster de bases de données
   complet, pas d'un sous-ensemble. De plus, un volumineux espace
   d'archivage est requis&nbsp;: la sauvegarde de la base peut être
   volumineuse et un système
   très utilisé engendre un trafic WAL à archiver de plusieurs Mo. Malgré tout,
   c'est la technique de sauvegarde préférée dans
   de nombreuses situations où une haute fiabilité est requise.
  </para>

  <para>
   Une récupération fructueuse à partir de l'archivage continu
   (aussi appelé sauvegarde à chaud par certains vendeurs de SGBD) nécessite
   une séquence ininterrompue de fichiers WAL archivés qui
   s'étend au moins jusqu'au point de départ de la sauvegarde. Pour
   commencer, il faut configurer et tester la procédure d'archivage
   des journaux WAL <emphasis>avant</emphasis> d'effectuer la première sauvegarde de
   base. C'est pourquoi la suite du document commence par présenter les mécanismes
   d'archivage des fichiers WAL.
  </para>

  <sect2 id="backup-archiving-wal">
   <title>Configurer l'archivage WAL</title>

   <para>
    Au sens abstrait, un système <productname>PostgreSQL</productname> fonctionnel
    produit une séquence infinie d'enregistrements WAL. Le système
    divise physiquement cette séquence en <firstterm>fichiers de segment</firstterm>
    WAL de 16&nbsp;Mo chacun (en génral, mais cette taille peut
    être modifiée lors de la construction de <productname>PostgreSQL</productname>). Les
    fichiers de segment reçoivent des noms numériques pour refléter leur
    position dans la séquence abstraite des WAL.
   </para>
   <para>
    Lorsque le système n'utilise
    pas l'archivage des WAL, il ne crée que quelques fichiers de segment,
    qu'il <quote>recycle</quote> en renommant les fichiers de segment devenus inutiles.
    Un fichier segment dont le contenu précède le
    dernier point de vérification est supposé inutile et peut être recyclé.
   </para>

   <para>
    Lors de l'archivage des données WAL, le contenu de
    chaque fichier de segment doit être capturé dès qu'il est rempli pour
    sauvegarder les données ailleurs avant son recyclage.
    En fonction de l'application et de matériel disponible, 
    <quote>sauvegarder les données ailleurs</quote> peut se faire de plusieurs
    façons&nbsp;: les fichiers de segment peuvent être copiés dans un répertoire
    NFS monté sur une autre machine, être écrits sur une cartouche (après
    s'être assuré que le fichier peut être restauré avec son nom
    d'origine) ou être groupés pour gravage sur un CD, ou tout à fait autre chose.
    Pour fournir autant de flexibilité que possible à l'administrateur de la
    base de données, <productname>PostgreSQL</productname> essaie de ne faire aucune
    supposition sur la façon dont l'archivage est réalisé. À la place,
    <productname>PostgreSQL</productname> permet de préciser la commande
    shell à exécuter pour copier le fichier de segment rempli à l'endroit
    désiré. La commande peut être aussi simple qu'un
    <literal>cp</literal> ou impliquer un shell complexe &mdash;
    à l'utilisateur de voir.
   </para>

   <para>
    La commande shell à utiliser est indiquée à l'aide du paramètre de
    configuration <xref linkend="guc-archive-command"/> qui, en pratique, est
    toujours placé dans le fichier <filename>postgresql.conf</filename>. Dans
    cette chaîne, tout <literal>%p</literal> est remplacé par le chemin
    absolu de
    l'archive alors que tout <literal>%f</literal> n'est remplacé que par le
    nom du fichier. (Le nom du chemin est relatif au répertoire de travail du
    serveur, c'est-à-dire le répertoire des données du cluster.)
    <literal>%%</literal> est utilisé pour écrire le
    caractère <literal>%</literal> dans la commande. La commande utile la plus
    simple ressemble à
<programlisting>archive_command = 'cp -i %p /mnt/serveur/repertoire_archive/%f &lt;/dev/null'</programlisting>
    qui copie les segments WAL archivables dans le répertoire
    <filename>/mnt/serveur/repertoire_archive</filename>. (Ceci est un exemple, pas
    une recommandation, et peut ne pas fonctionner sur toutes les
    plateformes.)
   </para>

   <para>
    La commande d'archivage est exécutée sous l'identité de l'utilisateur 
    propriétaire du serveur <productname>PostgreSQL</productname>. La série de
    fichiers WAL en cours d'archivage contient absolument tout ce qui se
    trouve dans la base de données, il convient donc de s'assurerer que les
    données archivées sont protégées des autres utilisateurs&nbsp;; on peut,
    par exemple, archiver dans un répertoire sur lequel les droits de lecture
    ne sont positionnés ni pour le groupe ni pour le reste du monde.
   </para>

   <para>
    Il est important que la commande d'archivage ne renvoie le code de sortie
    zéro que si, et seulement si, l'exécution a réussi. En obtenant un résultat
    zéro, <productname>PostgreSQL</productname> suppose que le fichier segment WAL a
    été archivé avec succès et qu'il peut le supprimer ou le recycler.
    Un statut différent de zéro indique à  
    <productname>PostgreSQL</productname> que le fichier n'a pas été archivé&nbsp;; il
    essaie alors périodiquement jusqu'à la réussite de l'archivage.
   </para>

   <para>
    La commande d'archivage doit en général être conçue pour refuser
    d'écraser tout fichier archive déjà existant. C'est une fonctionnalité
    de sécurité importante pour préserver l'intégrité de l'archive dans le
    cas d'une erreur de l'administrateur (comme l'envoi de la sortie de deux
    serveurs différents dans le même répertoire d'archivage). Il est
    conseillé de tester la commande d'archivage proposée pour
    s'assurer qu'en effet elle n'écrase pas un fichier existant <emphasis>et
    qu'elle retourne un statut différent de zéro dans ce cas</emphasis>.
    Il a été découvert
    que <literal>cp -i</literal> travaille correctement sur certaines plateformes,
    mais pas sur toutes. Si la commande choisie ne gère pas elle-même ce
    cas, il convient d'ajouter une commande pour tester l'existence du fichier
    d'archivage. Quelque chose comme
<programlisting>archive_command = 'test ! -f .../%f &amp;&amp; cp %p .../%f'</programlisting>
    fonctionne, par exemple, correctement sur la plupart des variantes Unix.
   </para>

   <para>
    Lors de la conception de la configuration d'archivage, il faut
    considérer ce qui arrive si la commande d'archivage échoue de façon répétée parce
    que certains aspects demandent une intervention de l'opérateur ou
    par manque d'espace dans le répertoire d'archivage. 
    Ceci peut arriver, par exemple, lors de l'écriture sur une cartouche sans changeur 
    automatique&nbsp;; quand la cartouche est pleine, rien ne peut être
    archivé tant que la cassette n'est pas changée. 
    Toute erreur ou requête à un opérateur humain doit être rapportée de façon
    approprié pour que la situation puisse être résolue
    rapidement. Le répertoire <filename>pg_xlog/</filename> continue à se remplir
    de fichiers de segment WAL jusqu'à la résolution de la situation.
   </para>

   <para>
    La vitesse de la commande d'archivage n'est pas importante, tant qu'elle
    suit le rythme que la génération de données WAL du serveur. Les
    opérations normales continuent même si le processus d'archivage est un peu
    plus lent. Si l'archivage est significativement plus lent, alors la
    quantité de données qui peut être perdue croît. Cela signifie
    aussi que le répertoire <filename>pg_xlog/</filename> contiend un grand nombre
    de fichiers segment non archivés, qui peuvent finir par
    dépasser l'espace disque disponible. Il est conseillé de surveiller
    le processus d'archivage pour s'assurer que tout fonctionne
    normalement.
   </para>

   <para>
    Lors de l'écriture de la commande d'archivage, il faut garder à l'esprit que les
    noms de fichier à archiver peuvent contenir jusqu'à 64 caractères et 
    être composés de toute combinaison de lettres ASCII, de chiffres et de points.
    Il n'est pas nécessaire de retenir le chemin complet original
    (<literal>%p</literal>) mais il est nécessaire de rappeler le nom du fichier
    (<literal>%f</literal>).
   </para>

   <para>
    Bien que l'archivage WAL autorise à restaurer toute
    modification réalisée sur les données de la base 
    <productname>PostgreSQL</productname>, il ne restaure pas les modifications
    effectuées sur les fichiers de configuration (c'est-à-dire
    <filename>postgresql.conf</filename>, <filename>pg_hba.conf</filename> et
    <filename>pg_ident.conf</filename>) car ceux-ci sont édités manuellement
    et non au travers d'opérations SQL. Il est souhaitable de conserver les
    fichiers de configuration à un endroit où ils sont sauvegardés par les
    procédures standard de sauvegarde du système de fichiers. Voir la
    <xref linkend="runtime-config-file-locations"/> pour savoir comment
    modifier l'emplacement des fichiers de configuration.
   </para>

   <para>
    La commande d'archivage n'est appelée que sur les segments WAL complets.
    Du coup, si le serveur engendre peu de trafic WAL (ou qu'il y a des périodes
    de calme où le trafic WAL est léger), il peut y avoir une longue période
    entre la fin d'une transaction et son enregistrement sûr dans le stockage
    d'archive. Pour placer une limite sur l'ancienneté des données archivées,
    on configure <xref linkend="guc-archive-timeout"/> qui force le
    serveur à changer de fichier segment WAL passé ce délai. Les
    fichiers archivés lors d'un tel forçage ont toujours
    la même taille que les fichiers complets. Il est donc déconseillé de configurer
    un délai <varname>archive_timeout</varname> trop court &mdash; cela grossit
    anormalement le stockage. Une minute pour <varname>archive_timeout</varname>
    est généralement raisonnable.
   </para>

   <para>
    De plus, le changement d'un segment peut être forcé manuellement avec
    <function>pg_switch_xlog</function>. Cela permet de s'assurer qu'une
    transaction tout juste terminée est immédiatement archivée. D'autres
    fonctions utilitaires relatives à la gestion des WAL sont disponibles dans
    <xref linkend="functions-admin-backup-table"/>.
   </para>
  </sect2>

  <sect2 id="backup-base-backup">
   <title>Réaliser une sauvegarde de base</title>

   <para>
    La procédure pour réaliser une sauvegarde de base est relativement
    simple&nbsp;:
  <orderedlist>
   <listitem>
    <para>
     S'assurer que l'archivage WAL est activé et fonctionnel.
    </para>
   </listitem>
   <listitem>
    <para>
     Se connecter à la base de données en tant que superutilisateur et
     lancer la commande
<programlisting>SELECT pg_start_backup('label');</programlisting>
     où <literal>label</literal> est une chaîne utilisée pour
     identifier de façon unique l'opération de sauvegarde (une bonne pratique
     est d'utiliser le chemin complet du
     fichier de sauvegarde). <function>pg_start_backup</function> crée un fichier
     <firstterm>de label de sauvegarde</firstterm> nommé
     <filename>backup_label</filename> dans
     le répertoire du cluster. Ce fichier contient les informations de la sauvegarde.
    </para>

    <para>
     La base de données de connexion utilisée pour lancer
     cette commande n'a aucune importance. Le résultat de la fonction peut
     être ignoré, mais il faut gérer l'erreur éventuelle avant
     de continuer.
    </para>
   </listitem>
   <listitem>
    <para>
     Lancer la sauvegarde à l'aide de n'importe quel outil de sauvegarde du
     système de fichiers, tel <application>tar</application> ou
     <application>cpio</application>. Il
     n'est ni nécessaire ni désirable de stopper les opérations normales de
     la base de données pour cela.
    </para>
   </listitem>
   <listitem>
    <para>
     Se connecter de nouveau à la base de données en tant que
     superutilisateur et lancer la commande
<programlisting>SELECT pg_stop_backup();</programlisting>
     Elle doit réussir. Néanmoins, la sauvegarde n'est pas encore entièrement
     valide. Un basculement automatique du prochain segment WAL intervient. 
     Tous les fichiers segment WAL en relation avec l'archivage sont maintenant
     marqués à archiver.
    </para>
   </listitem>
   <listitem>
    <para>
     Une fois que les fichiers des segments WAL utilisées lors de la sauvegarde
     sont archivées, c'est terminé. Le fichier identifié par le résultat de
     <function>pg_stop_backup</function> est le dernier segment à archiver pour
     terminer la sauvegarde. L'archivage de ces fichiers intervient automatiquement
     car <varname>archive_command</varname> est déjà configuré. Dans de
     nombreux cas, c'est assez rapide mais il est conseillé de
     surveiller le système d'archivage pour s'assurer que celui-ci s'effectue
     correctement et que la sauvegarde est valide.
    </para>
   </listitem>
  </orderedlist>
   </para>

   <para>
    Certains outils de sauvegarde émettent des
    messages d'avertissements ou d'erreurs si les fichiers qu'ils essaient de
    copier sont modifiés au cours de la copie. Cette situation, normale lors
    de la sauvegarde d'une base active, ne doit pas être considérée comme 
    une erreur&nbsp;; il suffit de s'assurer que ces messages peuvent être
    distingués des autres messages. 
    Certaines versions de <application>rsync</application>, par exemple,
    renvoient un code de sortie
    distinct en cas de <quote>disparition de fichiers source</quote>. Il est
    possible d'écrire un script qui considère ce code de sortie comme normal.
    De plus, certaines versions de <application>GNU tar</application>
    considèrent que la modification
    d'un fichier lors de sa copie par <application>tar</application> est une erreur. Il
    ne semble pas exister de moyen simple de distinguer cette erreur des autres
    types d'erreurs, sinon d'inspecter manuellement les messages de
    <application>tar</application>. De ce fait, GNU <application>tar</application>
    n'est pas le meilleur
    outil pour réaliser des sauvegardes de base.
   </para>

   <para>
    Il n'est pas utile d'accorder de l'importance au le temps passé entre
    <function>pg_start_backup</function> et le début réel de la sauvegarde, pas plus
    qu'entre la fin de la sauvegarde et <function>pg_stop_backup</function>&nbsp;; un
    délai de quelques minutes ne pose pas de problème. Néanmoins, si le
    serveur est normalement utilisé alors que
    <varname>full_page_writes</varname> est désactivé, une perte de
    performances entre <function>pg_start_backup</function>
    et <function>pg_stop_backup</function> peut être constatée. Il convient
    toutefois de s'assurer que les opérations de sauvegarde sont effectuées
    séquentiellement, sans chevauchement. Dans le ca contraire, la
    sauvegarde est invalidée.
   </para>

   <para>
    La sauvegarde doit inclure tous les fichiers du répertoire
    du groupe de bases de données
    (<filename>/usr/local/pgsql/data</filename>, par exemple). Si des
    <foreignphrase>tablespace</foreignphrase> 
    qui ne se trouvent pas dans ce répertoire sont utilisés, il ne faut pas
    oublier de les inclure (et s'assurer également que la sauvegarde archive les liens
    symboliques comme des liens, sans quoi la restauration des
    <foreignphrase>tablespace</foreignphrase> sera problématique).
   </para>

   <para>
    Néanmoins, les fichiers du sous-répertoire <filename>pg_xlog/</filename>
    contenu dans le répertoire du cluster peuvent être omis. Cette petite
    complication permet de réduire le risque d'erreurs lors de la restauration.
    C'est facile à réaliser si <filename>pg_xlog/</filename> est un lien
    symbolique vers quelque endroit extérieur au répertoire du cluster, 
    ce qui est toutefois une configuration courante, pour des raisons de performance.
   </para>

   <para>
    La sauvegarde n'est utilisable que si les  fichiers de segment WAL
    engendrés pendant ou après cette sauvegarde sont préservés.
    Pour faciliter cela, la fonction 
    <function>pg_stop_backup</function> crée un <firstterm>fichier d'historique de la
    sauvegarde</firstterm> immédiatement stocké dans la zone d'archivage des WAL.
    Ce fichier est nommé d'après le nom du premier fichier segment WAL dont
    nécessaire à l'utilisation de la sauvegarde. Ainsi, si le fichier
    WAL de démarrage est <literal>0000000100001234000055CD</literal>, le nom
    du fichier d'historique ressemble à 
    <literal>0000000100001234000055CD.007C9330.backup</literal> (le deuxième nombre
    dans le nom de ce fichier contient la position exacte à l'intérieur du fichier
    WAL et peut en général être ignoré). Une fois que la sauvegarde du
    système de fichiers et des segments WAL utilisés
    pendant celle-ci (comme précisé dans le fichier d'historique des sauvegardes) 
    sont archivés de façon sûre,   
    tous les segments WAL archivés de noms numériquement plus
    petits ne sont plus nécessaires à la récupération de la sauvegarde du
    système de fichiers et peuvent être supprimés. Toutefois, il est
    préférable de conserver plusieurs jeux de sauvegarde pour être absolument
    certain de pouvoir récupérer les données.
   </para>

   <para>
    Le fichier d'historique de la sauvegarde est un simple fichier texte. Il
    contient le label passé à <function>pg_start_backup</function>,
    l'heure et les segments WAL de début et de fin de la sauvegarde.
    Si le label est utilisé pour identifier l'endroit où le fichier de sauvegarde associé
    est conservé, alors le fichier d'historique archivé est suffisant pour
    savoir quel fichier de sauvegarde restaurer, en cas de besoin.
   </para>

   <para>
    Puisqu'il faut conserver tous les fichiers WAL archivés depuis la
    dernière sauvegarde de base, l'intervalle entre les sauvegardes de base
    est habituellement choisi en fonction de l'espace de stockage qu'on
    accepte de consommer en fichiers d'archives WAL. Il faut également
    considérer le temps à dépenser pour la
    récupération, si celle-ci s'avère nécessaire &mdash; le système doit rejouer
    tous les segments WAL et ceci peut prendre beaucoup de temps si la
    dernière sauvegarde de base est ancienne.
   </para>

   <para>
    La fonction
    <function>pg_start_backup</function> crée un fichier nommé 
    <filename>backup_label</filename> dans le répertoire du cluster de bases
    de données. Ce fichier est ensuite supprimé par
    <function>pg_stop_backup</function>. Ce fichier est bien sûr archivé
    comme faisant parti du fichier de
    sauvegarde. Le fichier de label de la sauvegarde inclut la chaîne de label
    passée à <function>pg_start_backup</function>, l'heure à
    laquelle <function>pg_start_backup</function> a été exécuté et le nom du fichier
    WAL initial. En cas de confusion, il est ainsi possible de regarder
    dans le fichier sauvegarde et de déterminer avec précision de quelle session
    de sauvegarde provient ce fichier.
   </para>

   <para>
    Il est aussi possible de faire une sauvegarde alors que le serveur est
    arrêté. Dans ce cas, <function>pg_start_backup</function> et
    <function>pg_stop_backup</function> ne peuvent évidemment pas être
    utilisés. L'utilisateur doit alors se débrouiller pour identifier les
    fichiers de sauvegarde et déterminer jusqu'où remonter avec les fichiers
    WAL associés. Il est généralement préférable de
    suivre la procédure d'archivage en ligne décrite ci-dessus.
   </para>
  </sect2>

  <sect2 id="backup-pitr-recovery">
   <title>Récupération d'une sauvegarde en ligne</title>

   <para>
    Le pire est arrivé et il faut maintenant repartir d'une sauvegarde.
    Voici la procédure&nbsp;:
  <orderedlist>
   <listitem>
    <para>
     Arrêter le serveur s'il est en cours d'exécution.
    </para>
   </listitem>
   <listitem>
    <para>
     Si la place nécessaire est disponible, copier le répertoire complet de
     données du cluster et tous les <foreignphrase>tablespaces<foreignphrase>
     dans un emplacement temporaire en prévision d'un éventuel besoin
     ultérieur. Cette précaution nécessite qu'un espace suffisant sur le
     système soit disponible pour contenir deux copies de la base de données
     existante. S'il n'y a pas assez de place disponible, il faut au minimum 
     copier le contenu du sous-répertoire <filename>pg_xlog</filename> du
     répertoire des données du cluster car il peut contenir des journaux
     qui n'ont pas été archivés avant l'arrêt du serveur.
    </para>
   </listitem>
   <listitem>
    <para>
     Effacer tous les fichiers et sous-répertoires existant sous le
     répertoire des données du cluster et sous les répertoires racines des
     <foreignphrase>tablespaces<foreignphrase>.
    </para>
   </listitem>
   <listitem>
    <para>
     Restaurer les fichiers de la base de données à partir de la
     sauvegarde. Il faut veiller à ce qu'ils soient restaurés avec le bon
     propriétaire (l'utilisateur système de la base de données, et non pas
     root&nbsp;!) et avec les bons droits. Si des
     <foreignphrase>tablespaces<foreignphrase> sont utilisés, il faut
     s'assurer que les liens symboliques dans
     <filename>pg_tblspc/</filename> ont été correctement restaurés.
    </para>
   </listitem>
   <listitem>
    <para>
     Supprimer tout fichier présent dans <filename>pg_xlog/</filename>&nbsp;; ils
     proviennent de la sauvegarde et sont du coup probablement obsolètes.
     Si <filename>pg_xlog/</filename> n'a pas été archivé, il suffit de 
     recréer ce répertoire ainsi que le sous-répertoire
     <filename>pg_xlog/archive_status/</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     Si des fichiers de segment WAL non archivés ont été sauvegardés dans
     l'étape 2, les copier dans <filename>pg_xlog/</filename>. Il
     est préférable de les copier plutôt que de les déplacer afin qu'une
     version non modifiée de ces fichiers soit toujours disponible si un
     problème survient et qu'il faille recommencer.
    </para>
   </listitem>
   <listitem>
    <para>
     Créer un fichier de commandes de récupération 
     <filename>recovery.conf</filename> dans le répertoire des données du
     cluster (voir <xref linkend="recovery-config-settings"/>). Il peut, de
     plus être judicieux de modifier temporairement le fichier 
     <filename>pg_hba.conf</filename> pour empêcher les utilisateurs
     ordinaires de se connecter tant qu'il n'est pas certain que la
     récupération a réussi.
    </para>
   </listitem>
   <listitem>
    <para>
     Démarrer le serveur. Le serveur se trouve alors en mode récupération et
     commence la lecture des fichiers WAL archivés dont il a besoin. Si la
     récupération se termine sur une erreur externe, le serveur peut tout
     simplement être relancé. Il continue alors la récupération. À la
     fin du processus de récupération, le serveur renomme
     <filename>recovery.conf</filename> en <filename>recovery.done</filename>
     (pour empêcher de retourner accidentellement en mode de récupération en
     cas de nouvel arrêt brutal ultérieur), puis passe ne mode de
     fonctionnement normal.
    </para>
   </listitem>
   <listitem>
    <para>
     Inspecter le contenu de la base de données pour s'assurer que la
     récupération a bien fonctionné. Dans le cas contraire, retourner
     à l'étape 1. Si tout va bien, le fichier <filename>pg_hba.conf</filename>
     peut-être restauré pour autoriser les utilisateurs à se reconnecter.
    </para>
   </listitem>
  </orderedlist>
   </para>

   <para>
    Le point clé de tout ceci est l'écriture d'un fichier de commandes de
    récupération qui décrit comment et jusqu'où récupérer. Le fichier 
    <filename>recovery.conf.sample</filename> (normalement présent dans le
    répertoire d'installation <filename>share/</filename>) peut être utilisé
    comme prototype. La seule chose qu'il faut absolument préciser dans
    <filename>recovery.conf</filename>, c'est <varname>restore_command</varname>
    qui indique à <productname>PostgreSQL</productname> comment récupérer les
    fichiers de segment WAL archivés. À l'instar 
    d'<varname>archive_command</varname>, c'est une chaîne de commande
    shell. Elle peut contenir <literal>%f</literal>, qui est
    remplacé par le nom du journal souhaité, et <literal>%p</literal>, qui est
    remplacé par le chemin du répertoire où copier le journal.
    (Le nom du chemin est relatif au répertoire de travail du serveur,
    c'est-à-dire le répertoire des données du cluster.) Pour écrire le
    caractère <literal>%</literal> dans la commande, on utilise
    <literal>%%</literal>. La commande utile la plus simple ressemble à
<programlisting>restore_command = 'cp /mnt/serveur/répertoire_archive/%f %p'</programlisting>
    qui copie les segments WAL précédemment archivés à partir du répertoire
    <filename>/mnt/serveur/répertoire_archive</filename>.  Il est toujours
    possible d'utiliser une commande plus compliquée, voire même un script shell
    qui demande à l'utilisateur de monter la cassette appropriée.
   </para>

<!-- ICI /home/sas/documentations/pg82/continuous-archiving.html -->
   <para>
    Il est important que la commande retourne un code de sortie différent de
    zéro en cas d'échec. Des journaux absents de l'archive
    <emphasis>seront</emphasis> demandés à la commande&nbsp;; elle doit
    renvoyer autre chose que
    zéro dans ce cas. Ce n'est pas une condition d'erreur. Soyez conscient
    que le nom de base du chemin <literal>%p</literal> sera différent de
    <literal>%f</literal>&nbsp;; ne vous attendez pas à ce qu'ils soient
    interchangeables.
   </para>

   <para>
    Les segments WAL qui n'ont pas pu être trouvés dans l'archive seront
    recherchés dans <filename>pg_xlog/</filename>&nbsp;; cela autorise l'utilisation
    des segments non archivés. Néanmoins, les segments disponibles à partir de
    l'archive seront utilisés de préférence par rapport aux fichiers dans
    <filename>pg_xlog/</filename>. Le système ne surchargera pas le contenu existant
    de <filename>pg_xlog/</filename> lors de la récupération des fichiers archivés.
   </para>

   <para>
    Normalement, la récupération traitera tous les segments WAL disponibles,
    restaurant du coup la base de données à cet instant (ou aussi proche que
    nous le pouvons suivant les segments WAL disponibles). Mais, si vous
    voulez récupérer à un instant particulier (disons, juste avant que
    l'administrateur junior ait supprimé votre table principale de
    transaction), spécifiez simplement le point d'arrêt requis dans
    <filename>recovery.conf</filename>. Vous pouvez spécifier le point d'arrêt, connu
    sous le nom de <quote>cible de récupération</quote>, soit par la date/heure
    soit par l'ID de la dernière transaction. Au moment où nous écrivons ceci,
    seule l'option date/heure est tout à fait utilisable car il n'existe pas
    d'outils pour vous aider à identifier avec une certaine précision l'ID de
    transaction à utiliser.
   </para>

   <note>
     <para>
      Le point d'arrêt doit se situer après l'heure de fin de la sauvegarde
      de base (le moment de <function>pg_stop_backup</function>). Vous ne pouvez pas
      utiliser une sauvegarde de base pour récupérer à un tel instant où la
      sauvegarde était encore en cours (pour récupérer jusqu'à cet instant,
      vous devez récupérer votre sauvegarde de base précédente et recommencer
      à partir de là).
     </para>
    </note>

   <para>
    Si la récupération découvre une corruption dans les données WAL,
    elle se termine à ce point et le serveur ne se lancera pas. Le processus
    de récupération pourra être ré-exécuté à partir du début en précisant un
    <quote>recovery target</quote> de façon à ce que la récupération puisse
    se terminer normalement. Si la récupération échoue pour une raison
    externe comme un arrêt brutal du système ou que l'archive WAL devient
    inaccessible, alors la récupération peut être simplement relancée
    et elle redémarrera pratiquement là où elle a échoué. La récupération
    relançable fonctionne en écrivant un enregistrement restartpoint dans le
    fichier de contrôle au premier enregistrement d'un point de contrôle
    trouvé après <varname>checkpoint_timeout</varname> secondes.
   </para>

    <sect3 id="recovery-config-settings" xreflabel="Configuration de la récupération">
     <title>Configuration de la récupération</title>

     <para>
      Ces configurations peuvent seulement être placées dans le fichier
      <filename>recovery.conf</filename> et s'appliquent seulement pour la durée de la
      récupération. Ils doivent être réinitialisés pour toute récupération
      ultérieure que vous souhaitez réaliser. Ils ne peuvent pas être modifiés
      une fois que la récupération a commencé.
     </para>

     <variablelist>

     <varlistentry id="restore-command" xreflabel="restore_command">
      <term><varname>restore_command</varname> (<type>string</type>)</term>
      <listitem>
       <para>
        La commande shell à exécuter pour récupérer un segment archivé de la
        série de fichiers WAL. Ce paramètre est requis. Tout <literal>%f</literal>
        dans la chaîne est remplacé par le nom du fichier à récupérer à
        partir de l'archive et tout <literal>%p</literal> est remplacé par le
	chemin pour le copier sur le serveur. (Le nom du chemin est relatif au
	répertoire de travail du serveur, c'est-à-dire le répertoire des données
	du cluster.) Écrivez <literal>%%</literal> pour embarquer un vrai
	caractère <literal>%</literal> dans la commande.
       </para>
       <para>
        Il est important que la commande renvoie un code de sortie zéro si et
        seulement si elle a réussi. La commande <emphasis>se verra
        demander</emphasis> les noms des fichiers absents dans l'archive&nbsp;; elle
        doit renvoyer une valeur différente de zéro dans ce cas.
        Exemples&nbsp;:
<programlisting>restore_command = 'cp /mnt/server/archivedir/%f "%p"'
restore_command = 'copy /mnt/server/archivedir/%f "%p"'  # Windows</programlisting>
       </para>
      </listitem>
     </varlistentry>

     <varlistentry id="recovery-target-time" xreflabel="recovery_target_time">
      <term><varname>recovery_target_time</varname> 
           (<type>timestamp</type>)
      </term>
      <listitem>
       <para>
        Ce paramètre spécifie le temps à partir duquel le serveur doit
        arrêter la récupération. Au plus un entre
        <varname>recovery_target_time</varname> et <xref
        linkend="recovery-target-xid"/> peut être spécifié. Par défaut, la
        récupération se passe jusqu'à la fin du journal WAL. Le point
        d'arrêt précis est aussi influencé par <xref
        linkend="recovery-target-inclusive"/>.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry id="recovery-target-xid" xreflabel="recovery_target_xid">
      <term><varname>recovery_target_xid</varname> (<type>string</type>)</term>
      <listitem>
       <para>
        Ce paramètre spécifie l'ID de transaction où arrêter la récupération.
        Gardez en tête qu'alors que les ID de transactions sont affectés
        séquentiellement au début de la transaction, les transactions peuvent
        se terminer dans un ordre numérique différent. Les transactions qui
        seront récupérées sont celles qui ont été validées avant celle
        spécifiée (et quelque fois en l'incluant). Au plus un entre
        <varname>recovery_target_xid</varname> et <xref
        linkend="recovery-target-time"/> peut être spécifié. La valeur par
        défaut est de récupérer jusqu'à la fin du journal WAL. Le point
        d'arrêt précis est aussi influencé par
        <xref linkend="recovery-target-inclusive"/>.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry id="recovery-target-inclusive" 
                   xreflabel="recovery_target_inclusive">
      <term><varname>recovery_target_inclusive</varname> 
        (<type>boolean</type>)
      </term>
      <listitem>
       <para>
        Spécifie si nous stoppons tout de suite après la cible de
        récupération spécifiée (<literal>true</literal>) ou tout juste avant
        (<literal>false</literal>). S'applique à <xref
        linkend="recovery-target-time"/> et <xref
        linkend="recovery-target-xid"/>, quelque soit celui qui est spécifié
        pour cette récupération. Ceci indique si les transactions ayant
        exactement l'instant de validation cible ou l'ID, respectivement,
        seront inclus dans la récupération. La valeur par défaut est
        <literal>true</literal>.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry id="recovery-target-timeline" 
                   xreflabel="recovery_target_timeline">
      <term><varname>recovery_target_timeline</varname> 
        (<type>string</type>)
      </term>
      <listitem>
       <para>
        Spécifie la récupération à un timeline particulier. La valeur par
        défaut est de récupérer suivant le timeline en cours au moment où la
        sauvegarde de base a été effectuée. Vous aurez seulement besoin de
        configurer ce paramètre dans les situations complexes de récupération
        où le besoin de retourner à un état qui a été atteint après une
        récupération à un temps donné. Voir la <xref
        linkend="backup-timelines"/> pour des informations.
       </para>
      </listitem>
     </varlistentry>

   </variablelist>

   </sect3>

  </sect2>

  <sect2 id="backup-timelines">
   <title>Timelines</title>

  <indexterm zone="backup">
   <primary>timelines</primary>
  </indexterm>

   <para>
    La possibilité de restaurer la base de données à un instant précédent
    crée une complexité qui sont la base des histoires de science-fiction sur
    le voyage dans le temps et les univers parallèles. Dans l'historique
    original de la base de données, vous avez peut-être supprimé une table
    critique à 17h15 mardi soir. Imperturbable, vous récupérez votre
    sauvegarde, la restaurez jusqu'à 17h14 mardi soir et êtes de nouveau
    fonctionnel. Dans <emphasis>cette</emphasis> histoire de l'univers de la base de
    données, vous n'avez jamais supprimé la table. Mais, supposez que vous
    réalisez plus tard qu'après tout, ce n'était pas une si grande idée et
    que vous voudriez revenir à un point plus lointain dans l'historique
    original. Vous ne serez plus capable de le faire si, une fois que votre
    base de donnée était de nouveau fonctionnelle, elle a écrit par dessus
    certaines des séquences de fichiers segments WAL qui vous aurait permis
    de récupérer à cet instant. Donc, vous voulez réellement distinguer les
    séries d'enregistrements WAL générées après la récupération à un instant
    donné de celles générées dans l'historique originale de la base de
    données.
   </para>

   <para>
    Pour gérer ces problèmes, <productname>PostgreSQL</productname> comprends la notion
    de <firstterm>timelines</firstterm>. Chaque fois que vous récupérez à un certain
    instant précédant la fin de la séquence WAL, un nouveau timeline est
    créé pour identifier les séries d'enregistrements WAL générées après la
    récupération (néanmoins, si la récupération continue jusqu'à la fin des
    WAL, nous ne commençons pas une nouvelle timeline&nbsp;: nous étendons
    celle qui existe). Le numéro d'identifiant de la timeline fait partie 
    des noms des fichiers segment WAL et, du coup, une nouvelle timeline
    ne réécrit pas sur les données générées par des timelines précédentes.
    En fait, il est possible d'archiver plusieurs timelines différentes.
    Bien que cela semble être une fonctionnalité inutile, parfois, cela vous
    sauve la vie. Considérez la situation où vous n'êtes plus sûr de l'instant
    jusqu'où récupérer. Du coup, vous devez tester des récupérations à
    différents instants jusqu'à trouver le meilleur moment dans l'ancien
    historique. Sans les timelines, ce processus génèrerait un incroyable
    bazar. Avec les timelines, vous pouvez récupérer à <emphasis>n'importe
    quel</emphasis> état précédent, ceci incluant les états dans les branches de
    timelines que vous abandonnerez plus tard.
   </para>

   <para>
    Chaque fois qu'une nouvelle timeline est créée,
    <productname>PostgreSQL</productname> crée un fichier d'<quote>historique des
    timeline</quote> qui montre les timelines, leur branchement et le moment
    auquel c'est arrivé. Ces fichiers historiques sont requis pour permettre
    au système de récupérer les bons fichiers segment WAL lors de la
    récupération à partir d'une archive contenant plusieurs timelines. Du
    coup, elles sont archivées dans l'aire des WAL comme tous les fichiers
    segment WAL. Les fichiers historiques sont de simples fichiers texte,
    donc il est peu coûteux et approprié de les conserver indéfiniment
    (contrairement aux fichiers segments qui sont gros). Vous pouvez, si
    vous le souhaitez, ajouter des commentaires au fichier historique pour
    ajouter vos propres notes sur comment et pourquoi cette timeline
    est particulièrement intéressante. De tels commentaires seront
    particulièrement utiles quand vous avez un ticket des différentes
    timelines comme résultat de l'expérimentation.
   </para>

   <para>
    Le comportement par défaut de la récupération est de récupérer parmi la
    timeline en cours au moment où la sauvegarde de base a été effectuée. Si
    vous voulez récupérer à une timeline enfant (c'est-à-dire si vous voulez
    retourner à un état qui a été enregistré après la tentative de
    récupération), vous avez besoin de spécifier l'ID cible de la timeline
    dans <filename>recovery.conf</filename>. Vous ne pouvez pas récupérer des
    timelines qui ont effectué leur branchement plus tôt que le moment où
    a été effectuée la sauvegarde de base.
   </para>
  </sect2>

  <sect2 id="backup-incremental-updated">
   <title>Sauvegardes mises à jour par incrément</title>

  <indexterm zone="backup">
   <primary>sauvegardes mises à jour par incrément</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>accumulation des modifications</primary>
  </indexterm>

   <para>
    La récupération après redémarrage peut aussi être utilisée pour décharger
    le serveur principal de la réalisation de sauvegardes de base périodiques.
    Le sauvegarde se fait sur le serveur d'attente. Ce concept est aussi connu
    sous le nom de sauvegardes mises à jour par incrément
    (<foreignphrase>incrementally updated backups</foreignphrase>, ou
    <foreignphrase>log change accumulation</foreignphrase> ou plus simplement
    <foreignphrase>change accumulation</foreignphrase>).
   </para>

   <para>
    Si nous réalisons une sauvegarde des fichiers du serveur alors qu'une
    récupération est en cours, nous serons capable de relancer la récupération
    à partir du dernier point de redémarrage. Maintenant, cette sauvegarde
    a certaines modifications des fichiers d'archive WAL précédents, donc
    cette version est une version mise à jour de la sauvegarde de base
    originale. Si nous avons besoin de la récupérer, il sera plus rapide de le
    faire à partir de la sauvegarde mise à jour par incrément que par celle de
    la sauvegarde de base.
   </para>

   <para>
    Pour utiliser cette possibilité, vous aurez besoin de configurer une base
    en attente sur un deuxième système comme décrit dans
    <xref linkend="warm-standby"/>. En réalisant une sauvegarde du serveur en
    attente alors qu'il est en cours d'exécution, vous aurez construit une
    sauvegarde mise à jour par incrément. Une fois ceci fait, vous n'aurez plus
    besoin de réaliser des sauvegardes de base régulièrement à partir du serveur
    principal&nbsp;: toutes les sauvegardes de base peuvent se faire sur le
    serveur en attente. Si vous souhaitez le faire, il n'est pas nécessaire
    d'implémenter les fonctionnalités de <foreignphrase>failover</foreignphrase>
    d'une configuration <foreignphrase>Warm Standby</foreignphrase> bien que
    vous puissiez faire les deux.
   </para>

  </sect2>

  <sect2 id="continuous-archiving-caveats">
   <title>Avertissements</title>

   <para>
    Au moment où nous écrivons ces lignes, il existe plusieurs limitations
    sur la technique de l'achivage continu. Elles seront probablement
    corrigées dans une prochaine version&nbsp;:

  <itemizedlist>
   <listitem>
    <para>
     Les opérations sur des index hachés
     ne sont pas tracées actuellement dans les WAL, donc ces index
     ne seront pas mis à jour. Le contournement recommandé est de
     <xref linkend="sql-reindex" endterm="sql-reindex-title"/>er manuellement
     chacun de ces index après avoir terminé une opération de récupération.
    </para>
   </listitem>

   <listitem>
    <para>
     Si une commande <xref linkend="sql-createdatabase" endterm="sql-createdatabase-title"/>
     est exécutée alors qu'une sauvegarde est en cours, alors la base de données
     modèle que l'instruction <command>CREATE DATABASE</command> a copié est
     modifiée alors que la sauvegarde de la base est toujours en cours, il est
     possible que la récupération sera la cause de la propagation des modifications
     dans la base de données créée. Pour éviter ce risque, il est préférable de
     ne pas modifier les bases de données modèles lors d'une sauvegarde de base.
    </para>
   </listitem>

   <listitem>
    <para>
     Les commandes <xref linkend="sql-createtablespace" endterm="sql-createtablespace-title"/>
     sont tracées dans WAL avec le chemin absolu littéral et seront donc rejouées
     en tant que créations d'espaces logiques avec le même chemin absolu. Ceci
     pourrait être indésirable si la trace est rejouée sur la même machine mais
     dans un nouveau répertoire de données&nbsp;: la ré-exécution surchargera
     toujours le contenu de l'espace logique original. Pour éviter des problèmes
     potentiels de cette sorte, la meilleure pratique est de prendre une
     nouvelle sauvegarde de base après la création ou la suppression d'espaces
     logiques.
    </para>
   </listitem>
  </itemizedlist>
   </para>

   <para>
    De plus, il devrait être noté que le format actuel des <acronym>WAL</acronym>
    est extrêmement difficile à gérer car il inclut de nombreuses images des
    pages disques. Ces images de page sont conçues pour supporter la
    récupération après un arrêt brutal car nous pouvons avoir besoin de
    corriger des pages disque partiellement écrites. Suivant le matériel et
    le logiciel de votre système, le risque d'écriture partielle pourrait être
    assez faible pour être ignoré, auquel cas vous pouvez réduire
    significativement le volume total des traces archivées en désactivat les
    images de page grâce au paramètre <xref linkend="guc-full-page-writes"/>
    (lire les notes et avertissements dans <xref linkend="wal"/> avant
    de le faire). Désactiver les images de page n'empêche pas l'utilisation des
    traces pour les opérations PITR. Un développement possible serait de
    compresser les données des WAL archivées en supprimant les copies
    inutiles de pages même si <varname>full_page_writes</varname> est actif. Entre
    temps, les administrateurs pourraient souhaiter réduire le nombre
    d'images de pages inclus dans WAL en augmentant autant que possible les
    paramètres d'intervalle des points de vérification.
   </para>
  </sect2>
 </sect1>

 <sect1 id="warm-standby">
  <title>Serveurs <quote>Warm Standby</quote> pour la haute disponibilité</title>

  <indexterm zone="backup">
   <primary>Warm Standby</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>PITR Standby</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>Standby Server</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>Log Shipping</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>Witness Server</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>STONITH</primary>
  </indexterm>

  <indexterm zone="backup">
   <primary>High Availability</primary>
  </indexterm>

  <para>
   L'archivage continue peut être utilisé pour créer une configuration
   de cluster de haute disponibilité avec un ou plusieurs serveurs en
   attente, prêt à prendre en main les opérations au cas où le serveur
   principal aurait un problème. Cette capacité est surtout connue sous
   le nom de <foreignphrase>Warm Standby Log Shipping</foreignphrase>.
  </para>

  <para>
   Le serveur principal et le serveur en attente travaillent ensemble pour
   fournir cette capacité, bien que les serveurs sont très faiblement couplés.
   Le serveur primaire opère dans le mode de l'archivage continu alors que le
   serveur en attente opère dans un mode de récupération continue en lisant
   les fichiers WAL du serveur primaire. Aucune modification des tables
   de la base n'est requise pour activer cette capacité, donc elle coûte peu
   en administration supplémentaire en comparaison à d'autres approches de
   réplication. Cette configuration a aussi un impact très faible sur les
   performances du serveur primaire.
  </para>

  <para>
   Déplacer directement les enregistrements des WAL (ou journaux) d'une base à
   une autre est typiquement décrit comme <foreignphrase>Log Shipping</foreignphrase>.
   <productname>PostgreSQL</productname> l'implemente à partir de fichiers,
   signifiant que les enregistrements
   WAL sont gérés un fichier à la fois. Les fichiers WAL peuvent être envoyés
   facilement et sans surcoût quelque soit la distance, que ce soit sur un
   système adjacent, sur un autre système du même site ou sur un autre système
   de l'autre côté du globe. La bande passante requise par cette technique
   varie suivant le taux de transaction du serveur principal.
   <foreignphrase>Record-based Log Shipping</foreignphrase> est aussi possible
   avec des procédures personnalisées, discutées dans une section suivante.
   Des futures développements devraient inclure des options pour les
   <foreignphrase>synchronous and/or integrated record-based log
   shipping</foreignphrase>.
  </para>

  <para>
   Il devrait être noté que l'envoi des journaux est asynchrone, c'est-à-dire
   que les enregistrements WAL sont envoyés après une validation de la
   transaction. Comme résultat, il y a un petit risque de perte de données,
   si le serveur principal souffre d'un problème catastrophique.
   Ce problème est minimisé grâce à l'utilisation du paramètre
   <varname>archive_timeout</varname> qui peut être configuré à quelques secondes
   si nécessaire. Un paramètrage très bas peut augmenter les besoins de bande
   passante pour l'envoi des journaux.
  </para>

  <para>
   Le serveur en attente n'est pas disponible en accès car il est en permanence
   dans le traitement de la récupération. Les performances de récupération
   sont suffisamment bonnes pour que l'attente ne soit typiquement que de
   quelques minutes avant une disponibilité complète une fois qu'il a été
   activé. Nous appelons cela une configuration <foreignphrase>Warm
   Standby</foreignphrase> qui offre la haute disponibilité. Restaurer un serveur
   à partir d'une sauvegarde archivée de la base et rejouer les journaux
   prendront considérablement plus de temps. Seule cette technique offre
   réellement une solution à la récupération suite à un désastre, mais pas
   de la haute disponibilité.
  </para>

  <para>
   Lors de l'exécution du serveur d'attente, les sauvegardes peuvent être
   réalisées sur ce serveur plutôt que sur le principal, ce qui décharge
   de la réalisation de sauvegarde basique (voir
   <xref linkend="backup-incremental-updated"/>)
  </para>

  <para>
   D'autres mécanismes de réplication pour haute disponibilité sont disponibles,
   solutions commerciales et libre.
  </para>

  <para>
   En général, l'envoi des journaux entre serveurs fonctionnant avec des
   niveaux de version différents n'est pas possible. La politique des
   développeurs PostgreSQL de ne pas faire de modification sur les formats
   disque lors de mises à jour mineures fait qu'il est possible d'utiliser des
   serveurs primaire et d'attente fonctionnant à partir de niveaux de
   versions mineures différents. Néanmoins, aucun support formel n'est offert
   pour cela et vous êtes avertis de na pas autoriser ceco pendant de longues
   périodes.
  </para>

  <sect2 id="warm-standby-planning">
   <title>Planification</title>

   <para>
    Sur le serveur en attente, tous les espaces logiques et chemins référeront
    aux points de montage noméms de façon similaire. Il est donc important de
    créer les serveurs primaire et d'attente de façon identique, au moins
    en ce qui concerne le serveur de bases de données. De puis, tout commande
    CREATE TABLESPACE sera passée ainsi, donc tout nouveau point de montage
    doit être créé sur les deux serveurs avant de pouvoir être utilisé sur
    le serveur principal. Le matériel n'a pas besoin d'être identique mais
    l'expérience a montré que maintenir deux systèmes identiques est plus
    facile que maintenir deux systèmes différents sur la durée de vie
    des applications et du système.
   </para>

   <para>
    Il n'existe pas de mode spécial requis pour activer un serveur d'attente.
    Les opérations qui surviennent sur les serveurs principal et d'attente
    sont entièrement des tâches d'archivage et de récupération continues.
    Le point principal de contacte entre les deux serveurs de base est
    l'archive des fichiers WAL qu'ils partagent&nbsp;: le principal les
    écrit, le serveur en attente les lit. Il faut aussi s'assurer que les
    archives WAL de serveurs différents ne soient pas mélangées.
   </para>

   <para>
    Ce qui fait que les deux serveurs faiblement liés travaillent ensemble
    est simplement un <varname>restore_command</varname> qui attend l'archivage
    du prochain fichier WAL à partir du serveur principal.
    <varname>restore_command</varname> est indiqué
    dans le fichier <filename>recovery.conf</filename> du serveur en attente.
    Le traitement de la récupération normale demandera un fichier sur le serveur
    en attente, occasionnant une erreur si le fichier n'est pas disponible.
    Pour le traitement du serveur en attente, il est normal que le prochain
    fichier soit indisponible, donc nous devons être patient et attendre
    son arrivée. Un restore_command en attente peut être écrit avec un
    script personnalisé qui attend l'arrivée du prochain fichier WAL. Il
    doit aussi y avoir un moyen pour déclencher le
    <foreignphrase>failover</foreignphrase>, ce qui interrompra le
    restore_command, cassera la boucle et renverra une erreur de fichier
    non trouvé sur le serveur en attente. Puis, cela arrêtera la
    récupération et le serveur en attente deviendra un serveur normal.
   </para>

   <para>
    Un exemple de code pour une version C de <varname>restore_command</varname>
    serait&nbsp;:
<programlisting>triggered = false;
while (!NextWALFileReady() &amp;&amp; !triggered)
{
    sleep(100000L);         /* wait for ~0.1 sec */
    if (CheckForExternalTrigger())
        triggered = true;
}
if (!triggered)
        CopyWALFileForRecovery();
</programlisting>
   </para>

   <para>
    <productname>PostgreSQL</productname> ne fournit pas de logiciel requis pour
    identifier un échec sur le serveur principal et pour notifier le serveur en
    attente. De nombreux outils de ce type existent et sont bien intégrés avec
    d'autres aspects dun système en <foreignphrase>failover</foreignphrase>,
    comme la migration d'une adresse IP.
   </para>

   <para>
    Déclencher le <foreignphrase>failover</foreignphrase> est une partie
    importante de la planification et de la conception. <varname>restore_command</varname> est
    exécuté complètement une fois pour chaque fichier WAL. Le processus
    exécutant <varname>restore_command</varname> est du coup créé et meurt pour chaque fichier,
    donc il n'y a pas de démon ou de processus serveur. Du coup, nous ne
    pouvons pas utiliser les signaux et un gestionnaire de signal. Une
    notification plus permanente est requise pour déclencher l'opération
    de <foreignphrase>failover</foreignphrase>. Il est possible d'utiliser
    un simple délai, spécialement s'il est utilisé en conjonction avec un
    paramètre <varname>archive_timeout</varname> connu sur le principal. Ceci peut porter à erreur
    car un réseau ou un serveur principal occupé pourrait suffire à provoquer
    un <foreignphrase>failover</foreignphrase>. Un mécanisme de notificaton
    comme la création explicite d'un fichier déclencheur est moins sujet à
    l'erreur si cela peut être arrangé.
   </para>
  </sect2>

  <sect2 id="warm-standby-config">
   <title>Implémentation</title>

   <para>
    Une procédure courte pour configurer un serveur en attente suit. Pour
    des détails complets de chaque étape, référez-vous aux sections précédentes.
    <orderedlist>
     <listitem>
      <para>
       Configurer les serveurs principal et d'attente de façon quasi identique,
       ceci incluant deux copies identiques de <productname>PostgreSQL</productname>,
       avec la même version.
      </para>
     </listitem>
     <listitem>
      <para>
       Configurer l'archivage continue sur le principal vers une archive locale
       situé dansun répertoire sur le serveur d'attente. Assurez-vous que les deux
       paramètres <xref linkend="guc-archive-command"/> et <xref
       linkend="guc-archive-timeout"/> sont configurés (voir
       <xref linkend="backup-archiving-wal"/>)
      </para>
     </listitem>
     <listitem>
      <para>
       Faites une sauvegarde de base du serveur principal (voir <xref
       linkend="backup-base-backup"/>)
      </para>
     </listitem>
     <listitem>
      <para>
       Commencer la récupération sur le serveur en attente à partir de l'archive
       WAL locale en utilisant un fichier <filename>recovery.conf</filename>
       spécifiant un <varname>restore_command</varname> qui attend (voir
       <xref linkend="backup-pitr-recovery"/>).
      </para>
     </listitem>
    </orderedlist>
   </para>

   <para>
    La récupération traite l'archive WAL en lecture seule, donc une fois
    qu'un fichier WAL a été copié sur le système en attente, il peut être
    copié sur une cassette en même temps qu'il est utilisé par le système
    en attente pour la récupération. Du coup, exécuter un serveur en
    attente pour la haute disponibilité peut se réaliser au même temps
    que le stockage des fichiers à plus long terme en cas de récupération
    après un désastre.
   </para>

   <para>
    Dans un but de tests, il est possible d'exécuter les serveurs principal
    et d'attente sur le même système. Ceci ne fournit aucune amélioration
    sur la robustesse du système pas plus qu'il ne pourra être décrit comme
    de la haute disponibilité.
   </para>
  </sect2>

  <sect2 id="warm-standby-failover">
   <title>Failover</title>

   <para>
    Si le serveur principal a un problème, le serveur en attente doit commencer
    la procédure de <foreignphrase>failover</foreignphrase>.
   </para>

   <para>
    Si le serveur en attente échoue, alors aucun <foreignphrase>failover</foreignphrase>
    n'a pas besoin de prendre place. Si le serveur en attente peut être
    redémarré, même quelques temps après, alors le processus de récupération
    peut aussi être immédiatement relancé en prenant avantage du
    <foreignphrase>Restartable Recovery</foreignphrase>. Si le serveur en
    attente ne peut être redémarré, alors un nouveau serveur en attente
    devra être créé.
   </para>

   <para>
    Si le serveur principal échoue et est immédiatement redémarré, vous devez
    avoir un mécanisme l'informant qu'il n'est plus le serveur principal. Ceci
    est connu sous l'acronyme <acronym>STONITH</acronym> (<foreignphrase>Shoot
    the Other Node In The Head</foreignphrase>), qui est nécessaire pour éviter
    les situations où les deux systèmes pensent qu'ils sont le principal, ce
    qui peut amener une certaine confusion et des pertes de données.
   </para>

   <para>
    Un grand nombre de systèmes <foreignphrase>failover</foreignphrase>
    utilisent simplement deux systèmes, le principal et celui en attente,
    connectés par un mécanisme appelé heartbeat pour vérifier la connexion
    entre les deux et la viabilité du principal. Il est aussi possible
    d'utiliser un troisième système appelé serveur témoin pour éviter
    des problèmes de <foreignphrase>failover</foreignphrase> inapproprié
    mais la complexité supplémentaire pourrait être inutile sauf s'ils
    sont configurés avec suffisamment d'attention et testés rigoureusement.
   </para>

   <para>
    Au moment où le <foreignphrase>failover</foreignphrase> prend place sur le
    serveur en attente, nous avons seulement un serveur en opération. C'est
    connu sous le terme d'état dégénéré. L'ancien serveur en attente est
    devenu le serveur principal. L'ancien serveur principal est arrêté
    et pourrait le rester. 
    Nous devons maintenant recréer un serveur en attente, soit sur l'ancien
    système principal soit sur un troisième système. Une fois terminé,
    nous pouvons considérer avoir changer de serveur principal et de
    serveur d'attente. Certaines personnes choisissent un troisième serveur
    pour fournir une protection supplémentaire au travers de l'interval du
    <foreignphrase>failover</foreignphrase> bien que cela complique à coup
    sûr la configuration du système et les processus opérationnelles
    (et il peut aussi agir en tant que serveur témoin).
   </para>

   <para>
    Donc, basculer du principal ou serveur d'attente peut être rapide
    mais requiert du temps pour re-préparer le cluster en
    <foreignphrase>failover</foreignphrase>. Un basculement régulier entre
    le serveur principal et celui d'attente est encouragé bien que cela
    permette un arrêt habituel pour chaque système qui requiert un HA.
    Cela agit aussi en tant que test des mécanismes de
    <foreignphrase>failover</foreignphrase> pour s'assurer que cela
    fonctionnera toujours quand vous en aurez besoin.
   </para>
  </sect2>

  <sect2 id="warm-standby-record">
   <title>Implémenter le <foreignphrase>Record-based Log Shipping</foreignphrase></title>

   <para>
    Les principales fonctionnalités de <foreignphrase>Log Shipping</foreignphrase>
    dans cette version sont basées autour du <foreignphrase>Log Shipping</foreignphrase>.
    décrit ci -dessus. Ils est aussi possibles d'implémenter
    <foreignphrase>Log Shipping</foreignphrase> en utilisant la fonction
    <function>pg_xlogfile_name_offset()</function> (voir <xref
    linkend="functions-admin"/>), bien que ceci requiert un développement
    personnalisé.
   </para>

   <para>
    Un programme externe peut appeler <function>pg_xlogfile_name_offset()</function>
    pour trouver le nom du fichier et le décalage en octets du dernier pointeur WAL.
    Si le programme externe demande régulièrement au serveur, il peut savoir.
    Si le programme externe interroge souvent le serveur, elle peut trouver
    comment le pointeur a été déplacé&nbsp;; ensuite, il peut accéder au
    fichier WAL et copie ces octets. Il peut accèder aux fichiers qui a une copie
    pas mis à jour) sur un serveur en attente.
   </para>
  </sect2>
 </sect1>

 <sect1 id="migration">
  <title>Migration entre les différentes versions</title>

  <indexterm zone="migration">
   <primary>mise à jour</primary>
  </indexterm>

  <indexterm zone="migration">
   <primary>version</primary>
   <secondary>compatibilité</secondary>
  </indexterm>

  <para>
   Cette section discute de la façon de migrer vos données de la base à partir
   d'une version de <productname>PostgreSQL</productname> vers une autre, plus récente. La
   procédure d'installation du logiciel <foreignphrase>per se</foreignphrase> n'est pas le
   sujet de cette section&nbsp;; ces détails sont dans le <xref
   linkend="installation"/>.
  </para>

  <para>
   En règle générale, le format interne des données est modifié entre les 
   différentes versions de <productname>PostgreSQL</productname> (quand le nombre après le
   deuxième point change). Ceci ne s'applique pas entre les différentes sorties
   mineures ayant le même numéro de version majeur (quand le nombre après le
   deuxième point change)&nbsp;; elles ont toujours un format de stockage
   compatible.
   Par exemple, les versions 7.2.1, 7.3.2 et 7.4 ne sont pas compatibles, alors
   que les versions 7.2.1 et 7.2.2 le sont. Lorsque vous mettez à jour entre 
   des versions compatibles, vous pouvez simplement remplacer les exécutables et
   ré-utiliser le répertoire des données sur le disque. Sinon, vous avez besoin
   de sauvegarder vos données et de les restaurer sur le nouveau serveur. Ceci
   doit se faire en utilisant <application>pg_dump</application>&nbsp;; les méthodes de
   sauvegarde au niveau système de fichiers ne fonctionneront évidemment pas. Il
   existe des vérifications en place pour vous empêcher d'utiliser un répertoire
   de données d'une version incompatible version de
   <productname>PostgreSQL</productname>, donc aucun mal ne sera fait si vous
   essayez de lancer un serveur d'une mauvaise version dans un répertoire de
   données.
  </para>

  <para>
   Il est recommandé d'utiliser les programmes <application>pg_dump</application> et
   <application>pg_dumpall</application> à partir de la nouvelle version de
   <productname>PostgreSQL</productname>, pour utiliser les avantages de toutes
   améliorations effectuées sur ces programmes. Les versions actuelles des
   programmes de sauvegarde peuvent lire des données à partir des serveurs
   d'anciennes versions, jusqu'à la 7.0.
  </para>

  <para>
   Vous minimiserez la durée d'indisponibilité en installant le nouveau serveur
   dans un répertoire différent et en lançant l'ancien et le nouveau serveur en 
   parallèle sur des ports différents, puis en utilisant des commandes comme
 
<programlisting>pg_dumpall -p 5432 | psql -d postgres -p 6543</programlisting>

   pour transférer les données. Ou utilisez un fichier intermédiaire si vous
   voulez. Vous pouvez alors éteindre le nouveau serveur et démarrer le nouveau
   sur le port que l'ancien utilisait. Vous devez vous assurer que l'ancienne
   base de données n'est pas modifiée après que vous ayez lancé 
   <application>pg_dumpall</application>, sans quoi ces modifications seraient évidemment 
   perdues. Référez vous au <xref linkend="client-authentication"/> pour savoir 
   comment interdire l'accès.
  </para>
  
  <para>
   En pratique, vous voudrez certainement tester votre application sur le
   nouveau serveur avant de basculer définitivement. C'est une autre raison
   pour configurer des installations concurrentes avec l'ancienne et la nouvelle
   version.
  </para>

  <para>
   Si vous ne pouvez pas ou ne voulez pas lancer les deux serveurs en 
   parallèle, vous pouvez faire l'étape de sauvegarde avant d'installer la 
   nouvelle version, éteindre le serveur, déplacer l'ancienne version à un autre
   endroit, installer la nouvelle, la démarrer et enfin restaurer les données. Par
   exemple&nbsp;:
   
<programlisting>pg_dumpall &gt; sauvegarde.sql
pg_ctl stop
mv /usr/local/pgsql /usr/local/pgsql.old
cd ~/postgresql-&version;
gmake install
initdb -D /usr/local/pgsql/data
postgres -D /usr/local/pgsql/data
psql -f sauvegarde.sql postgres</programlisting>

   Vous trouverez les méthodes pour arrêter et démarrer les serveurs, ainsi que 
   d'autres détails dans le <xref linkend="runtime"/>.
   Les instructions d'installation vous donneront des conseils sur les endroits 
   stratégiques pour réaliser ces opérations.
  </para>

  <note>
   <para>
    Quand vous <quote>déplacez l'ancienne version à un autre endroit</quote>, 
    l'ancienne installation pourrait ne plus être tout à fait utilisable.
    Certains des exécutables contiennent les chemins absolus vers les
    différents programmes et fichiers de données installés. Ceci n'est
    habituellement pas un gros problème mais si vous planifiez d'utiliser deux
    installations en parallèle pendant un moment, vous devez leur affecter des
    répertoires d'installation différents au moment de la construction. (Ce
    problème est rectifié pour <productname>PostgreSQL</productname> 8.0 et ultérieurs mais
    vous devez faire bien attention à déplacer les anciennes installations.)
   </para>
  </note>
 </sect1>
</chapter>
