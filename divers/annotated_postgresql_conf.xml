<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
"http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd" >

<article id="postgresqlconf" lang="fr">
 <articleinfo>
  <title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
 </articleinfo>

<sect1>
<title>Connections and Authentication</title>

<sect2>
<title>Connection Settings</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>tcpip_socket</entry>
  <entry>true, false</entry>
  <entry>none</entry>
  <entry>false</entry>
  <entry>no</entry>
  <entry>-i</entry>
  <entry>
  If this is true, then the server will accept TCP/IP connections.
  Otherwise only local Unix domain socket connections are accepted.
  </entry>
  <entry>
  Unless this is a test-only server, you probably want to set this to true.
  Do so <emphasis>after</emphasis> configuring your pg_hba.conf file for secure
  access.
  </entry>
 </row>
 <row>
  <entry>port</entry>
  <entry>129 to 32768</entry>
  <entry>none</entry>
  <entry>5432</entry>
  <entry>No</entry>
  <entry>-p #</entry>
  <entry>
  The TCP port the server listens on.
  </entry>
  <entry>
  <para>
  Changing the PostgreSQL port can provide you weak protection against future
  database worms and script kiddies. However, you will need to remember to give
  port options on <emphasis>all</emphasis> connecting software and libraries,
  which can be a pain.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_connections</entry>
  <entry>2 to Int Max</entry>
  <entry>14k RAM</entry>
  <entry>32</entry>
  <entry>No</entry>
  <entry>-N</entry>
  <entry>
  Determines the maximum number of concurrent connections to the database
  server.
  The default is 32 (unless altered while building the
  server).
  </entry>
  <entry>
  An important setting. Keep it as low as possible for
  your application configuration; if you're running a web app with persistent
  connections, you may be able to lower it to 10-16.
  </entry>
 </row>
 <row>
  <entry>superuser_reserved_connections</entry>
  <entry>0 To max_connections - 1</entry>
  <entry>Reduces regular connections available</entry>
  <entry>2</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Determines the number of "connection slots" that are reserved for
  connections by PostgreSQL superusers. At most max_connections connections
  can ever be active simultaneously. Whenever the number of active
  concurrent connections is at least max_connections minus
  superuser_reserved_connections, new connections will be accepted only from
  superuser accounts.
  </entry>
  <entry>
  This is a new setting to protect superuser access
  in case of a maxed-out database. Do not set it to 0 unless you are very sure
  that connections to your database cannot be swamped. I generally set it to 1,
  as I only connect to the database as the superuser in the event of a problem.
  </entry>
 </row>
 <row>
  <entry>_socket_directory</entry>
  <entry></entry>
  <entry></entry>
  <entry>''</entry>
  <entry>No</entry>
  <entry>-k $</entry>
  <entry>
  Specifies the directory of the Unix-domain socket on which the server
  is to listen for connections from client applications.
  The default is normally /tmp but can be changed at build time.
  </entry>
  <entry>
  These options apply to UDP connections to the
  server, usually only used for a command-line connection from the console of
  the server machine. Since I usually disable UDP connections as insecure, I
  have no recommendations here.
  </entry>
 </row>
 <row>
  <entry>unix_socket_group</entry>
  <entry></entry>
  <entry></entry>
  <entry>''</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Sets the group owner of the Unix domain socket. (The owning user of the
  socket is always the user that starts the server.) In combination with
  the option UNIX_SOCKET_PERMISSIONS this can be used as an additional
  access control mechanism for this socket type. By default this is the
  empty string, which uses the default group for the current user.
  </entry>
 </row>
 <row>
  <entry>unix_socket_permissions</entry>
  <entry></entry>
  <entry></entry>
  <entry>0777</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  <para>Sets the access permissions of the Unix domain socket.
  Unix domain sockets use the usual Unix file system permission set. The option
  value is expected to be an numeric mode specification in the form accepted by
  the chmod and umask system calls. (To use the customary octal format the
  number must start with a 0 (zero).)</para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Security and Authentication</title>

<table>
<title>Security and Authentication (Annotated postgresql.conf and Global User Configuration (GUC) Guide)</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>authentication_timeout</entry>
  <entry>1-600 sec</entry>
  <entry></entry>
  <entry>60</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Maximum time to complete client authentication, in seconds. If a would-be
  client has not completed the authentication protocol in this much time,
  the server breaks the connection. This prevents hung clients from occupying
  a connection indefinitely. This option can only be
  set at server start or in the postgresql.conf file.
  </entry>
  <entry>
  </entry>
 </row>
 <row>
  <entry>ssl</entry>
  <entry>true, false</entry>
  <entry>See notes</entry>
  <entry>false</entry>
  <entry>No</entry>
  <entry>-l</entry>
  <entry>Enables SSL connections</entry>
  <entry>
  SSL encrypts traffic over TCP/IP port, so the data
  transferred cannot be read normally. Due to encryption process, it adds to
  CPU intensive load on both client and server. It could also increase the size
  of data transferred required. However, it can be tricky to configure and
  troubleshoot, and not all client software can support SSL access.
  </entry>
 </row>
 <row>
  <entry>krb_server_keyfile</entry>
  <entry></entry>
  <entry></entry>
  <entry>''</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Sets the location of the Kerberos server key file.
  </entry>
  <entry>
  Only used for Kerberos authentication of users.
  </entry>
 </row>
 <row>
  <entry>virtual_host</entry>
  <entry></entry>
  <entry></entry>
  <entry>''</entry>
  <entry>No</entry>
  <entry>-h x</entry>
  <entry>
  Specifies the TCP/IP host name or address on which the postmaster
  is to listen for connections from client applications. Defaults
  to listening on all configured addresses (including localhost).
  </entry>
  <entry>
  Essential for databases in a secure network with a DMZ, or where the
  database server has a public and a private TCP/IP address.
  </entry>
 </row>
 <row>
  <entry>db_user_namespace</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  This allows per-database user names. It is off by
  default.
  </entry>
  <entry>
  By default, users in PostgreSQL can connect to any
  database. This may not be an acceptable scenario in some cases. This option
  can be used in such cases. This feature is intended as a temporary measure
  until a complete solution is found. At that time, this option will be
  removed.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Resource Usage</title>

<sect2>
<title>Memory</title>

<note>
 <para>
  Please note: Raising many of these options will require you to set kernel
  options for your host operating system to the amount of memory allowed per
  process or per user. See the online documentation for suggested commands
  for various operating systems. Unless otherwise noted, all memory options
  are additive to determine the total memory used by PostgreSQL.
 </para>
</note>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>shared_buffers</entry>
  <entry>16 to Int Max</entry>
  <entry>8K RAM</entry>
  <entry>64</entry>
  <entry>No</entry>
  <entry>-B x</entry>
  <entry>
  Sets the number of shared memory buffers used by the database server.
  Minimum is 2 X max_connections.
  </entry>
  <entry>
  <para>
  Sets the size of PostgreSQL's memory buffer where queries are held before
  being fed into the Kernel buffer of the host system. It's very important
  to remember that this is only a holding area, and <emphasis>not</emphasis>
  the total memory available for the server. As such, resist the urge to
  set this number to a large portion of your RAM, as this will actually
  degrade performance on many operating systems. Members of the
  pgsql-performance mailing list have found useful values in the range of
  1000-6000, depending on available RAM, database size, and number of
  concurrent queries. For servers with very large amounts of available RAM
  (more than 1 GB) increasing this setting to 6-15% or available RAM has
  worked well for some users. The real analysis of the precise best setting
  is not fully understood and is more readily determined through testing than
  calculation.
  </para>
  <para>
  As a rule of thumb, observe shared memory usage of PostgreSQL with
  tools like ipcs and determine the setting. Remember that this is only half
  the story. You also need to set effective_cache_size so that postgreSQL will
  use available memory optimally.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  sort_mem
  </entry>
  <entry>64 to Int Max</entry>
  <entry>1 KB</entry>
  <entry>1024</entry>
  <entry>Yes</entry>
  <entry>-S #</entry>
  <entry>
  <para>
  Specifies the amount of memory to be used by internal sorts and hashes
  before switching to temporary disk files. The value is specified in
  kilobytes, and defaults to 1024 kilobytes (1 MB). Note that for a complex
  query, several sorts might be running in parallel, and each one will be
  allowed to use as much memory as this value specifies before it starts to
  put data into temporary files. Also, each running backend could be doing
  one or more sorts simultaneously, so the total memory used could be many
  times the value of SORT_MEM. Sorts are used by ORDER BY, merge joins, and
  CREATE INDEX.
  </para>
  <para>
  Command-line options require use of -o &#8220;option&#8221;.
  </para>
  </entry>
  <entry>
  <para>
  Sort_mem is much more difficult to set. Adjust it upwards for: large
  databases, complex queries, lots of available RAM. Adjust it downwards for:
  low available RAM, or many concurrent users. Finding the right balance spot
  can be hard.
  </para>
  <para>
  Another way to set this value is to monitor the PostgreSQL temp files
  (in PGDATA/base/DB_OID/pgsql_tmp) and adjust sort_mem upward if you see a
  lot of queries swapping from these temp files.
  </para>
  <para>
  Also keep in mind that this parameter can be adjusted per connection. So if
  you only have a few really large processes, you can increase the sort_mem
  for them before query execution, and leave it low for the rest of the
  connections.
  </para>
  </entry>
 </row>
 <row>
  <entry>vacuum_mem</entry>
  <entry>1024 to Int Max</entry>
  <entry>1 KB</entry>
  <entry>8192</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Specifies the maximum amount of memory to be used
  by VACUUM to keep track of to-be-reclaimed tuples. The value is specified in
  kilobytes, and defaults to 8192 kilobytes. Larger settings may improve the
  speed of vacuuming large tables that have many deleted tuples.
  </entry>
  <entry>
  <para>
  As this setting only uses RAM when VACUUM is running, you may wish to increase
  it on high-RAM machines to make VACUUM run faster (but never more than 20% of
  available RAM!)
  </para>
  <para>
  Further, this setting can be SET at runtime, so a good approach is often to
  set it low for the frequent regular VACUUMs, and set it high for the
  nightly/weekly/periodic VACUUM FULL.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Free Space Map</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_fsm_pages</entry>
  <entry>1000 to Int Max</entry>
  <entry>6 bytes RAM</entry>
  <entry>10000</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Sets the maximum number of disk pages for which free space will be
  tracked in the shared free-space map.
  The default is 10000. This option can only be set
  at server start.
  </entry>
  <entry>
  <para>
  A proper FSM setting can eliminate or at least postpone your need to run
  VACUUM FULL. The best way to set
  it is as follows: 1) figure out the VACUUM (regular) frequency of your
  database based on write activity; 2) run the database under normal production
  load, and run VACUUM VERBOSE ANALYZE instead of VACUUM, saving the output to
  a file; 3) calculate the maximum total number of pages reclaimed between
  VACUUMs based on the output, and use that.
  </para>
  <para>
  If the above approach is impractical, try to estimate the total
  number of rows which are likely to be updated or deleted between
  VACUUMs, and use half of that number, increasing it based on the
  amount of work your periodic VACUUM FULL is still doing.
  </para>
  <para>
  Please note that databases with high &#8220;peak&#8221; activity
  (bursts of 1 million updates but nothing else for minutes or
  hours) this number can be impossible to tune perfectly. Inserted
  rows are not significant for FSM. Finally, if your database server
  is short on RAM, increasing FSM to needed values may be
  counter-productive.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_fsm_relations</entry>
  <entry>10 to Int Max</entry>
  <entry>40 bytes RAM</entry>
  <entry>100</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Sets the maximum number of relations (tables) for which free space will be
  tracked in the shared free-space map.
  </entry>
  <entry>
  You definitely want to increase this to cover the
  expected number of tables in all databases ... say, 300 to 500. PostgreSQL
  develops odd performance quirks if it is does not have enough FSM_relations.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Disk Resource Usage</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_files_per_process</entry>
  <entry>25 to Int Max</entry>
  <entry></entry>
  <entry>1000</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Sets the maximum number of simultaneously open files
  in each server subprocess. The default is 1000. The limit actually used by the
  code is the smaller of this setting and the result of sysconf(_SC_OPEN_MAX).
  Therefore, on systems where sysconf returns a reasonable limit, you don't need
  to worry about this setting. But on some platforms (notably, most BSD
  systems), sysconf returns a value that is much larger than the system can
  really support when a large number of processes all try to open that many
  files. If you find yourself seeing "Too many open files" failures, try
  reducing this setting. This option can only be set at server start or in the
  postgresql.conf configuration file; if changed in the configuration file, it
  only affects subsequently-started server subprocesses.
  </entry>
  <entry>
  Per the docs, mainly used for BSD. Don't bother with it unless you get
  a &#8220;too many files&#8221; message.
  </entry>
 </row>
 <row>
  <entry>preload_libraries</entry>
  <entry>File path</entry>
  <entry>See notes</entry>
  <entry>Empty</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  This variable specifies one or more shared libraries
  that are to be preloaded at server start. An initialization function can also
  be optionally specified by adding a colon followed by the name of the
  initialization function after the library name. For example
  '$libdir/mylib:init_mylib' would cause mylib to be preloaded and init_mylib
  to be executed. If more than one library is to be loaded, they must be
  delimited with a comma. If mylib is not found, the server will fail to start.
  However, if init_mylib is not found, mylib will still be preloaded without
  executing the initialization function.
  </entry>
  <entry>
  By preloading a shared library (and initializing
  it if applicable), the library startup time is avoided when the library is
  first used. This effectively trades longer startup times for shorter delays
  calling libraries not in memory.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>WAL Options</title>

<sect2>
<title>Settings</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>fsync</entry>
  <entry>true, false</entry>
  <entry>See notes</entry>
  <entry>true</entry>
  <entry>No</entry>
  <entry>-F (off)</entry>
  <entry>
  If this option is on, the PostgreSQL backend will use the fsync() system
  call in several places to make sure that updates are physically written to
  disk. This insures that a database installation will recover to a consistent
  state after an operating system or hardware crash. (Crashes of the database
  server itself are not related to this.)
  </entry>
  <entry>
  <note>
  <para>
  Since 7.2, turning fsync off does <emphasis>NOT</emphasis> stop WAL. It does
  stop checkpointing, however. This is a change in the notes that follow. Turn
  WAL off (fsync=false) only for a read-only database or one where the database
  can be regenerated from external software. While RAID plus UPSes can do a lot
  to protect your data, turning off fsync means that you <emphasis>will</emphasis>
  be restoring from backup in the event of hardware or power failure.
  </para>
  </note>
  <para>
  On the other hand, WAL imposes significant penalties on database writes,
  especially in single-disk systems. Essentially you are doubling the amount of
  read/write activity required for each update, plus requiring you to disable
  performance-enhancing disk-caching features of your OS and hardware.
  </para>
  <para>
  If WAL is off, the rest of the options in this section are irrelevant.
  </para>
  </entry>
 </row>
 <row>
  <entry>wal_sync_method</entry>
  <entry>fsync, fdatasync, open_sync, or open_datasync</entry>
  <entry></entry>
  <entry>Varies by platform</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Method used for forcing WAL updates out to disk. Possible values are
  FSYNC (call fsync() at each commit), FDATASYNC (call fdatasync() at
  each commit), OPEN_SYNC (write WAL files with open() option O_SYNC),
  or OPEN_DATASYNC (write WAL files with open() option O_DSYNC). Not
  all of these choices are available on all platforms.
  </entry>
  <entry>
  The system call used to sync the WAL to disk. Defaults have been
  set for each OS based on OS documentation, but no in-depth
  comparative tests have been posted. It's possible that changing the
  method could improve write speed on your platform, but don't monkey
  with it unless you have the time and resources to run comparative
  and failure tests. If you change the defaults, WAL may not protect
  you adequately.
  </entry>
 </row>
 <row>
  <entry>wal_buffers</entry>
  <entry>4 to Int Max</entry>
  <entry>8K RAM</entry>
  <entry>8</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Number of disk-page buffers in shared memory for WAL logging.
  </entry>
  <entry>
  Raising this setting can improve the speed of WAL writes for large
  transactions. To date, no one has posted an analysis of the impact
  of this setting.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Checkpoints</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>checkpoint_segments</entry>
  <entry>1 to Int Max</entry>
  <entry>16 MB on disk</entry>
  <entry>3</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Maximum distance between automatic WAL checkpoints, in log file segments
  (each segment is normally 16 megabytes).
  </entry>
  <entry>
  Increase these settings if your database has lots of large batch writes to
  decrease the frequency of checkpoints (and thus lower disk activity).
  Decrease them if you are short on disk space or your environment has a
  significant risk of unexpected power-outs, as any un-checkpointed
  transactions will dropped on restart.
  </entry>
 </row>
 <row>
  <entry>checkpoint_timeout</entry>
  <entry>30 to 3600</entry>
  <entry>See notes</entry>
  <entry>300</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Maximum time between automatic WAL checkpoints, in seconds.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>checkpoint_warning</entry>
  <entry>0 to Int Max</entry>
  <entry>See notes</entry>
  <entry>0</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Send a message to the server logs if checkpoints caused by the filling of
  checkpoint segment files happens more frequently than this number of
  seconds. Zero turns off the warning.
  </entry>
  <entry>
  A new option which should be quite useful for tuning checkpoint_segments
  heavy write activity databases. If you see this message often and
  regularly, you should consider increasing checkpoint_segments.
  </entry>
 </row>
 <row>
  <entry>commit_delay</entry>
  <entry>0-100000</entry>
  <entry>See notes</entry>
  <entry>0</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Time delay between writing a commit record to the WAL buffer and flushing the
  buffer out to disk, in microseconds. A nonzero delay allows multiple
  transactions to be committed with only one fsync system call, if system load
  is high enough additional transactions may become ready to commit within the
  given interval. But the delay is just wasted if no other transactions become
  ready to commit. Therefore, the delay is only performed if at least
  COMMIT_SIBLINGS other transactions are active at the instant that a backend
  process has written its commit record.
  </entry>
  <entry>
  These two settings are configured together for an environment with a high
  volume of small transactions. When set, they allow a group of otherwise
  unrelated transactions to be flushed to disk at the same time, with possible
  significant performance gain. Don't consider it, though, if you are short on
  disk space or in an unstable-power environment.
  </entry>
 </row>
 <row>
  <entry>commit_siblings</entry>
  <entry>1-1000</entry>
  <entry>See notes</entry>
  <entry>5</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Minimum number of concurrent open transactions to require before performing
  the COMMIT_DELAY delay. A larger value makes it more probable that at least
  one other transaction will become ready to commit during the delay interval.
  </entry>
  <entry>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Query Tuning</title>

<sect2>
<title>Planner Methods</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para><emphasis>enable_hashagg</emphasis></para>
  <para>enable_hashjoin</para>
  <para>enable_indexscan</para>
  <para>enable_mergejoin</para>
  <para>enable_nestloop</para>
  <para>enable_seqscan</para>
  <para>enable_sort</para>
  <para>enable_tidscan</para>
  </entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>true</entry>
  <entry>Yes</entry>
  <entry>
  <para></para>
  <para>-fi</para>
  <para>-fm</para>
  <para>-fn</para>
  <para>-fs</para>
  <para></para>
  <para>-ft*</para>
  <para></para>
  </entry>
  <entry>
  <para>
  Enables or disables the query planner's use of the respective plan types.
  The default is on. This is used for debugging the query planner.
  </para>
  <para>
  Command-line options require use of -o &#8220;option&#8221;.
  </para>
  </entry>
  <entry>
  <para>
  These options are pretty much only for use in query testing; frequently one
  sets &#8220;enable_seqscan = false&#8221; in order to determine if the
  planner is unnecessarily discarding an index, for example. However,
  it would require very unusual circumstances to change any of them to false in
  the .conf file.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Planner Cost Constants</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>effective_cache_size</entry>
  <entry>0 to Int Max</entry>
  <entry>8 KB</entry>
  <entry>1000</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the optimizer's assumption about the effective size of the disk cache
  (that is, the portion of the kernel's disk cache that will be used for
  PostgreSQL data files). This is measured in disk pages, which are normally
  8 kB each.
  </entry>
  <entry>
  An oft-overlooked setting that can result in better use of RAM on high-memory
  computers if raised to a correct level. I use 25% of my &#8220;available
  RAM&#8221; (after Linux and applications) as a general level, but have not
  tested extensively. Please note that if this setting is tuned, one need not
  increase shared_buffers unnecessarily.
  </entry>
 </row>
 <row>
  <entry>
  <para>random_page_cost</para>
  <para>cpu_tuple_cost</para>
  <para>cpu_index_tuple_cost</para>
  <para>cpu_operator_cost</para>
  </entry>
  <entry>0 to Double</entry>
  <entry>
  <para></para>
  <para>0.01</para>
  <para>0.001</para>
  <para>0.0025</para>
  </entry>
  <entry>4</entry>
  <entry>
  </entry>
  <entry>Yes</entry>
  <entry>
  Sets the query optimizer's estimate of the cost of processing each page
  lookup, tuple, index lookup, and where clause item (respectively) during a
  query. This is measured as a fraction of the cost of a sequential page
  fetch.
  </entry>
  <entry>
  The default costs are based entirely on anecdotal experience, and are
  probably not ideal for your system. For example, machines with very fast
  seeking disk arrays should probably lower the random_page_cost. Remember,
  though, that when testing values for these settings you need to test a
  variety of queries, as the right setting for one kind of query can hurt
  another. Fortunately, since these settings are all relative to the cost of a
  sequential fetch, they are unlikely to be too far off in a balanced system.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Genetic Estimate Query Optimizer</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>geqo</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>true</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  Enables or disables genetic query optimization, which is an algorithm that
  attempts to do query planning without exhaustive searching. This is on by
  default. See also the various other GEQO_ settings.
  </entry>
  <entry>
  <para>
  GEQO was introduced in PostgreSQL 6.5 as a way of dealing with join
  optimization queries with too many tables for an exhaustive analysis by the
  planner. It was quite revolutionary at the time, but was never fully
  optimized, and has been relatively indifferently maintained since then. Since
  new, faster CPUs and more, faster RAM has made exhaustive query planning more
  affordable, I raise the GEQO threshold, usually to 20-25 tables. This
  prevents GEQO from being used except in the situations where it is really the
  only option. Of course, if you are running PostgreSQL on a machine with
  limited (available) CPU power, you may want to use a lower GEQO threshold
  than that.
  </para>
  <para>
  If you are certain that you will never have a query that complex, you can
  just turn it off.
  </para>
  </entry>
 </row>
 <row>
  <entry>geqo_threshold</entry>
  <entry>2 to Int Max</entry>
  <entry></entry>
  <entry>11</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  Use genetic query optimization to plan queries with at least this many FROM
  items involved. (Note that a JOIN construct counts as only one FROM item.)
  The default is 11. For simpler queries it is usually best to use the
  deterministic, exhaustive planner. This parameter also controls how hard
  the optimizer will try to merge subquery FROM clauses into the upper query.
  </entry>
 </row>
 <row>
  <entry>
  <para>geqo_selection_bias</para>
  <para>geqo_pool_size</para>
  <para>geqo_effort</para>
  <para>geqo_generations</para>
  <para>geqo_random_seed</para>
  </entry>
  <entry>1.5-2.0</entry>
  <entry></entry>
  <entry>
  <para>2.0</para>
  <para>0</para>
  <para>1</para>
  <para>0</para>
  <para>-1</para>
  </entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  Various tuning parameters for the genetic query optimization algorithm: The
  pool size is the number of individuals in one population. Valid values are
  between 128 and 1024. If it is set to 0 (the default) a pool size of
  2^(QS+1), where QS is the number of FROM items in the query, is taken. The
  effort is used to calculate a default for generations. Valid values are
  between 1 and 80, 40 being the default. Generations specifies the number of
  iterations in the algorithm. The number must be a positive integer. If 0 is
  specified then Effort * Log2(PoolSize) is used. The run time of the algorithm
  is roughly proportional to the sum of pool size and generations. The
  selection bias is the selective pressure within the population. Values can be
  from 1.50 to 2.00; the latter is the default. The random seed can be set to
  get reproducible results from the algorithm. If it is set to -1 then the
  algorithm behaves non-deterministically.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Query and Index Statistics</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>stats_start_collector</para>
  <para>stats_reset_on_server_start</para>
  <para>stats_command_string</para>
  <para>stats_row_level</para>
  <para>stats_block_level</para>
  </entry>
  <entry>true, false</entry>
  <entry>
  <para>true</para>
  <para>true</para>
  <para>false</para>
  <para>false</para>
  <para>false</para>
  </entry>
  <entry></entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  These flags determine what information backends send to the statistics
  collector process: current commands, block-level activity statistics, or
  row-level activity statistics. All default to off. Enabling statistics
  collection costs a small amount of time per query, but is invaluable for
  debugging and performance tuning.
  </entry>
  <entry>
  Eventually I will have an article on Techdocs explaining how to use the
  query statistics to tune your use of indexes. These are particularly useful
  for a &#8220;deductive&#8221; approach to indexing, where you index
  everything and then drop the indexes which are not used.
  </entry>
 </row>
 <row>
  <entry>default_statistics_target</entry>
  <entry>1 -1000</entry>
  <entry></entry>
  <entry>10</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the default statistics target for table columns that have not had a
  column-specific target set via ALTER TABLE SET STATISTICS. Larger values
  increase the time needed to do ANALYZE, but may improve the quality of the
  planner's estimates.
  </entry>
  <entry>
  It can be useful to raise this target if your main tables all have very
  uneven distribution in often-queried columns. Raising it does make ANALYZE
  take longer.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Query Modifiers</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>explain_pretty_print</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Determines whether EXPLAIN VERBOSE uses the indented or non-indented format
  for displaying detailed query-tree dumps.
  </entry>
  <entry>
  Try it and see. The extra formatting is useful for some people, but not for
  everyone.
  </entry>
 </row>
 <row>
  <entry>from_collapse_limit</entry>
  <entry>0 to Int Max</entry>
  <entry></entry>
  <entry>8</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  The planner will merge sub-queries into upper queries if the resulting FROM
  list would have no more than this many items. Smaller values reduce planning
  time but may yield inferior query plans. The default is 8. It is usually
  wise to keep this less than GEQO_THRESHOLD.
  </entry>
  <entry>
  </entry>
 </row>
 <row>
  <entry>join_collapse_limit</entry>
  <entry>1 to Int Max</entry>
  <entry></entry>
  <entry>8</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  The planner will flatten explicit inner JOIN constructs into lists of FROM
  items whenever a list of no more than this many items would result. Usually
  this is set the same as FROM_COLLAPSE_LIMIT. Setting it to 1 prevents any
  flattening of inner JOINs, allowing explicit JOIN syntax to be used to
  control the join order. Intermediate values might be useful to trade off
  planning time against quality of plan.
  </entry>
  <entry>
  This option is designed for those of us who like writing our queries using
  explicit JOIN syntax (e.g. &#8220;a join b using (1) join c using (2)&#8221;),
  but would still like the planner to select the join order for best execution.
  Particularly, people switching from MS SQL Server will want to enable this
  option with a moderately high value, as that database does JOIN collapsing
  automatically.
  </entry>
 </row>
 <row>
  <entry>max_expr_depth</entry>
  <entry>10 to Int Max</entry>
  <entry></entry>
  <entry>10000</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the maximum expression nesting depth of the parser. The default value
  is high enough for any normal query, but you can raise it if needed. (But if
  you raise it too high, you run the risk of backend crashes due to stack
  overflow.)
  </entry>
  <entry>
  I cannot imagine anyone needing to raise this.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Logging and Messaging Options</title>

<sect2>
<title>Syslog</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>syslog</para>
  <para>syslog_facility</para>
  <para>syslog_ident</para>
  </entry>
  <entry>0-2</entry>
  <entry>
  <para>0</para>
  <para>LOCAL0</para>
  <para>postgres</para>
  </entry>
  <entry></entry>
  <entry></entry>
  <entry>No</entry>
  <entry>
  PostgreSQL allows the use of syslog for logging. If this option is set to
  1, messages go both to syslog and the standard output. A setting of 2 sends
  output only to syslog. (Some messages will still go to the standard
  output/error.) The default is 0, which means syslog is off. This option must
  be set at server start.
  </entry>
  <entry>
  Very useful if you have syslog management tools of some sort. Otherwise can
  make it difficult to separate PostgreSQL output from numerous other
  processes.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>When to Log/Message</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>server_min_messages</para>
  <para>client_min_messages</para>
  <para>log_min_error_statement</para>
  </entry>
  <entry>
  debug5, debug4, debug3, debug2, debug1,
  info, notice, warning, error, log, fatal, panic
  </entry>
  <entry></entry>
  <entry>notice</entry>
  <entry>Yes</entry>
  <entry>-d x</entry>
  <entry>
  This controls how much message detail is written to the server logs. Valid
  values are DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO, NOTICE, WARNING,
  ERROR, LOG, FATAL, and PANIC. Later values send less detail to the logs. The
  default is NOTICE. Note that LOG has a different precedence here than in
  CLIENT_MIN_MESSAGES.
  </entry>
  <entry>
  Raising debug levels is always good for testing applications. The cost is
  greater use of disk space, some minor performance cost for output (usually
  &lt; 5%). However, the performance cost increases significantly if your logs
  are on the same disk/array as WAL or your database, as heavy debug output
  will take I/O away from database activity. The impact of debug5 on a
  high-transaction single-disk system can be quite high. This caution applies
  to all of the logging options below.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>What to Log</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>debug_print_parse</para>
  <para>debug_print_rewritten</para>
  <para>debug_print_plan</para>
  <para>debug_pretty_print</para>
  </entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  These flags enable various debugging output to be sent to the server log. For
  each executed query, print either the query text, the resulting parse tree,
  the query rewriter output, or the execution plan. DEBUG_PRETTY_PRINT indents
  these displays to produce a more readable but much longer output format.
  </entry>
  <entry>
  Can be useful for detecting common slow queries if you are able to wade
  through the voluminous log output. Particularly useful in interactive log
  watching when procedures hang; you can sometimes see exactly what step
  hangs (sometimes you can't, though, because the log waits on the database).
  </entry>
 </row>
 <row>
  <entry>
  <para>log_connections</para>
  <para>log_pid</para>
  <para>log_statement</para>
  <para>log_duration</para>
  <para>log_timestamp</para>
  </entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>
  <para>No</para>
  <para>No</para>
  <para>Yes</para>
  <para>Yes</para>
  <para>Yes</para>
  </entry>
  <entry></entry>
  <entry>
  Logs respective items.
  </entry>
  <entry>
  <para>
  All can be useful depending on what problems you are expecting. I generally
  leave log_timestamp on and the others off.
  </para>
  <note>
  <para>
  A patch was proposed which would allow users to turn logging options on, but
  only the superuser would be able to turn them off. I don't know whether this
  patch will make it into 7.4 or not.
  </para>
  </note>
  </entry>
 </row>
 <row>
  <entry>
  log_hostname
  </entry>
  <entry>true, false</entry>
  <entry>See notes</entry>
  <entry>false</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  By default, connection logs only show the IP address of the connecting host.
  If you want it to show the host name you can turn this on, but depending on
  your host name resolution setup it might impose a non-negligible performance
  penalty.
  </entry>
  <entry>
  This can be useful for debugging/security management, but if DNS is not local
  can delay new connections significantly.
  </entry>
 </row>
 <row>
  <entry>
  log_source_port
  </entry>
  <entry>true, false</entry>
  <entry>See notes</entry>
  <entry>false</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  Shows the outgoing port number of the connecting host in the connection log
  messages. You could trace back the port number to find out what user initiated
  the connection. Other than that, it's pretty useless and therefore off by
  default.
  </entry>
  <entry>
  Imposes a significant but unmeasured performance penalty due to lookup as
  well as extra logging activity.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Statistics Logging</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>show_parser_stats</para>
          <para>show_planner_stats</para>
          <para>show_executor_stats</para>
          <para>show_statement_stats</para>
          <para>log_parser_stats</para>
	  <para>log_planner_stats</para>
          <para>log_executor_stats</para>
          <para>log_statement_stats</para>
  </entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>No*</entry>
  <entry>
  <para>-tpa</para>
  <para>-tpl</para>
  <para>-te</para>
  <para>-s</para>
  </entry>
  <entry>
  <para>
  For each query, write performance statistics of the respective module to
  the server log. This is a crude profiling instrument.
  </para>
  <para>
  Command-line options require use of -o &#8220;option&#8221;.
  </para>
  </entry>
  <entry>
  May be SET by superuser.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Client Connection Defaults</title>

<sect2>
<title>Statement Behavior</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>search_path</entry>
  <entry>path</entry>
  <entry>None</entry>
  <entry>'$user,public'</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  This variable specifies the order in which schemas are searched when an
  object (table, data type, function, etc.) is referenced by a simple name
  with no schema component. When there are objects of identical names in
  different schemas, the one found first in the search path is used. An object
  that is not in any of the schemas in the search path can only be referenced
  by specifying its containing schema with a qualified (dotted) name.
  </entry>
  <entry>
  If your application makes heavy use of schema, you can reverse this search
  path to make sure that public objects will override user-schema objects with
  the same name. Otherwise, leave it alone.
  </entry>
 </row>
 <row>
  <entry>default_transaction_isolation</entry>
  <entry>read committed, serializable</entry>
  <entry>See Note</entry>
  <entry>'read committed'</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Each SQL transaction has an isolation level, which can be either "read
  committed" or "serializable". This parameter controls the default isolation
  level of each new transaction. Consult the PostgreSQL User's Guide and the
  command SET TRANSACTION for more information.
  </entry>
  <entry>
  The default, here, is the value that supports standard MVCC behavior.
  &#8220;Serializable&#8221; is mainly useful for when you need to launch
  long-running procedures which must be successive, or when your updates pose a
  significant and regular risk of deadlock. Under a heavy multi-user load,
  setting &#8220;serializable&#8221; can impose a significant penalty as
  numerous transactions are forced to wait for the serialized transaction to
  complete. In a single-concurrent-user database, there should be little
  effect.
  </entry>
 </row>
 <row>
  <entry>default_transaction_read_only</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  A read-only SQL transaction cannot alter non-temporary tables. This parameter
  controls the default read-only status of each new transaction. The default is
  false (read/write).
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>statement_timeout</entry>
  <entry>0 to Int Max</entry>
  <entry>See Note</entry>
  <entry>0</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Aborts any statement that takes over the specified number of milliseconds.
  A value of zero turns off the timer.
  </entry>
  <entry>
  Designed to help the application where it is possible to users to execute
  queries that swamp the CPU for minutes, such as apps that allow dynamic
  queries. Setting this value to a finite amount can prevent those users from
  monopolizing resources, but you'll need to be prepared to deal with the
  exception.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Locale and Formatting</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>datestyle</para>
  <para>timezone</para>
  <para>australian_timezones</para>
  </entry>
  <entry></entry>
  <entry>None</entry>
  <entry>
  <para>'iso, us'</para>
  <para>unknown</para>
  <para>false</para>
  </entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  <para>
  Sets the display format for dates, as well as the rules for interpreting
  ambiguous input dates.
  </para>
  <para>
  Sets the time zone for displaying and interpreting timestamps. The default
  is to use whatever the system environment specifies as the time zone.
  </para>
  <para>
  If set to true, CST, EST, and SAT are interpreted as Australian time zones
  rather than as North American Central/Eastern time zones and Saturday.
  </para>
  </entry>
  <entry>
  For changing the default display of dates and interpretation of timezones to
  suit your locality and/or organization standards.
  </entry>
 </row>
 <row>
  <entry>extra_float_digits</entry>
  <entry>-14 to 2</entry>
  <entry>None</entry>
  <entry>0</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  This parameter adjusts the number of digits displayed for floating-point
  values, including float4, float8, and geometric data types. The parameter
  value is added to the standard number of digits (FLT_DIG or DBL_DIG as
  appropriate). The value can be set as high as 2, to include
  partially-significant digits; this is especially useful for dumping float
  data that needs to be restored exactly. Or it can be set negative to suppress
  unwanted digits.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>
  <para>lc_messages</para>
  <para>lc_monetary</para>
  <para>lc_time</para>
  <para>lc_numeric</para>
  </entry>
  <entry>System-dependent</entry>
  <entry>None</entry>
  <entry>Special</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the locale to use for formatting error messages, monetary amounts, time
  and numeric values. Acceptable values are system-dependent; see Section 7.1
  for more information. If this variable is set to the empty string (which is
  the default) then the value is inherited from the execution environment of
  the server in a system-dependent way.
  </entry>
  <entry>
  These settings are set by the initdb script when it creates your PGDATA
  directory. Should be set to your language, currency, etc.
  </entry>
 </row>
 <row>
  <entry>client_encoding</entry>
  <entry>OS-dependent</entry>
  <entry>None</entry>
  <entry>sql_ascii</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the client-side encoding for multi-byte character sets. The default is
  to use the database encoding.
  </entry>
  <entry>
  Usually ignored in favor of database encoding. Would be set per client only
  for multi-lingual applications, which would then require considerable care to
  manage the different encodings.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Defaults</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>password_encryption</entry>
  <entry>true, false</entry>
  <entry>None</entry>
  <entry>true</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  When a password is specified in CREATE USER or ALTER USER without writing
  either ENCRYPTED or UNENCRYPTED, this flag determines whether the password
  is to be encrypted.
  </entry>
  <entry>
  Should remain set to true, for all practical purposes.
  </entry>
 </row>
 <row>
  <entry>dynamic_library_path</entry>
  <entry>path</entry>
  <entry>None</entry>
  <entry>'$libdir'</entry>
  <entry>No*</entry>
  <entry></entry>
  <entry>
  If a dynamically loadable module needs to be opened and the specified name
  does not have a directory component (i.e. the name does not contain a slash),
  the system will search this path for the specified file. (The name that is
  used is the name specified in the CREATE FUNCTION or LOAD command.)
  </entry>
  <entry>
  Can be SET by superuser.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Lock Management</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>deadlock_timeout</entry>
  <entry>1 to Int Max</entry>
  <entry>See Note</entry>
  <entry>1000</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  This is the amount of time, in milliseconds, to wait on a lock before
  checking to see if there is a deadlock condition. The check for deadlock is
  relatively slow, so the server doesn't run it every time it waits for a lock.
  We (optimistically?) assume that deadlocks are not common in production
  applications and just wait on the lock for a while before starting check for
  a deadlock. Increasing this value reduces the amount of time wasted in
  needless deadlock checks, but slows down reporting of real deadlock errors.
  The default is 1000 (i.e., one second), which is probably about the smallest
  value you would want in practice. On a heavily loaded server you might want
  to raise it. Ideally the setting should exceed your typical transaction time,
  so as to improve the odds that the lock will be released before the waiter
  decides to check for deadlock.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>max_locks_per_transaction</entry>
  <entry>10 to Int Max</entry>
  <entry></entry>
  <entry>64</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  The shared lock table is sized on the assumption that at most
  max_locks_per_transaction * max_connections distinct objects will need to be
  locked at any one time. The default, 64, which has historically proven
  sufficient, but you might need to raise this value if you have clients that
  touch many different tables in a single transaction. This option can only be
  set at server start.
  </entry>
  <entry></entry>
 </row>
</tbody>
</tgroup>
</table>

</sect1>

<sect1>
<title>Version and Platform Compatibility</title>

<sect2>
<title>Previous PostgreSQL Versions</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>add_missing_from</entry>
  <entry>true, false</entry>
  <entry>None</entry>
  <entry>true</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Enables planner to &#8220;Add Missing From Clause&#8221; when you omit a
  table from your query. Will be false by default in future versions.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>regex_flavor</entry>
  <entry>advanced, extended, basic</entry>
  <entry>None</entry>
  <entry>advanced</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  The regular expression "flavor" can be set to advanced, extended, or basic.
  The usual default is advanced. The extended setting may be useful for exact
  backwards compatibility with pre-7.4 releases of PostgreSQL.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>sql_inheritance</entry>
  <entry>true, false</entry>
  <entry>None</entry>
  <entry>true</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  This controls the inheritance semantics, in particular whether subtables are
  included by various commands by default. They were not included in versions
  prior to 7.1. If you need the old behavior you can set this variable to off,
  but in the long run you are encouraged to change your applications to use the
  ONLY keyword to exclude subtables.
  </entry>
  <entry></entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Platform and Client Compatibility</title>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>transform_null_equals</entry>
  <entry>true, false</entry>
  <entry>None</entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  When turned on, expressions of the form expr = NULL (or NULL = expr) are
  treated as expr IS NULL, that is, they return true if expr evaluates to the
  null value, and false otherwise. The correct behavior of expr = NULL is to
  always return null (unknown).
  </entry>
  <entry></entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Source Developer Options</title>

<note>
<para>
These options have been dropped from postgresql.conf in 7.4 because there are
not useful user options, but instead are aimed at source developers. Most DBAs
should have no reason to modify them.
</para>
</note>

<table>
<title>Annotated postgresql.conf and Global User Configuration (GUC) Guide</title>
<tgroup cols="8" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Resources</entry>
  <entry>Default</entry>
  <entry>SET</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>wal_debug</entry>
  <entry>0-16</entry>
  <entry></entry>
  <entry>0</entry>
  <entry>No*</entry>
  <entry></entry>
  <entry>
  If nonzero, turn on WAL-related debugging output on standard error.
  </entry>
  <entry>
  May be SET by superuser.
  </entry>
 </row>
 <row>
  <entry>trace_notify</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Generates a great amount of debugging output for the LISTEN and NOTIFY
  commands.
  </entry>
  <entry>
  </entry>
 </row>
 <row>
  <entry>
  <para>trace_locks</para>
  <para>trace_userlocks</para>
  <para>trace_lwlocks</para>
  <para>debug_deadlocks</para>
  <para>trace_lock_oidmin</para>
  <para>trace_lock_table</para>
  <para>log_btree_build_stats</para>
  </entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>
  <para>false</para>
  <para>false</para>
  <para>false</para>
  <para>false</para>
  <para>16384</para>
  <para>0</para>
  <para>false</para>
  </entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  No documentation is available for these options at this time.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>debug_assertions</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>true</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Turns on various assertion checks. This is a debugging aid. If you are
  experiencing strange problems or crashes you might want to turn this on, as
  it might expose programming mistakes. To use this option, the macro
  USE_ASSERT_CHECKING must be defined when PostgreSQL is built (accomplished
  by the configure option --enable-cassert). Note that DEBUG_ASSERTIONS
  defaults to on if PostgreSQL has been built with assertions enabled.
  </entry>
  <entry>
  Only useful if your PostgreSQL system is crashing, and then only if you are
  a source hacker.
  </entry>
 </row>
 <row>
  <entry>zero_damaged_pages</entry>
  <entry>true, false</entry>
  <entry></entry>
  <entry>false</entry>
  <entry></entry>
  <entry>No*</entry>
  <entry>
  Detection of a damaged page header normally causes PostgreSQL to report an
  error, aborting the current transaction. Setting zero_damaged_pages to true
  causes the system to instead report a warning, zero out the damaged page and
  continue processing. This behavior will destroy data, namely all the rows on
  the damaged page. But it allows you to get past the error and retrieve rows
  from any undamaged pages that may be present in the table. So it is useful
  for recovering data if corruption has occurred due to hardware or software
  error. You should generally not set this true until you have given up hope of
  recovering data from the damaged page(s) of a table. The default setting is
  off, and it can only be changed by a superuser.
  </entry>
  <entry>
  May be SET by superuser.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect1>

</article>