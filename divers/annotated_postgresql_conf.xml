<?xml version="1.0" encoding="ISO-8859-1"?>
<!-- SAS 20060623 : Relecture initiale -->
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
"http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd" >

<article id="postgresqlconf" lang="fr">
 <articleinfo>
  <title>Fichier postgresql.conf et guide de configuration utilisateur générale (<foreignphrase>Global User Configuration (GUC)</foreignphrase>) annotés</title>
  <subtitle>PostgreSQL 8.0.x</subtitle>
 </articleinfo>

<sect1>
<title>Emplacement des fichiers</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>data_directory</entry>
  <entry>Répertoire</entry>
  <entry>ConfigDir</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Répertoire de stockage des données
  </entry>
  <entry>
  Ces nouveaux paramètres de configuration des emplacements de fichiers facilitent l'administration
  d'une installation de PostgreSQL lorsque les fichiers de configuration et de surveillance
  sont séparés de la base, généralement dans un but d'ajustement à une spécification particulière
  du fichier d'administration ou pour automatiser la conduite de tests avec plusieurs configurations.
  Lorsque ce paramètre est utilisé, seul l'emplacement du fichier postgresql.conf doit être
  précisé au démarrage du postmaster (à l'aide de -D ou PGDATA). Cette approche est supérieure
  à l'utilisation de lien symbolique, unique option jusque là disponible.
  </entry>
 </row>
 <row>
  <entry>hba_file</entry>
  <entry>nom de fichier</entry>
  <entry>ConfigDir/pg_hba.conf</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Fichier de configuration pour l'authentification basée sur l'hôte (habituellement appelé pg_hba.conf)
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>ident_file</entry>
  <entry>Nom de fichier</entry>
  <entry>ConfigDir/pg_ident.conf</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Fichier de configuration pour l'authentification par ident (habituellement appelé pg_ident.conf)
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>external_pid_file</entry>
  <entry>Nom de fichier</entry>
  <entry>Aucun</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nom du fichier additionnel d'identifiant de processus (PID) que le postmaster crée pour les programmes d'administration serveur
  </entry>
  <entry>
  Ce paramètre est utile pour les programmes d'administration et les interfaces utilisateur 
  graphiques qui s'attendent à trouver le PID de PostgreSQL à un emplacement particulier, en général
  /var. Ce n'est qu'une copie du PID, en aucun cas le fichier utilisé par pg_ctl au démarrage. 
  Ce dernier est situé dans le répertoire des données.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect1>

<sect1>
<title>Connexions et authentification</title>

<sect2>
<title>Paramètres de connexion</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>listen_addresses</entry>
  <entry></entry>
  <entry>localhost</entry>
  <entry>Démarrage</entry>
  <entry>-h x -i</entry>
  <entry>
  Adresse(s) TCP/IP sur la(es)quelle(s) le serveur écoute les connexions en provenance
  des clients. La valeur à la forme d'une liste de noms d'hôte ou d'adresses IP séparés par des
  virgules. La valeur spéciale '*' correspond à toutes les interfaces IP disponibles. 
  Si la liste est vide, le serveur n'écoute aucune interface IP. Dans ce cas, seules les
  sockets de domaine UNIX peuvent être utilisées pour se connecter. La valeur par défaut est
  'localhost', ce qui n'autorise que les connexions &laquo&nbsp;loopback&nbsp;&raquo;.
  </entry>
  <entry>
  <para>
  Ce paramètre remplace les deux paramètres &laquo&nbsp;tcp_ip&nbsp;&raquo; et 
  &laquo&nbsp;virtual_host&nbsp;&raquo; de la version 7.4. La plupart des utilisateurs peuvent
  utiliser '*' pour écouter toutes les adresses, ou laisser 'localhost' pour une machine sécurisée.
  À la différence des versions précédentes, la valeur par défaut autorise désormais les connexions
  TCP/IP sur 127.0.0.1. Le serveur web local peut ainsi se connecter sans paramétrage particulier.
  </para>
  <para>
  Pour une accès sécurisé, ce paramètre doit être modifié <emphasis>après</emphasis>
  la configuration du fichier pg_hba.conf.
  </para>
  </entry>
 </row>
 <row>
  <entry>port</entry>
  <entry>129 à 32768</entry>
  <entry>5432</entry>
  <entry>Démarrage</entry>
  <entry>-p #</entry>
  <entry>
  Le port TCP sur lequel le serveur écoute. 5432 par défaut. Ce port est utilisé pour toutes les 
  adresses IP que le serveur écoute.
  </entry>
  <entry>
  <para>
  Un port alternatif est essentiellement utilisé lorsqu'il est nécessaire de faire tourner
  plusieurs serveurs PostgreSQL sur la même machine, pendant une mise à niveau par exemple.
  </para>
  <para>
  Une alternative à cette configuration est l'utilisation de l'option de compilation
  &laquo;&nbsp;with-port&nbsp;&raquo;.
  Cette option fixe le port alternatif dans toutes les bibliothèques évitant ainsi de
  préciser l'option -p pour tous les clients.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_connections</entry>
  <entry>2 à 262143</entry>
  <entry>100</entry>
  <entry>Démarrage</entry>
  <entry>-N #</entry>
  <entry>
  Nombre maximum de connexions concurrentes à un serveur de bases de données.
  Typiquement 100 par défaut, il peut être réduit si la configuration du noyau
  l'impose (initdb tente de le déterminer).
  </entry>
  <entry>
  Ce paramètre doit être maintenu près du minimum requis par l'application.
  En effet, chaque connexion nécessite des ressources
  système significatives. Les applications web qui servent des centaines
  d'utilisateurs peuvent utiliser une réserve de connexions
  (<foreignphrase>connection pool</foreignphrase>) pour réduire le nombre 
  de connexions demandées. L'augmentation du paramètre demande un ajustement des
  limites mémoire du système.
  </entry>
 </row>
 <row>
  <entry>superuser_reserved_connections</entry>
  <entry>0 à max_connections - 1</entry>
  <entry>2</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nombre de connexions réservées aux superutilisateurs PostgreSQL. Au plus
  max_connections connexions peuvent être actives simultanément. Lorsque
  le nombre de connexions concurrentes atteint max_connections moins
  superuser_reserved_connections, seules les connexions de superutilisateurs
  sont encore autorisées.
  </entry>
  <entry>
  Cela protège l'accès des superutilisateurs en cas d'engorgement de la base.
  Ce paramètre ne doit être positionné à 0 que lorsqu'il est certain que
  toutes les connexions ne sont jamais utilisées. (NDR&nbsp;: Je positionne
  souvent ce paramètre à 1, puisque je ne me connecte en superutilisateur
  à la base qu'en cas de problème.) Le paramétrage à 2 par défaut prévoit le 
  cas d'utilitaire administratif connecté en permanence, autovacuum par exemple.
  </entry>
 </row>
 <row>
  <entry>unix_socket_directory</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry>-k $</entry>
  <entry>
  Répertoire du socket de domaine Unix sur lequel le serveur écoute
  les connections de clients. Par défaut, c'est /tmp, mais le paramètre
  peut être modifié à la compilation.
  </entry>
  <entry>
  Aucune recommandation particulière.
  </entry>
 </row>
 <row>
  <entry>unix_socket_group</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Groupe propriétaire du socket de domaine Unix. (L'utilisateur propriétaire
  de ce socket est toujours celui qui démarre le serveur.) Combiné avec l'option
  UNIX_SOCKET_PERMISSIONS, ce paramètre peut être utilisé comme mécanisme
  supplémentaire de contrôle des accès pour ce type de socket. Par défaut, 
  c'est une chaîne vide, soit le groupe par défaut de l'utilisateur.
  </entry>
  <entry>
  Aucune recommandation particulière.</entry>
 </row>
 <row>
  <entry>unix_socket_permissions</entry>
  <entry></entry>
  <entry>0777</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  <para>
  Permissions d'accès au socket de domaine Unix. Les sockets de domaine Unix
  utilise le système habituel de gestion des permissions des systèmes de 
  fichier Unix. La valeur de l'option doit être précisée sous la forme numérique
  acceptée par les outils système chmod et umask. L'utilisation du format 
  octal impose un 0 (zéro) en début de nombre.
  </para>
  <para>
  Les permissions par défaut sont 0777, tout le monde peut se connecter.
  Des alternatives acceptables sont 0770 (autorisations pour l'utilisateur
  et le groupe, voir aussi unix_socket_group), et 0700 (utilisateur seul).
  En général, dans le cas d'une socket de domaine Unix, seule la permission
  d'écriture importe. Il n'y a donc aucun intérêt à positionner ou supprimer
  les droits d'écriture ou de lecture.
  </para>
  </entry>
  <entry>
  Aucune recommandation particulère.</entry>
 </row>
 <row>
  <entry>rendezvous_name</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nom du diffuseur Rendezvous. La valeur par défaut, indiquée par une chaîne
  vide '', est le nom de l'ordinateur. Cette option n'a d'intérêt que pour les
  plateformes qui supportent Rendezvous.
  </entry>
  <entry>
  Aucune recommandation particulière.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Securité et authentification</title>

<table>
<title>Securité et authentication (Fichier postgresql.conf et guide de configuration utilisateur générale (<foreignphrase>Global User Configuration (GUC)</foreignphrase>) annotés)</title>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>authentication_timeout</entry>
  <entry>1-600 sec</entry>
  <entry>600</entry>
  <entry>Rechargement</entry>
  <entry></entry>
  <entry>
  Temps maximum laissé à un client pour réussir l'authentification, en secondes.
  Si un client potentiel n'a pas terminé la séquence d'authentification
  pendant ce temps, le serveur met fin à la connexion. Cela permet 
  d'éviter qu'un client bloqué n'occupe indéfiniment une connexion.
  </entry>
  <entry>
  Le temps d'attente peut être réduit s'il s'agit d'exécuter un site web
  à grand traffic. Afin d'éviter une indisponibilité non souhaitée,
  ou une attente trop longue lorsque le serveur est chargé, il peut
  être utile de faire correspondre ce temps d'attente avec celui de l'intergiciel.
  </entry>
 </row>
 <row>
  <entry>ssl</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Démarrage</entry>
  <entry>-l</entry>
  <entry>Active les connexions SSL</entry>
  <entry>
  SSL est une alternative chiffrée à l'accès direct au port TCP/IP, nécessaire
  pour les clients accédant à des données sécurisées, en particulier à travers
  un réseau sans fil. PostgreSQL envoie les requêtes et les données en texte,
  même lors de l'utilisation d'un mot de passe chiffré. SSL peut être difficile
  à configurer, et tout les clients ne supportent pas l'accès SSL.
  </entry>
 </row>
 <row>
  <entry>password_encryption</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Détermine le chiffrement du mot de passe lorsque ni ENCRYPTED ni UNENCRYPTED
  ne sont précisés lors de l'indication d'un mot de passe avec les commandes
  CREATE USER et ALTER USER.
  </entry>
  <entry>
  Il est préférable de laisser la valeur à <foreignphrase>true</foreignphrase> (vrai),
  à la fois dans le fichier de configuration et à la connexion. Il n'y a quasiment
  jamais de raison de ne pas chiffrer les mots de passe des utilisateurs de la base de
  données.
  </entry>
 </row>
 <row>
  <entry>krb_server_keyfile</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Positionne l'implantation du fichier de clés du serveur Kerberos.
  </entry>
  <entry>
  Utilisé uniquement pour l'authentification Kerberos des utilisateurs.
  </entry>
 </row>
 <row>
  <entry>db_user_namespace</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Rechargement</entry>
  <entry></entry>
  <entry>
  Lorsque cette option est activée, les utilisateurs doivent être créés comme
  username@dbname. Lorsque le nom d'utilisateur est fourni par un client, 
  @ et le nom de la base sont ajoutés au nom de l'utilisateur.
  C'est ce nom d'utilisateur, dépendant d'une base de données, qui est
  ensuite recherché par le serveur. Lors de la création dans l'environnement
  SQL d'utilisateurs dont le nom contient @, il est nécessaire de placer le
  nom de l'utilisateur entre des guillemets simples.
  name.
  </entry>
  <entry>
  Cette option prend en charge les installations (telles que les FAI)
  qui nécessitent des utilisateurs définis par base de données. C'est
  assez contraignant, et cela devrait être supprimé lorsqu'une meilleure
  solution sera créée. Il est ainsi préférable de ne pas utiliser cette option
  lorsqu'elle n'est pas vitale.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Utilisation des ressources</title>

<sect2>
<title>Mémoire</title>

<note>
 <para>
  Augmenter la valeur de la plupart des paramètres suivants
  oblige à modifier les options du noyau du système d'exploitation 
  pour augmenter la mémoire alloué à un processus ou à un utilisateur.
  La documentation en ligne fournit des informations sur les commandes
  à utiliser pour de nombreux systèmes d'exploitation. Sauf indication
  contraire, la plupart de ces options s'additionnent pour déterminer 
  la quantité totale de mémoire utilisée par PostgreSQL.
 </para>
</note>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documetation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>shared_buffers</entry>
  <entry>16 à 262143</entry>
  <entry>1000</entry>
  <entry>
  Démarrage
  </entry>
  <entry>-B x</entry>
  <entry>
  Positionne le nombre de tampons de mémoire partagée utilisé par le 
  serveur de bases de données. Le minimum est 2 X max_connections.
  La valeur par défaut est généralement 1000, mais elle peut être
  inférieure si la configuration du noyau l'impose (ce qu'initdb détermine). 
  Chaque tampon représente 8192 octets, à moins qu'une valeur
  différente de BLCKSZ n'ait été choisie à la compilation. La valeur
  minimale est de 16 et de deux fois la valeur de max_connections.
  Néanmoins, un paramétrage significativement supérieur au minimum
  est souvent nécessaire pour assurer des performances satisfaisantes.
  En production, il est recommandé d'utiliser une valeur de quelques
  milliers.
  </entry>
  <entry>
  <para>
  Le paramétrage de shared_buffers nécessite une discussion bien plus complète
  que ne l'autorise la place ici disponible. On peut se référer à d'autres
  articles sur le sujet.
  </para>
  <para>
  Quelques règles empiriques&nbsp;:
  Sur un serveur PostgreSQL dédié, une valeur convenable se situe en général entre 
  1&nbsp;000 et 50&nbsp;000 (8Mo et 400Mo). Les facteurs qui incitent à augmenter
  la valeur sont des connexions plus nombreuses, des parties actives de la base
  plus grandes, des requêtes longues et complexes, et des grandes tables. La
  RAM disponible limite le ombre maximum de shared_buffers&nbsp;; 1/3 de la RAM
  disponible est la limite maximale à utiliser.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  work_mem
  </entry>
  <entry>64 à Int Max</entry>
  <entry>1024</entry>
  <entry>
  Exécution
  </entry>
  <entry>-S #</entry>
  <entry>
  <para>
  Précise la quantité de mémoire utisable par les opérations de tri interne et
  les tables de hachage avant d'utiliser des fichiers temporaires. La valeur
  est indiquée en kilooctets, la valeur par défaut est 1024 kilooctets (1Mo).
  En cas de requête complexe, de nombreuses opérations de tri ou de hachage
  peuvent s'exécuter en parallèle&nbsp;; chacune peut utiliser la quantité
  de mémoire indiquée par la valeur de ce paramètre avant de commencer à
  utiliser des fichiers temporaires. De plus, de nombreuses sessions
  peuvent effectuer ces opérations concurrentiellement. La mémoire totale
  utilisée peut être plusieurs fois la valeur de work_mem&nbsp;; il faut
  en tenir compte lors du choix de la valeur. Les opérations de tri sont 
  utilisées par ORDER BY, DISTINCT et les jointures. Les tables de hachage
  sont utilisées dans les jointures de hachage, les aggrégations par hachage
  et la résolution par hachage des sous-requêtes IN.
  </para>
  </entry>
  <entry>
  <para>
  À l'origine appelé sort_mem, le paramètre a été renommé pour refléter
  l'extension de son rôle au-delà des simples tris.
  </para>
  <para>
  work_mem est un compromis. Une plus grande valeur est utilisée pour&nbsp;: les
  bases de données volumineuses, les requêtes complexes, une grande quantité de 
  RAM disponible. Une plus petite valeur est recherchée pour&nbsp;: une faible
  quantité de RAM ou de nombreux accès concurrents. Trouver le bon compromis
  peut s'avérer délicat.
  </para>
  <para>
  Une autre façon d'ajuster cette valeur consiste à surveiller les fichiers
  temporaires de PostgreSQL (dans PGDATA/base/DB_OID/pgsql_tmp) et d'accroître
  la valeur de sort_mem si de nombreuses requêtes permutent avec ces fichiers.
  </para>
  <para>
  Il ne faut pas oublier que ce paramètre peut être positionné par connexion.
  Ainsi, dans le cas où seules quelques requêtes très complexes sont à
  exécuter, la valeur peut être augmentée avant leur exécution, mais conservée
  basse pour les autres connexions.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  maintenance_work_mem
  </entry>
  <entry>1024 à Int Max</entry>
  <entry>8192</entry>
  <entry>
  Exécution
  </entry>
  <entry></entry>
  <entry>
  Indique la quantité maximale de mémoire à utiliser dans les opérations
  de maintenance, telles que VACUUM, CREATE INDEX et ALTER TABLE ADD FOREIGN KEY.
  La valeur est précisée en kilooctets. La valeur par défaut est 16384 kilooctets
  (16 Mo). Puisque seule une de ces opérations peut être effectuée à la fois
  au cours d'une session, et qu'en général peu se produisent simultanément
  sur une même installation, il n'y a aucun risque à positionner ce paramètre
  à une valeur nettement supérieure à celle de work_mem. Une valeur élevée
  peut améliorer les performances du nettoyage (vacuum) et de la restauration
  des sauvegardes.
  </entry>
  <entry>
  <para>
  À l'origine appelé vacuum_mem, le paramètre a été renommé pour refléter l'extension
  de son rôle à l'allocation de mémoire lors du chargement des index.
  </para>
  <para>
  La valeur par défaut est généralement trop basse. Il en résulte un blocage
  des E/S du système par les opérations de VACUUM et de créations d'index et/ou
  des blocages d'objets pendant la permutation. Une valeur convenable est généralement
  comprise entre 32&nbsp;Mo et 256&nbsp;Mo&nbsp;; cela dépend autant de la RAM
  disponible que du plus grand volume (attendu) des objets de la base. 
  </para>
  <para>
  Tout comme work_mem, ce paramètre peut être fixé à l'exécution, ce qui permet 
  de l'accroître temporairement lors du chargement d'index ou de la création 
  de clés sur des tables volumineuses.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Mappe de l'espace libre <foreignphrase>Free Space Map</foreignphrase></title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_fsm_pages</entry>
  <entry>1000 à Int Max</entry>
  <entry>20000</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  Positionne le nombre maximum de pages disque pour lesquels l'espace
  libre est recherché dans la mappe de l'espace libre partagé.
  Six octets de mémoire partagée sont consommés pour chaque connecteur
  de page. La valeur doit être supérieure à 16 X max_fsm_relations.
  </entry>
  <entry>
  <para>
  Un paramétrage correct de la FSM peut éliminer, ou au moins, retarder
  l'obligation d'exécuter VACUUM FULL et REINDEX. La meilleure façon de le régler 
  est la suivante&nbsp;: 1) calculer la fréquence du VACUUM (normal) de la
  base en fonction des écritures&nbsp;; 2) utiliser la base en fonctionnement
  normal et exécuter VACUUM VERBOSE ANALYZE à la place de VACUUM, en sauvegardant
  la sortie dans un fichier&nbsp;; 3) calculer le nombre de pages maximum réclamé
  par VACUUM et utiliser ce chiffre.
  </para>
  <para>
  Alternativement, en cas d'utilisation d'autovacuum, la valeur peut être
  issue d'un pourcentage du nombre total de pages dans la base, pour coïncider
  avec le pourcentage d'autovacuum. Quoiqu'il en soit, une page demande peu
  de mémoire (environ 6 octets). il est donc préférable d'être généreux plutôt 
  que radin.
  </para>
  <para>
  Pour les base de données qui connaissent des &laquo&nbsp;pics&nbsp;&raquo;
  d'activité (rafales d'un million de mises à jour mais pas d'autre
  activité des minutes ou des heures durant), ce nombre peut être 
  impossible à optimiser. Les lignes insérées n'ont pas d'impact
  sur la FSM. Enfin, si le serveur est peu fourni en RAM, augmenter
  cette valeur peut s'avérer contre-productif.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_fsm_relations</entry>
  <entry>10 à Int Max</entry>
  <entry>1000</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  Positionne le nombre maximum de relations (tables et index) pour
  lesquels l'espace libre est recherché dans la mappe de l'espce libre
  partagé. Chaque connecteur utilise approximativement 50 octets de mémoire.
  </entry>
  <entry>
  Peu d'utilisateurs peuvent avoir besoin d'ajuster ce paramètre, mais il est
  intéressant de le considérer. FSM_relations doit être au moins équivalent
  au nombre de tables dans l'ensemble des bases, bases squelettes et schéma
  système compris. PostgreSQL peut avoir des performances aléatoires 
  si le nombre de FSM_relations est trop faible.
  </entry>
 </row>
 <row>
  <entry>max_stack_depth</entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry>
  Indique la profondeur maximale que peut atteindre la pile d'exécution du serveur
  en toute sécurité. Le réglage idéal du parmètre correspond à la limite réelle
  de la pile imposée par le noyau (positionné par ulimit -s ou équivalent), diminué
  d'une marge de sécurité d'un Mo environ. Cette marge de sécurité est nécessaire
  parce que la profondeur de la pile n'est pas vérifiée pour chaque routine du
  serveur, mais uniquement pour les routines potentiellement récursives, telles
  que les évaluations d'expressions. Une valeur plus grande
  que la limite réelle du noyau peut conduire une fonction récursive à
  occasionner un plantage d'un processus serveur. La valeur par défaut de 2048 ko
  (2 Mo) est résolument basse et ne risque pas d'occasionner un plantage. Néanmoins, 
  elle peut s'avérer trop petite pour autoriser l'exécution de fonctions complexes.
  </entry>
  <entry>
  <para>
  La paramètre s'est appelé max_expr_depth, et son unité ne correspondait pas 
  à celle utilisée par la plupart des noyaux systèmes.
  </para>
  <para>
  En cas de dépassement de ce paramètre, un message d'erreur spécifique est
  produit. A ce moment-là, il peut être augmenté
  <emphasis>avec précaution</emphasis>&nbsp;; de nombreux systèmes d'exploitation
  ont des limites aussi basses que 8&nbsp;Mo.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Utilisation des ressources du noyau</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_files_per_process</entry>
  <entry>25 à Int Max</entry>
  <entry>1000</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  Fixe le nombre maximum de fichiers simultanément ouverts par chaque
  sous-processus du serveur. La valeur par défaut est 1&nbsp;000. 
  Si le noyau impose une limite par processus, il n'est pas nécessaire
  de s'inquiéter de ce paramètre. Mais sur la plupart des plateformes
  (et notamment BSD), le noyau autorise des processus individuels à ouvrir
  beaucoup plus de fichiers que le système ne peut en prendre en charge
  lorsque de nombreux processus essayent tous d'ouvrir ce nombre de fichiers.
  Si le message d'erreur &laquo;&nbsp;Trop de fichiers ouverts&nbsp;&raquo;
  (<foreignphrase>"Too many open files"</foreignphrase>) apparaît, 
  il faut alors essayer de réduire ce paramètre. Il ne peut être
  fixé qu'au démarrage du serveur.
  </entry>
  <entry>
  D'après la documentation, utilisé essentiellement pour BSD. À considérer uniquement
  à l'appartion de messages &laquo;&nbsp;Trop de fichiers ouverts&nbsp;&raquo;
  (<foreignphrase>"Too many open files"</foreignphrase>).
  </entry>
 </row>
 <row>
  <entry>preload_libraries</entry>
  <entry>Chemin de fichier</entry>
  <entry>Vide</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  <para>
  Indique les bibliothèques à précharger au démarrage du serveur. Une
  fonction d'initialisation sans paramètre peut optionnellement être
  appelée pour chaque bibliothèque. Pour cela, il suffit d'ajouter un 
  double-point et le nom de la fonction d'initialisation après le
  nom de la bibliothèque. '$libdir/mylib:mylib_init' implique, par exemple,
  le préchargement de mylib et l'exécution de la fonction mylib_init.
  Si plusieurs bibliothèques doivent être chargées, leurs noms
  sont séparés par des virgules.
  </para>
  <para>
  Si une bibliothèque ou une fonction d'initialisation ainsi indiquée
  n'est pas trouvée, le serveur ne peut pas démarrer. Les bibliothèques
  du langage procédural de PostgreSQL peuvent être préchargées de cette 
  façon, typiquement en utilisant la syntaxe '$libdir/plXXX:plXXX_init'
  avec XXX qui peut être pgsql, perl, tcl ou python.
  </para>
  <para>
  Le préchargement (et l'initialisation éventuelle) d'une bibliothèque
  partagée permet d'éviter le temps de chargement de la bibliothèque
  la première fois qu'elle est utilisée. Néanmoins, le temps de démarrage
  de chaque processus serveur peut croître légèrement, même si ce
  processus n'utilise jamais cette bibliothèque. Cette option n'est
  donc recommandée que pour les bibliothèques utilisées dans la plupart
  des sessions.
  </para>
  </entry>
  <entry>
  Cela n'est utile que pour dans le cas de bases de données spécialisées.
  Une base de cartographie peut, par exemple, gagner légèrement en performances
  en préchargeant les bibliothèques GIS. Pour la plupart des systèmes, il est
  préférable de ne pas renseigner cette option.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Délai de nettoyage (<foreignphrase>vacuum</foreignphrase>)</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>&Eacute;chelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>vacuum_cost_delay</entry>
  <entry></entry>
  <entry>0</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Le temps, en millisecondes, pendant lequel le processus est endormi lorsque
  la limite de coût est atteinte. La valeur par défaut est 0, ce qui désactive
  la fonctionnalité de délai de nettoyage en fonction du coût. Une valeur
  positive active le nettoyage fonction du coût. Sur la plupart des systèmes
  la résolution réelle du délai est de 10 millisecondes&nbsp;; une valeur
  de vacuum_cost_delay qui n'est pas un multiple de 10 a le même comportement
  que le plus petit multiple de 10 supérieur à cette valeur.
  </entry>
  <entry>
  Ce paramètre est très utile lors du nettoyage de tables volumineuses, qui
  autrement, peut bloquer les E/S pendant de longues périodes ou maintenir
  des verrous bloquant de nombreuses requêtes. Pour l'essentiel, l'activation
  de ce paramètre découpe le nettoyage d'une table volumineuse en segments
  définis comme des unités de travail spécifiques, entre lesquelles le
  nettoyage est mis en veille pour le temps défini par le paramètre. Cela a pour
  effet d'augmenter parfois considérablement le temps nécessaire au nettoyage, 
  mais aussi de réduire l'impact du nettoyage sur le système, de l'ordre de 85%.
  Une valeur raisonnable est comprise entre 50&nbsp;ms et 200&nbsp;ms.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_hit</entry>
  <entry></entry>
  <entry>1</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Indique le coût estimé de nettoyage d'un tampon trouvé dans le cache de
  tampon partagé. Ce paramètre représente le coût du vérouillage du pool de
  tampons, la recherche de la table de hachage partagée et le parcours du
  contenu de la page.
  </entry>
  <entry>
  Il est préférable de ne pas modifier ce paramètre, mais plutôt
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_miss</entry>
  <entry></entry>
  <entry>10</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Indique le coût estimé de nettoyage d'un tampon à lire sur le disque. Ce
  paramètre représente le coût de vérouillage du pool de tampons, la recherche de la
  table de hachage partagée, la lecture du bloc souhaité sur le disque et le
  parcours de son contenu.
  </entry>
  <entry>
  Il est préférable de ne pas modifier ce paramètre, mais plutôt
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_dirty</entry>
  <entry></entry>
  <entry>20</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Indique le coût estimé de la modification par le nettoyeur d'un bloc
  précédemment nettoyé. Ce paramètre représente les E/S supplémentaires requises
  pour supprimer une nouvelle fois du disque les blocs inutiles.
  </entry>
  <entry>
  Il est préférable de ne pas modifier ce paramètre, mais plutôt
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_limit</entry>
  <entry></entry>
  <entry>200</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Indique le coût cumulé qui impose la mise en sommeil du processus de
  nettoyage.
  </entry>
  <entry>
  La valeur de ce paramètre est diminuée pour fragmenter le nettoyage en des
  &laquo;&nbsp;segments&nbsp;&raquo; plus nombreux. Une combinaison très
  aggressive consiste à positionner vacuum_cost_delay à 200&nbsp;ms et
  vacuum_cost_limit à 50&nbsp;ms&nbsp;; cela implique un nettoyage 10 fois plus
  long mais sans impact sur les performances de la base de données. Dans la
  plupart des cas, le DBA peut être plus modéré.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Scripteur d'arrière-plan (<foreignphrase>Background
Writer</foreignphrase>)</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>bgwriter_delay</entry>
  <entry></entry>
  <entry>200</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Indique le délai entre les périodes d'activité du scripteur d'arrière-plan. À
  chaque tour, le scripteur écrit sur le disque un certain nombre de tampons
  modifiés (nombre ajustable à l'aide des paramètres qui suivent). Les tampons
  sélectionnés sont toujours les plus anciens des tampons modifiés. Le scripteur
  est alors mis en veille pour bgwriter_delay millisecondes, et ainsi de suite.
  </entry>
  <entry>
  <para>
  Fonctionnalité nouvelle, le scripteur d'arrière-plan est destiné à
  alléger les pics de contrôle.
  </para>
  <para>
  L'OSDL effectue toujours des tests de configuration du bgwriter&nbsp;; aucune
  recommendation ne peut être faite à ce jour.
  </para>
  </entry>
 </row>
 <row>
  <entry>bgwriter_percent</entry>
  <entry></entry>
  <entry>1</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Au maximum ce pourcentage de tampons modifiés est écrit à chaque tour (si
  besoin, le nombre est arrondi à l'entier supérieur).
  </entry>
  <entry>
  L'OSDL effectue toujours des tests de configuration du bgwriter&nbsp;; aucune
  recommendation ne peut être faite à ce jour.
  </entry>
 </row>
 <row>
  <entry>bgwriter_maxpages</entry>
  <entry></entry>
  <entry>100</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Au maximum ce nombre de tampons modifiés est écrit à chaque tour.
  </entry>
  <entry>
  L'OSDL effectue toujours des tests de configuration du bgwriter&nbsp;; aucune
  recommendation ne peut être faite à ce jour.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Options WAL</title>

<sect2>
<title>Paramétrage</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>fsync</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Démarrage</entry>
  <entry>-F (off)</entry>
  <entry>
  <para>
  Lorsque cette option est activée, le serveur PostgreSQL utilise les appels
  système fsync() pour s'assurer que les mises à jour sont physiquement écrites
  sur le disque. Cela garantit la récupération d'une bases de données
  cohérente après une panne matérielle ou système.
  </para>
  <para>
  Néanmoins, l'utilisation de fsync() implique une baisse de performances&nbsp;:
  lorsqu'une transaction est validée, PostgreSQL doit attendre que le système
  purge le journal d'écriture anticipée. Lorsque fsync est désactivé, a toute
  latitude dans la mise en mémoire tampon, le tri et le report des écritures. 
  Il peut en découler des performances accrues. Toutefois, si le système plante,
  le résultat des dernières transactions validées peut être perdu, en tout ou
  partie. Dans le pire des cas, les données peuvent être irrémédiablement
  corrompues. Les plantages du serveur de base de données ne présentent ici
  aucun risque&nbsp;; seul un plantage du système d'exploitation présente un
  risque de corruption.
  </para>
  </entry>
  <entry>
  <para>
  La journalisation des écritures anticipées (<foreignphrase>Write-Ahead
  Logging ou WAL</foreignphrase>) ne doit être désactivée que sur les bases en
  écriture seule ou celles qu'il est possible de régénérer à l'aide de logiciels
  externes. Tandis que du RAID associé à un système de haute-disponibilité
  électrique peuvent aider à la protection des données, la désactivation de
  fsync <emphasis>impose</emphasis> la restauration des données à partir de
  sauvegardes en cas de pannes matériel ou électrique.
  </para>
  <para>
  D'un autre côté, le WAL imlique une baisse de performances lors des écritures, à
  plus forte raison sur des systèmes mono-disques. Pour l'essentiel l'activité
  nécessaire aux opérations de lecture/écriture est doublée à chaque mise à
  jour. De plus, les fonctionnalités d'amélioration des performances par cache
  disque matériel ou logiciel sont désactivées. C'est pourquoi, dans le cas de
  données dont la conservation n'est pas une priorité, il est intéressant de
  considérer la désactivation de fsync.
  </para>
  <para>
  Si le WAL est arrêté, les options qui suivent n'ont pas d'intérêt.
  </para>
  </entry>
 </row>
 <row>
  <entry>wal_sync_method</entry>
  <entry>fsync, fdatasync, open_sync, open_datasync</entry>
  <entry>Dépend de la plateforme</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Méthode utilisée pour forcer la mise à jour des WAL sur le disque. Les valeurs
  possibles sont FSYNC (fsync() est appelé à chaque validation), FDATASYNC
  (fdatasync() est appelé à chaque validation), OPEN_SYNC (écrit les fichiers
  WAL avec l'option O_SYNC d'open()) et OPEN_DATASYNC (écrit les fichiers WAL
  avec l'option O_DSYNC d'open()). Ces choix ne sont pas tous disponibles sur
  toutes les plateformes.
  </entry>
  <entry>
  Il s'agit de l'appel système utilisé pour synchroniser les WAL sur disque. La
  valeur par défaut a été réglée pour chaque OS en fonction de la documentation
  de l'OS. En revanche, aucun test comparatif n'a été mené. Il est possible que
  le changement de méthode accélère l'écriture sur une plateforme spécifique,
  mais cela ne doit être tenté que si les ressources nécessaires à des tests
  comparatifs et de régression sont disponibles.
  </entry>
 </row>
 <row>
  <entry>wal_buffers</entry>
  <entry>4 à Int Max</entry>
  <entry>8</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  indique le nombre de tampons de pages disque alloués dans la mémoire partagée
  pour les données du WAL. La valeur par défaut est 8. La valeur doit juste être
  assez grande pour contenir la quantité de données WAL engendrée par une
  transaction.
  </entry>
  <entry>
  L'accroissement de ce paramètre n'a que peu d'influence, même dans le cas de
  système OLTP (On-Line Transaction Processing) chargés. Dans le cas de
  transactions conséquentes, on peut accroître ce paramètre par sécurité (de 16
  à 64), mais il est préférable de se concentrer sur checkpoint_segments.
  </entry>
 </row>
 <row>
  <entry>commit_delay</entry>
  <entry>0 - 100000</entry>
  <entry>0</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Indique le délai, en microsecondes, entre l'écriture d'une validation dans le
  tampon WAL et la purge du tampon sur disque. Un délai positif peut permettre
  la validation de plusieurs transactions avec un seul appel système fsync(), si
  la charge système est suffisamment élevée pour que de nouvelles transactions
  soient prêtes pendant cet interval. Mais ce délai est perdu dans le cas
  contraire. Ainsi, le délai n'est exécuté que si au moins commit_siblings autre
  transactions sont actives au moment où le processus serveur a écrit sa
  validation.
  </entry>
  <entry>
  Ces deux paramètres sont configurés ensemble pour un environnement à fort
  volume de petites transactions. Activés, ils permettent de purger en même
  temps sur disques des transactions sans relation entre elles, qui autrement ne
  le seraient pas, avec à la clé un potentiel accroissement des performances.
  Néanmoins, c'est une manière de pallier l'attente de quelques millisecondes
  supplémentaires entre chaque transaction. Afin de tester l'amélioration des
  performances dans un cas précis, un point de départ peut être un commit_delay
  de 500 (soit ½ milliseconde).
  </entry>
 </row>
 <row>
  <entry>commit_siblings</entry>
  <entry>1 - 1000</entry>
  <entry>5</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Indique le nombre minimum de transactions concurrentes ouvertes avant
  l'éxécution du délai COMMIT_DELAY. Plus la valeur est grande, plus la
  probabilité de valider une autre transaction pendant cet interval grandit.
  </entry>
  <entry>
  Si commit_delay est utilisé, ce paramètre peut être modifié en fonction de la
  longueure moyenne d'une transaction. Dans le cas de transactions courtes
  (requêtes insert/update d'une ligne) une valeur basse peut être utilisée,
  puisque des validations simultanées sont possibles&nbsp;; s'il existe des
  transactions plus longues, la valeur peut être augmentée pour éviter le
  d'inutiles commit_delay.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Points de contrôle</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>checkpoint_segments</entry>
  <entry>1 à Int Max</entry>
  <entry>3</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Distance maximale entre deux points de contôle WAL automatiques, en segments de
  fichier journal (chaque segment représente normalement 16 Mo).
  </entry>
  <entry>
  C'est le paramètre qui permet d'ajuster le plus finement le comportement lors de
  mises à jour volumineuses, de chargements de données et de grande activité OLTP.
  Sur les systèmes où les écritures sont nombreuses, ce paramètre peut être
  poussé à 8, au moins&nbsp;; sur les systèmes où sont chargés de grandes
  volumétries (telles que le chargement de plusieurs Go de données), cela peut
  aller jusqu'à 128 (256 est
  la valeur utilisée lors des tests DBT2). Cela requiert toutefois une quantité
  non négligeable d'espace disque pour les fichiers xlog ( ( 2  x segments  + 1
  )  x 16Mo, pour être précis). Si les fichiers xlog ne sont pas sur un disque
  distinct de celui des données, l'amélioration est minime.
  </entry>
 </row>
 <row>
  <entry>checkpoint_timeout</entry>
  <entry>30 à 3600</entry>
  <entry>300</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Temps maximal entre deux points de contôle WAL automatiques, en secondes.
  </entry>
  <entry>
  Ce paramètre peut être augmenté fortement (jusqu'à 30 minutes) pour les
  chargements de gros volumes. Dans les autres cas, un réglage entre 3
  et 10 minutes représente une bonne échelle. Lorsque des bloquages d'écriture
  apparaissent, ce paramètre peut être augmenté. L'augmentation de la valeur du
  paramètre est actuellement limitée par l'impact croissant que cela engendre
  sur la synchronisation du disque.
  </entry>
 </row>
 <row>
  <entry>checkpoint_warning</entry>
  <entry>0 à Int Max</entry>
  <entry>0</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Un message est envoyé dans les journaux du serveur si la fréquence des points de contrôle
  engendrés par le remplissage des fichiers de segments de points de contrôle 
  est supérieure à ce temps, en secondes. Zéro désactive les alertes.
  </entry>
  <entry>
  Ce paramètre permet de détecter si checkpoint_segments doit être augmenté.
  Ce paramètre peut être activé pendant la phase de développement. Des alertes
  nombreuses dans les journaux incitent alors à accroitre ce paramètre.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Archivage</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>archive_command</entry>
  <entry>Commande shell</entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  <para>
  Indique la commande shell à exécuter pour archiver un segment terminé des
  séries de fichiers WAL. Une chaîne vide (défaut) désactive l'archivage des
  WAL. %p dans la chaîne est remplacé par le chemin absolu du fichier à archiver,
  %f par le nom du fichier seul. %% permet d'échapper un caractère %. Pour de
  %plus amples informations, on peut se reporter à la section 22.3.1.
  </para>
  <para>
  Cette commande doit impérativement ne retourner une valeur de sortie nulle
  qu'en cas de succès.
  </para>
  </entry>
  <entry>
  Ce paramètre active la nouvelle fonctionnalité de restauration à un instant
  donné (<foreignphrase>Point In Time Recovery, PITR</foreignphrase>) en
  fournissant une commande shell d'archivage (copie) des segments WAL finalisés
  vers une autre destination. De plus amples informations concernant leur
  utilisation sont disponibles dans
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Optimisation des requêtes</title>

<sect2>
<title>Méthodes de planification</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>enable_hashagg</para>
  <para>enable_hashjoin</para>
  <para>enable_indexscan</para>
  <para>enable_mergejoin</para>
  <para>enable_nestloop</para>
  <para>enable_seqscan</para>
  <para>enable_sort</para>
  <para>enable_tidscan</para>
  </entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Exécution</entry>
  <entry>
  <para></para>
  <para>-fi</para>
  <para>-fm</para>
  <para>-fn</para>
  <para>-fs</para>
  <para></para>
  <para>-ft*</para>
  <para></para>
  </entry>
  <entry>
  Active ou désactive l'utilisation par le planificateur de requêtes des types
  de plan respectifs. Par défaut, ils sont actifs. Cela permet de déboguer le
  planificateur de requêtes.
  </entry>
  <entry>
  <para>
  Ces options ne devraient être utilisées que pour tester les requêtes&nbsp;; il
  est courant, par exemple, de positionner &laquo;&nbsp;enable_seqscan = false&nbsp;&raquo;
  pour déterminer si le planificateur n'omet pas inutilement un index. Quoi
  qu'il en soit, seules des circonstances extraordinaires nécessitent qu'un
  de ces paramètres soit positionné à <foreignphrase>false</foreignphrase> dans
  le fichier .conf. En fait, si cela devait arriver, c'est probablement que
  d'autres paramètres d'optimisation ont été négligés. 
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Constantes de coût du planificateur</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>effective_cache_size</entry>
  <entry>0 à Double</entry>
  <entry>1000</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  <!-- Trad: assumption -->
  Fournit à l'optimiseur une estimation de la taille efficace du cache
  disque (c'est-à-dire la partie du cache disque du noyau utilisée pour les
  fichiers de données PostgreSQL). Elle est mesurée en pages disque, chacune
  de 8 ko.
  </entry>
  <entry>
  Fournir au planificateur une hypothèse concernant la probabilité
  qu'un index ou une table particulière se trouve en mémoire a une forte
  influence sur le choix par le planificateur des index
  préférentiellement aux parcours séquentiels, et sur quelques autres
  structures de requête. De ce fait, positionner ce paramètre à environ
  2/3 de la RAM disponible permet de s'assurer que le planificateur est
  correctement informé. La plupart du temps, les DBA qui souhaitent désactiver
  enable_seqscan peuvent commencer par modifier ce paramètre.
  </entry>
 </row>
 <row>
  <entry>
  <para>random_page_cost</para>
  </entry>
  <entry>0 à Double</entry>
  <entry>4</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Fournit au planificateur une estimation du coût de récupération non
  séquentielle d'une page disque. Elle est mesurée en multiples du coût de
  récupération séquentielle d'une page. Plus grande est la valeur, plus grande
  est la probabilité d'un parcours séquentiel. Plus petite est la valeur, plus
  grande est la probabilité d'utilisation des index.
  </entry>
  <entry>
  <para>
  L'échelle utile se situe entre 2.0 et 4.0. La valeur la plus basse
  pour un CPU rapide, des E/S rapides et une base de données qui
  tient entièrement en mémoire. La valeur haute lorsque le CPU ou le disque sont
  limités, ou si les tables principales et leurs index ont une taille beaucoup
  plus grande que la RAM disponible (plusieurs fois). Ce paramètre ne doit
  jamais être positionné à une valeur inférieure à 1.5&nbsp;; si des problèmes
  avec certaines requêtes semblent obliger à étudier cette possibilité, c'est
  qu'il y a probablement d'autres paramètres à régler (effective_cache_size, par
  exemple).
  </para>
  <para>
  Lorsque l'effet de différents réglages est testé, il est important de tester
  plusieurs requêtes, et pas uniquement celle qui pose problème. 
  </para>
  </entry>
 </row>
 <row>
  <entry>
  <para>cpu_tuple_cost</para>
  <para>cpu_index_tuple_cost</para>
  <para>cpu_operator_cost</para>
  </entry>
  <entry>0 à Double</entry>
  <entry>
  <para>0.01</para>
  <para>0.001</para>
  <para>0.0025</para>
  </entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Fournit à l'optimiseur une estimation du coût CPU de traitement de chaque
  tuple, le parcours des index et le traitement de chaque item (respectivement)
  where pendant la requête. La mesure s'effectue en fraction du coût de parcours
  séquentiel d'une page.
  </entry>
  <entry>
  Les coûts par défaut sont assez arbitraires&nbsp;; c'est pourquoi ils sont
  modifiables. Toutefois, personne, au sein de la communauté n'a pu présenté de
  meilleur coûts par défaut, et la plupart du temps, les modifications on un
  effet inverse sur quelques requêtes. Ainsi, à moins de disposer de beaucoup de
  temps pour tester les requêtes, il est préférable de ne pas toucher à ces
  trois paramètres.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Optimisation génétique de requêtes (<foreignphrase>Genetic Estimate Query Optimizer, GEQO</foreignphrase>)</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>geqo</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Active ou désactive l'optimisation génétique de requêtes. Il s'agit en fait
  d'un algorithme génétique de planification de requêtes qui tente d'éviter
  les recherches exhaustives. Activé par défaut. Divers paramètres GEQO_
  permettent d'en affiner le comportement.
  </entry>
  <entry>
  <para>
  GEQO a été introduit dans PostgreSQL 6.5 pour optimiser les requêtes de
  jointures qui utilisent trop de tables pour permettre une analyse exhaustive
  par le planificateur. Par définition, les requêtes GEQO sont plus lentes que
  les requêtes habituelles. Son but est d'intervenir quand la planification
  d'une requête peut réquisitionner toute la CPU.
  </para>
  <para>
  Lorsque l'application semble faire un usage immodéré de GAQO, il peut être
  intéressant d'écrire les requêtes en explicitant l'ordre de la jointure.
  L'utilisateur a, en effet, un pouvoir dscriminant plus grand que l'algorithme.
  </para>
  </entry>
 </row>
 <!-- ICI -->
 <row>
  <entry>geqo_threshold</entry>
  <entry>2 to Int Max</entry>
  <entry>11</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Use genetic query optimization to plan queries with at least this many FROM
  items involved. (Note that a JOIN construct counts as only one FROM item.)
  The default is 11. For simpler queries it is usually best to use the
  deterministic, exhaustive planner. This parameter also controls how hard
  the optimizer will try to merge subquery FROM clauses into the upper query.
  </entry>
  <entry>
  It's possible that, on machines with very fast CPUs (dual Opteron, for
  example) raising this threshold slightly (such as to 14) is warranted.
  However, previous advice to raise it to 20 turned out to be based on an
  unusual test case and has since been disproven.
  </entry>
 </row>
 <row>
  <entry>
  <para>geqo_selection_bias</para>
  <para>geqo_pool_size</para>
  <para>geqo_effort</para>
  <para>geqo_generations</para>
  <para>geqo_random_seed</para>
  </entry>
  <entry>1.5-2.0</entry>
  <entry>
  <para>2.0</para>
  <para>0</para>
  <para>1</para>
  <para>0</para>
  <para>-1</para>
  </entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Various tuning parameters for the genetic query optimization algorithm: The
  pool size is the number of individuals in one population. Valid values are
  between 128 and 1024. If it is set to 0 (the default) a pool size of
  2^(QS+1), where QS is the number of FROM items in the query, is taken. The
  effort is used to calculate a default for generations. Valid values are
  between 1 and 80, 40 being the default. Generations specifies the number of
  iterations in the algorithm. The number must be a positive integer. If 0 is
  specified then Effort * Log2(PoolSize) is used. The run time of the algorithm
  is roughly proportional to the sum of pool size and generations. The
  selection bias is the selective pressure within the population. Values can be
  from 1.50 to 2.00; the latter is the default. The random seed can be set to
  get reproducible results from the algorithm. If it is set to -1 then the
  algorithm behaves non-deterministically.
  </entry>
  <entry></entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Query Modifiers</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>default_statistics_target</entry>
  <entry>1-1000</entry>
  <entry>10</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Sets the default statistics target for table columns that have not had a
  column-specific target set via ALTER TABLE SET STATISTICS. Larger values
  increase the time needed to do ANALYZE, but may improve the quality of the
  planner's estimates.
  </entry>
  <entry>
  Has no effect until your next ANALYZE.  Generally not recommended as a way of
  improving statistics overall except for unusual databases; for one thing,
  collecting increased statistics on wide columns (large text, for example) can
  be burdensome enough to be counter-productive.  For a database which is
  almost entirely numerical, modest increases (to 100, for example) may have
  overall benefit; otherwise, try increasing statistics on specific columns.
  </entry>
 </row>
 <row>
  <entry>from_collapse_limit</entry>
  <entry>0 to Int Max</entry>
  <entry>8</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The planner will merge sub-queries into upper queries if the resulting FROM
  list would have no more than this many items. Smaller values reduce planning
  time but may yield inferior query plans. The default is 8. It is usually
  wise to keep this less than GEQO_THRESHOLD.
  </entry>
  <entry>
  As with many other settings in this section, you want only to change this for
  specific unfixable queries at runtime.  Decreasing it should force
  materialization of some subqueries if that is desired.  Most DBAs won't want
  to change it at all.
  </entry>
 </row>
 <row>
  <entry>join_collapse_limit</entry>
  <entry>1 to Int Max</entry>
  <entry>8</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The planner will flatten explicit inner JOIN constructs into lists of FROM
  items whenever a list of no more than this many items would result. Usually
  this is set the same as FROM_COLLAPSE_LIMIT. Setting it to 1 prevents any
  flattening of inner JOINs, allowing explicit JOIN syntax to be used to
  control the join order. Intermediate values might be useful to trade off
  planning time against quality of plan.
  </entry>
  <entry>
  This option is designed for those of us who like writing our queries using
  explicit JOIN syntax (e.g. &#8220;a join b using (1) join c using (2)&#8221;),
  but would still like the planner to select the join order for best execution.
  Particularly, people switching from MS SQL Server will want to enable this
  option with a moderately high value, as that database does JOIN collapsing
  automatically. As above, keep this setting below geqo_threshold.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Logging and Debugging Options</title>

<sect2>
<title>Where To Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>log_destination</entry>
  <entry>stderr, syslog, eventlog</entry>
  <entry>stderr</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  PostgreSQL supports several methods for logging server messages, including
  stderr and syslog. On Windows, eventlog is also supported. Set this option
  to a list of desired log destinations separated by commas.
  </entry>
  <entry>
  This is analogous to the old â&#8364;&#339;syslogâ&#8364;&#157; setting, but
  with the cryptic codes removed. Also supports the Win32 â&#8364;&#339;eventlogâ&#8364;&#157;.
  When setting up your server, it's important to decide how you want to log
  PostgreSQL messages: either to syslog, which is easier for overall system
  administration, or to a private PostgreSQL log, which is better for debugging
  database problems. Of course, you can log to both, but that's probably an
  excess of output.
  </entry>
 </row>
 <row>
  <entry>redirect_stderr</entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry>
  This option allows messages sent to stderr to be captured and redirected into
  log files. This option, in combination with logging to stderr, is often more
  useful than logging to syslog, since some types of messages may not appear in
  syslog output (a common example is dynamic-linker failure messages).
  </entry>
  <entry>
  This is the new â&#8364;&#339;log rotationâ&#8364;&#157; feature. It also
  replaces the -l command line switch for pg_ctl, and/or command-line redirect.
  It is only applicable if you chose â&#8364;&#339;stderrâ&#8364;&#157; above,
  and the following 5 options only take effect if you choose this one. You can
  use redirect_stderr and turn rotation off in order to have create the same
  effect as the old -l option.
  </entry>
 </row>
 <row>
  <entry>log_directory</entry>
  <entry>directory</entry>
  <entry>pg_log</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the directory in
  which log files will be created. It may be specified as an absolute path,
  or relative to the cluster data directory.
  </entry>
  <entry>
  Defaults to a â&#8364;&#339;pg_logâ&#8364;&#157; directory in your PGDATA,
  which is probably not a wise choice if you have other disks/arrays available.
  /var/pg_log is popular.
  </entry>
 </row>
 <row>
  <entry>log_filename</entry>
  <entry>special</entry>
  <entry>postgresql-%Y-%m-%d_%H%M%S.log</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option sets the file names of the
  created log files. The value is treated as a strftime pattern, so
  %-escapes can be used to specify time-varying file names. If no
  %-escapes are present, PostgreSQL will append the epoch of the new log file's
  open time. For example, if log_filename were server_log, then the chosen file
  name would be server_log.1093827753 for a log starting at Sun Aug 29 19:02:33
  2004 MST.</entry>
  <entry>
  File name for each rotational log segment, with escapes. The default should
  suit most DBAs.  If your logs never go over size, it can be simpler to
  include only the date.  Another possible variation is to have the log record
  only the hour, or only the day of the week, in order to prevent getting more
  than a certain number of logs.  See log_truncate below.
  </entry>
 </row>
 <row>
  <entry>log_rotation_age</entry>
  <entry>0 to Int Max</entry>
  <entry>1440</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the maximum lifetime
  of an individual log file. After this many minutes have elapsed, a new log
  file will be created. Set to zero to disable time-based creation of new log
  files.
  </entry>
  <entry>
  The default (24 hours) is suitable for most installations.
  </entry>
 </row>
 <row>
  <entry>log_rotation_size</entry>
  <entry>0 to Int Max</entry>
  <entry>10240</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the maximum size of
  an individual log file. After this many kilobytes have been emitted into a
  log file, a new log file will be created. Set to zero to disable size-based
  creation of new log files.
  </entry>
  <entry>
  The default (10MB) is suitable for most installations.
  </entry>
 </row>
 <row>
  <entry>log_truncate_on_rotation</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option will cause PostgreSQL to truncate
  (overwrite), rather than append to, any existing log file of the same name.
  However, truncation will occur only when a new file is being opened due to
  time-based rotation, not during server startup or size-based rotation. When
  false, pre-existing files will be appended to in all cases. For example,
  using this option in combination with a log_filename like postgresql-%H.log
  would result in generating twenty-four hourly log files and then cyclically
  overwriting them.
  </entry>
  <entry>
  This setting can be combined with log_filename, above, to create a 7-day or
  24-hour (or 60-minute, for that matter) continuous replacement of logs.
  </entry>
 </row>
 <row>
  <entry>syslog_facility</entry>
  <entry>LOCAL#</entry>
  <entry>LOCAL0</entry>
  <entry></entry>
  <entry>Startup</entry>
  <entry>
  When logging to syslog is enabled, this option determines the syslog "facility"
  to be used. You may choose from LOCAL0, LOCAL1, LOCAL2, LOCAL3, LOCAL4, LOCAL5,
  LOCAL6, LOCAL7; the default is LOCAL0. See also the documentation of your
  system's syslog daemon.
  </entry>
  <entry>
  No recommendations.
  </entry>
 </row>
 <row>
  <entry>syslog_ident</entry>
  <entry></entry>
  <entry>postgres</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When logging to syslog is enabled, this option determines the program name
  used to identify PostgreSQL messages in syslog logs. The default is postgres.
  </entry>
  <entry>
  Those running multiple versions of PostgreSQL on the same machine will want
  to remember to change this string to indicate which server.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>When to Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>client_min_messages</para>
  <para>log_min_messages</para>
  <para>log_min_error_statement</para>
  </entry>
  <entry>
  debug5, debug4, debug3, debug2, debug1,
  info, notice, warning, error, log, fatal, panic
  </entry>
  <entry>
  <para>notice</para>
  <para>notice</para>
  <para>panic</para>
  </entry>
  <entry>
  <para>Runtime</para>
  <para>Superuser</para>
  <para>Superuser</para>
  </entry>
  <entry>-d x</entry>
  <entry>
  <para>
  This controls how much message detail is written to the server logs and the
  client. Valid values are DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO,
  NOTICE, WARNING, ERROR, LOG, FATAL, and PANIC. Later values send less detail
  to the logs. The default is NOTICE. Note that LOG has a different precedence
  here than in CLIENT_MIN_MESSAGES.
  </para>
  <para>
  client_min_messages outputs to the client session; log_min_messages to the
  log, and log_min_error_statement controls recording of SQL errors to the log.
  </para>
  </entry>
  <entry>
  <para>
  Raising debug levels is always good for testing applications; DEBUG1 is a good
  setting for general troubleshooting.  NOTICE is suitable for general
  production, and thourougly tested systems can probably be reduced to ERROR or
  even FATAL.
  </para>
  <para>
  The cost is greater use of disk space, some minor performance cost for output
  (usually &lt; 5%). However, the performance cost increases significantly if
  your logs are on the same disk/array as WAL or your database, as heavy debug
  output will take I/O away from database activity. The impact of debug5 on a
  high-transaction single-disk system can be quite high.  This caution applys
  to all of the loggin options below.
  </para>
  </entry>
 </row>
 <row>
  <entry>log_error_verbosity</entry>
  <entry>terse, default, verbose</entry>
  <entry>default</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Controls the amount of detail written in the server log for each message
  that is logged. Valid values are TERSE, DEFAULT, and VERBOSE, each adding
  more fields to displayed messages.
  </entry>
  <entry>
  What setting you use here depends on your production status, and what
  log-monitoring tools you are using.
  </entry>
 </row>
 <row>
  <entry>log_min_duration_statement</entry>
  <entry>-1 to Int Max</entry>
  <entry>-1</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Sets a minimum statement execution time (in milliseconds) that causes a
  statement to be logged. All SQL statements that run for the time specified
  or longer will be logged with their duration. Setting this to zero will
  print all queries and their durations. Minus-one (the default) disables the
  feature. For example, if you set it to 250 then all SQL statements that run
  250ms or longer will be logged. Enabling this option can be useful in tracking
  down unoptimized queries in your applications.
  </entry>
  <entry>
  This setting is extremely useful for second-stage database tuning. Once
  you've taken care the bulk of the indexing and performance issues,
  log_min_duration_statement will allow you to log only the slowest (and
  possibly still broken) queries.
  </entry>
 </row>
 <row>
  <entry>silent_mode</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Runs the server silently. If this option is set, the server will automatically
  run in background and any controlling terminals are disassociated (same effect
  as postmaster's -S option). The server's standard output and standard error
  are redirected to /dev/null, so any messages sent to them will be lost. Unless
  syslog logging is selected or redirect_stderr is enabled, using this option is
  discouraged because it makes it impossible to see error messages.
  </entry>
  <entry>
  The documentation pretty much covers it.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>What to Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>debug_print_parse</para>
  <para>debug_print_rewritten</para>
  <para>debug_print_plan</para>
  <para>debug_pretty_print</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  These flags enable various debugging output to be sent to the server log. For
  each executed query, print either the query text, the resulting parse tree,
  the query rewriter output, or the execution plan. DEBUG_PRETTY_PRINT indents
  these displays to produce a more readable but much longer output format.
  </entry>
  <entry>
  Can be useful for detecting common slow queries if you are able to wade
  through the voluminous log output. Particularly useful in interactive log
  watching when procedures hang; you can sometimes see exactly what step
  hangs (sometimes you can't, though, because the log waits on the database).
  </entry>
 </row>
 <row>
  <entry>
  <para>log_connections</para>
  <para>log_disconnections</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  log_connections outputs a line to the server log detailing each successful
  connection. log_disconnections outputs a line in the server log similar to
  log_connections but at session termination, and includes the duration of the
  session.
  </entry>
  <entry>
  Essential logging items for any secure application.
  </entry>
 </row>
 <row>
  <entry>log_hostname</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  By default, connection logs only show the IP address of the connecting host.
  If you want it to show the host name you can turn this on, but depending on
  your host name resolution setup it might impose a non-negligible performance
  penalty.
  </entry>
  <entry>
  This can be useful for debugging/security management, but if DNS is not local
  can delay new connections significantly.
  </entry>
 </row>
 <row>
  <entry>log_statement</entry>
  <entry>None, DDL, Mod, All</entry>
  <entry>False</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Controls which SQL statements are logged. Valid values are none, ddl, mod,
  and all. ddl logs all data definition commands like CREATE, ALTER, and DROP
  commands. mod logs all ddl statements, plus INSERT, UPDATE, DELETE, TRUNCATE,
  and COPY FROM. PREPARE and EXPLAIN ANALYZE statements are also logged if
  their contained command is of an appropriate type.
  </entry>
  <entry>
  This setting has been improved and expanded by the ability to log only
  database changes, or only updates/inserts/deletes. Please see also the
  limitations on this feature, mentioned in the docs.
  </entry>
 </row>
 <row>
  <entry>log_duration</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Causes the duration of every completed statement which satisfies
  log_statement to be logged. When using this option, if you are not using
  syslog, it is recommended that you log the PID or session ID using
  log_line_prefix so that you can link the statement to the duration using
  the process ID or session ID.
  </entry>
  <entry>
  Essential to first-state database tuning. The PQA log digest utility, for
  example, requires log_statement and log_duration options to supply you with
  a list of the slowest and the most frequent queries. Only takes effect if
  log_statement is at least â&#8364;&#339;DDLâ&#8364;&#157;.
  </entry>
 </row>
 <row>
  <entry>log_line_prefix</entry>
  <entry>Special</entry>
  <entry>''</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  This is a printf-style string that is output at the beginning of each log
  line. The default is an empty string. Each recognized escape is replaced as
  outlined in the docs - anything else that looks like an escape is ignored.
  Other characters are copied straight to the log line. Some escapes are only
  recognized by session processes, and do not apply to background processes
  such as the postmaster. Syslog produces its own time stamp and process ID
  information, so you probably do not want to use those escapes if you are
  using syslog.
  </entry>
  <entry>
  <para>
  Replaces log_pid, log_source_port, log_timestamp, and a host of home-grown
  logging techniques to supply exactly the detail wanted with each log line.
  </para>
  <para>
  For example, if you were trying to diagnose a deadlocking problem, you might
  use  â&#8364;&#339;%t %p %u %d %xâ&#8364;&#157; to give you the information
  you need. No doubt in the future log tools will develop which expect specific
  formats for these, but none exist yet.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Statistics</title>

<sect2>
<title>Statistics Logging</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>log_parser_stats</para>
  <para>log_planner_stats</para>
  <para>log_executor_stats</para>
  <para>log_statement_stats</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Superuser</entry>
  <entry>
  <para>-tpa</para>
  <para>-tpl</para>
  <para>-te</para>
  <para>-s</para>
  </entry>
  <entry>
  For each query, write performance statistics of the respective module to the
  server log. This is a crude profiling instrument. log_statement_stats reports
  total statement statistics, while the others report per-state statistics.
  log_statement_stats can not be enabled with the other options. All of these
  options are disabled by default. Only superusers can turn off any of these
  options if they have been enabled by the administrator.
  </entry>
  <entry>
  Unless you have a serious log-crunching tool designed to crunch this
  information it's of limited usefulness due to sheer volume.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Query and Index Statistics</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>stats_start_collector</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Controls whether the server should start the statistics-collection subprocess.
  </entry>
  <entry>
  Unless the 5% or so overhead created by the statistics collector is critical
  for your system, you should turn on at least start_collector and
  stats_command_string.
  </entry>
 </row>
 <row>
  <entry>stats_reset_on_server_start</entry>
  <entry></entry>
  <entry>True</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  If on, collected statistics are zeroed out whenever the server is restarted.
  If off, statistics are accumulated across server restarts.
  </entry>
  <entry>
  If routine database restarts are part of your maintenance plan, then you
  probably want to turn this off or you'll have difficulty accumulating enough
  statistics to be useful.  Otherwise, leave it on.
  </entry>
 </row>
 <row>
  <entry>stats_command_string</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of statistics on the currently executing command of
  each session, along with the time at which that command began execution.
  This option is off by default. Note that even when enabled, this information
  is not visible to all users, only to superusers and the user owning the
  session being reported on; so it should not represent a security risk. This
  data can be accessed via the pg_stat_activity system view.
  </entry>
  <entry>
  This allows you to use pg_stat_activity view to track current queries, which
  can be invaluable for troubleshooting.  Most DBAs will want this on.
  </entry>
 </row>
 <row>
  <entry>stats_row_level</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of row-level statistics on database activity. This
  option is disabled by default. If this option is enabled, the data that
  is produced can be accessed via the pg_stat and pg_statio family of system
  views.
  </entry>
  <entry>
  This option enables the collection of some statistics on index and table use.
  Vitally important during initial database tuning, it becomes less useful in
  production and should probably be turned off then.
  </entry>
 </row>
 <row>
  <entry>stats_block_level</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of block-level statistics on database activity. This
  option is disabled by default.
  </entry>
  <entry>
  Gives block-level stats, which are useful in monitoring I/O and cache hit
  performance for turning system variables and hardware. Again, turn it on
  during system testing, and back off in production.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Client Connection Defaults</title>

<sect2>
<title>Statement Behavior</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>search_path</entry>
  <entry>path</entry>
  <entry>'$user,public'</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  <para>
  This variable specifies the order in which schemas are searched when an
  object (table, data type, function, etc.) is referenced by a simple name
  with no schema component. When there are objects of identical names in
  different schemas, the one found first in the search path is used. An object
  that is not in any of the schemas in the search path can only be referenced
  by specifying its containing schema with a qualified (dotted) name.
  </para>
  <para>
  The value for search_path has to be a comma-separated list of schema names.
  If one of the list items is the special value $user, then the schema having
  the name returned by SESSION_USER is substituted, if there is such a schema.
  (If not, $user is ignored.) The system catalog schema, pg_catalog, is always
  searched, whether it is mentioned in the path or not.
  </para>
  </entry>
  <entry>
  <para>
  This is a variable to manipulate after you have the schema design for your
  database, but not necessarily in this file.  For example, you may with to
  set search_path by user, which is done through ALTER USER and not through
  this GUC.
  </para>
  <para>
  On the other hand, if you are using multiple schema which should be visible
  to all users, remember to add the additional schema to the search_path in
  postgresql.conf.
  </para>
  </entry>
 </row>
 <row>
  <entry>default_tablespace</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This variable specifies the default tablespace in which to create objects
  (tables and indexes) when a CREATE command does not explicitly specify a
  tablespace.  The value is either the name of a tablespace, or an empty string
  to specify using the default tablespace of the current database. If the value
  does not match the name of any existing tablespace, PostgreSQL will
  automatically use the default tablespace of the current database.
  </entry>
  <entry>
  It is unlikely that you will want to set this in the .conf file; see ALTER
  DATABASE instead.
  </entry>
 </row>
 <row>
  <entry>check_function_bodies</entry>
  <entry>True, False</entry>
  <entry>True</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This parameter is normally true. When set to false, it disables validation of
  the function body string during CREATE FUNCTION. Disabling validation is
  occasionally useful to avoid problems such as forward references when
  restoring function definitions from a dump.
  </entry>
  <entry>
  As with the others, not to be set in the .conf file for general purposes.
  </entry>
 </row>
 <row>
  <entry>default_transaction_isolation</entry>
  <entry>read committed, serializable</entry>
  <entry>'read committed'</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Each SQL transaction has an isolation level, which can be either "read
  uncommitted", "read committed", "repeatable read", or "serializable". This
  parameter controls the default isolation level of each new transaction. The
  default is "read committed".
  </entry>
  <entry>
  The default, here, is the value that supports standard MVCC behavior.
  â&#8364;&#339;Serializableâ&#8364;&#157; is mainly useful for when you need
  to launch long-running procedures which must be successive, or when your
  updates pose a significant and regular risk of deadlock. Under a heavy
  multi-user load, setting â&#8364;&#339;serializableâ&#8364;&#157; can impose
  a significant penalty as numerous transactions are forced to wait for the
  serialized transaction to complete. In a single-user database, there should
  be little effect.  In any case, not to be set in the .conf file but rather at
  runtime.
  </entry>
 </row>
 <row>
  <entry>default_transaction_read_only</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  A read-only SQL transaction cannot alter non-temporary tables. This parameter
  controls the default read-only status of each new transaction. The default is
  false (read/write).
  </entry>
  <entry>
  Potentially useful for individual connections, but not as useful to set in
  .conf file, unless you want to force a lot of users into read-only mode (and
  assume that they don't know how to use SET commands).
  </entry>
 </row>
 <row>
  <entry>statement_timeout</entry>
  <entry>0 to Int Max</entry>
  <entry>0</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Aborts any statement that takes over the specified number of milliseconds.
  A value of zero turns off the timer.
  </entry>
  <entry>
  Designed to help the application where it is possible to users to execute
  queries that swamp the CPU for minutes, such as apps that allow dynamic
  queries. Setting this value to a finite amount can prevent those users from
  monopolizing resources, but you'll need to be prepared to deal with the
  exception, which is the same error as â&#8364;&#339;query cancelled by
  userâ&#8364;&#157;.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Locale and Formatting</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>datestyle</para>
  <para>timezone</para>
  <para>australian_timezones</para>
  </entry>
  <entry></entry>
  <entry>
  <para>'iso, us'</para>
  <para>unknown</para>
  <para>false</para>
  </entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  <para>
  Sets the display format for dates, as well as the rules for interpreting
  ambiguous input dates.
  </para>
  <para>
  Sets the time zone for displaying and interpreting timestamps. The default
  is to use whatever the system environment specifies as the time zone.
  </para>
  <para>
  If set to true, CST, EST, and SAT are interpreted as Australian time zones
  rather than as North American Central/Eastern time zones and Saturday.
  </para>
  </entry>
  <entry>
  For changing the default display of dates and interpretation of timezones to
  suit your locality and/or organization standards.
  </entry>
 </row>
 <row>
  <entry>extra_float_digits</entry>
  <entry>-14 to 2</entry>
  <entry>0</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  This parameter adjusts the number of digits displayed for floating-point
  values, including float4, float8, and geometric data types. The parameter
  value is added to the standard number of digits (FLT_DIG or DBL_DIG as
  appropriate). The value can be set as high as 2, to include
  partially-significant digits; this is especially useful for dumping float
  data that needs to be restored exactly. Or it can be set negative to suppress
  unwanted digits.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>
  <para>lc_messages</para>
  <para>lc_monetary</para>
  <para>lc_time</para>
  <para>lc_numeric</para>
  </entry>
  <entry>System-dependent</entry>
  <entry>Special</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the locale to use for formatting error messages, monetary amounts, time
  and numeric values. Acceptable values are system-dependent; see Section 7.1
  for more information. If this variable is set to the empty string (which is
  the default) then the value is inherited from the execution environment of
  the server in a system-dependent way.
  </entry>
  <entry>
  These settings are set by the initdb script when it creates your PGDATA
  directory. Should be set to your language, currency, etc, or 'C'
  locale for some installations.
  </entry>
 </row>
 <row>
  <entry>client_encoding</entry>
  <entry>OS-dependent</entry>
  <entry>sql_ascii</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Sets the client-side encoding for multi-byte character sets. The default is
  to use the database encoding.
  </entry>
  <entry>
  Usually ignored in favor of database encoding. Would be set per client only
  for multi-lingual applications, which would then require considerable care to
  manage the different encodings.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Defaults</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>explain_pretty_print</entry>
  <entry>True,False</entry>
  <entry>False</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Determines whether EXPLAIN VERBOSE uses the indented or non-indented format
  for displaying detailed query-tree dumps.
  </entry>
  <entry>
  If you need to use EXPLAIN VERBOSE, pretty_print is essential for readability;
  set it to True. It's a rare occasion where VERBOSE is needed, though.
  </entry>
 </row>
 <row>
  <entry>dynamic_library_path</entry>
  <entry>path</entry>
  <entry>'$libdir'</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  If a dynamically loadable module needs to be opened and the specified name
  does not have a directory component (i.e. the name does not contain a slash),
  the system will search this path for the specified file. (The name that is
  used is the name specified in the CREATE FUNCTION or LOAD command.)
  </entry>
  <entry>
  Can be SET by superuser.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Lock Management</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>deadlock_timeout</entry>
  <entry>1 to Int Max</entry>
  <entry>1000</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  This is the amount of time, in milliseconds, to wait on a lock before
  checking to see if there is a deadlock condition. The check for deadlock is
  relatively slow, so the server doesn't run it every time it waits for a lock.
  We (optimistically?) assume that deadlocks are not common in production
  applications and just wait on the lock for a while before starting check for
  a deadlock. Increasing this value reduces the amount of time wasted in
  needless deadlock checks, but slows down reporting of real deadlock errors.
  The default is 1000 (i.e., one second), which is probably about the smallest
  value you would want in practice. On a heavily loaded server you might want
  to raise it. Ideally the setting should exceed your typical transaction time,
  so as to improve the odds that the lock will be released before the waiter
  decides to check for deadlock.
  </entry>
  <entry>
  No recommendations aside from those in the documentation.
  </entry>
 </row>
 <row>
  <entry>max_locks_per_transaction</entry>
  <entry>10 to Int Max</entry>
  <entry>64</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  The shared lock table is sized on the assumption that at most
  max_locks_per_transaction * max_connections distinct objects will need to be
  locked at any one time. The default, 64, which has historically proven
  sufficient, but you might need to raise this value if you have clients that
  touch many different tables in a single transaction. This option can only be
  set at server start.
  </entry>
  <entry>
  Occasionally it can be necessary to raise this parameter in star-schema
  database with hundreds of lookup tables. It's better to act in response to
  the error, though, than to anticipate.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Version and Platform Compatibility</title>

<sect2>
<title>Previous PostgreSQL Versions</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>add_missing_from</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Enables planner to â&#8364;&#339;Add Missing From Clauseâ&#8364;&#157; when
  you omit a table from your query. Will be False by default in future versions.
  When true, tables that are referenced by a query will be automatically added
  to the FROM clause if not already present. The default is true for
  compatibility with previous releases of PostgreSQL. However, this behavior is
  not SQL-standard, and many people dislike it because it can mask mistakes
  (such as referencing a table where you should have referenced its alias).
  Set to false for the SQL-standard behavior of rejecting references to tables
  that are not listed in FROM.
  </entry>
  <entry>
  Always set this to false.  If it's set to true, a simple mis-reference of a
  table alias can result in an unconstrained join, and a runaway query that
  will soak up your system resources.  This will hopefully be false by default
  in the future.
  </entry>
 </row>
 <row>
  <entry>regex_flavor</entry>
  <entry>advanced, extended, basic</entry>
  <entry>advanced</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The regular expression "flavor" can be set to advanced, extended, or basic.
  The usual default is advanced. The extended setting may be useful for exact
  backwards compatibility with pre-7.4 releases of PostgreSQL.
  </entry>
  <entry>
  What you set here is pretty much dependent on what kind of regex behavior
  you're used to.  Programmers in Perl, Java, and other languages will be
  familiar with Advanced; other users may wish the less complex syntax of
  Basic.  Do not change this after your database testing is complete, as it
  could change the results of queries.
  </entry>
 </row>
 <row>
  <entry>sql_inheritance</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This controls the inheritance semantics, in particular whether subtables are
  included by various commands by default. They were not included in versions
  prior to 7.1. If you need the old behavior you can set this variable to off,
  but in the long run you are encouraged to change your applications to use the
  ONLY keyword to exclude subtables.
  </entry>
  <entry>
  Only needed for people upgrading 7.0 applications.
  </entry>
 </row>
 <row>
  <entry>default_with_oids</entry>
  <entry>True, false</entry>
  <entry>True</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This controls whether CREATE TABLE and CREATE TABLE AS include an OID column
  in newly-created tables, if neither WITH OIDS nor WITHOUT OIDS is specified.
  It also determines whether OIDs will be included in tables created by SELECT
  INTO. In PostgreSQL 8.0.0 default_with_oids defaults to true. This is also
  the behavior of previous versions of PostgreSQL. However, assuming that
  tables will contain OIDs by default is not encouraged. This option will
  probably default to false in a future release of PostgreSQL.
  </entry>
  <entry>
  In a database with very large tables, it can be useful to set this to false.
  This will save you around 8 bytes per row, which across millions of rows can
  make a difference.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Platform and Client Compatibility</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>transform_null_equals</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  When turned on, expressions of the form expr = NULL (or NULL = expr) are
  treated as expr IS NULL, that is, they return true if expr evaluates to the
  null value, and false otherwise. The correct behavior of expr = NULL is to
  always return null (unknown).
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>custom_variable_classes</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  This variable specifies one or several class names to be used for custom
  variables, in the form of a comma-separated list. A custom variable is a
  variable not normally known to PostgreSQL proper but used by some add-on
  module. Such variables must have names consisting of a class name, a dot,
  and a variable name. custom_variable_classes specifies all the class names
  in use in a particular installation.
  </entry>
  <entry>
  The add-in modules which require this (e.g. PL/Java) should have instructions
  on how to set it.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

</article>
