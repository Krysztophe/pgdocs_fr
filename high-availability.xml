<?xml version="1.0" encoding="ISO-8859-15"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

<chapter id="high-availability">
 <title>Haute disponibilité, répartition de charge et réplication</title>

 <indexterm><primary>haute disponibilité</primary></indexterm>
 <indexterm><primary>failover</primary></indexterm>
 <indexterm><primary>réplication</primary></indexterm>
 <indexterm><primary>répartition de charge</primary></indexterm>
 <indexterm><primary>clustering</primary></indexterm>
 <indexterm><primary>partitionnement de données</primary></indexterm>

<!-- seamlessly ? -->
 <para>
  Des serveurs de bases de données peuvent travailler ensemble pour permettre
  à un serveur secondaire de prendre rapidement la main si le serveur principal
  échoue (haute disponibilité, ou <foreignphrase>high availability</foreignphrase>),
  ou pour permettre à plusieurs serveurs de servir les mêmes données (répartition
  de charge, ou <foreignphrase>load balancing</foreignphrase>). Idéalement, les
  serveurs de bases de données peuvent travailler ensemble sans jointure.
  </para>
  <para>
  Il est aisé de faire coopérer des serveurs web qui traitent des pages web statiques
  en répartissant la charge des requêtes web sur plusieurs
  machines. Dans les faits, les serveurs de bases de données en lecture seule peuvent
  également coopérer facilement. Malheureusement, la plupart des
  serveurs de bases de données traitent des requêtes de lecture/écriture et,
  de ce fait, collaborent plus difficilement. En effet, alors qu'il suffit de
  placer une seule fois les données en lecture seule sur chaque serveur, une
  écriture sur n'importe quel serveur doit, elle, être propagée à tous les
  serveurs afin que les lectures suivantes sur ces serveurs renvoient des résulats
  cohérents.
 </para>

 <para>
  Ce problème de synchronisation représente la difficulté fondamentale à la
  collaboration entre serveurs. Comme la solution au problème de
  synchronisation n'est pas unique pour tous les cas pratiques, plusieurs
  solutions co-existent. Chacune répond de façon différente et minimise
  cet impact au regard d'une charge spécifique.
 </para>

 <para>
  Certaines solutions gèrent la synchronisation en autorisant les modifications
  des données sur un seul serveur. Les serveurs qui peuvent modifier les données
  sont appelés serveurs en lecture/écriture ou serveurs maîtres. Les serveurs qui
  peuvent répondre aux requêtes en lecture seule sont appelés serveurs
  esclaves. Les serveurs qui ne sont pas accessibles tant qu'ils ne se sont pas
  promus en serveurs maîtres sont appelées serveurs en attente
  (<foreignphrase>standby servers</foreignphrase>).
 </para>

 <para>
  Certaines solutions sont synchrones, ce qui signifie qu'une transaction de
  modification de données n'est pas considérée valide tant que tous les
  serveurs n'ont pas validé la transaction. Ceci garantit qu'un
  <foreignphrase>failover</foreignphrase> ne perd pas de données et que tous
  les serveurs en répartition de charge retournent des résultats cohérents, quel
  que soit le serveur interrogé. Au contraire, les solutions asynchrones
  autorisent un délai entre la validation et sa propagation aux
  autres serveurs. Cette solution implique une éventuelle perte de transactions
  lors de la bascule sur un serveur de sauvegarde, ou l'envoi de données
  obsolètes par les serveurs à charge répartie. La communication asynchrone est
  utilisée lorsque la version synchrone est trop lente.
 </para>

 <para>
  Les solutions peuvent aussi être catégorisées par leur granularité. Certaines
  ne gèrent que la totalité d'un serveur de bases alors que
  d'autres autorisent un contrôle par table ou par base.
 </para>

 <para>
  Il importe de considérer les performances dans tout choix. Il y
  a généralement un compromis à trouver entre les fonctionnalités et les
  performances. Par exemple, une solution complètement synchrone sur un réseau
  lent peut diviser les performances par plus de deux, alors qu'une
  solution asynchrone peut n'avoir qu'un impact minimal sur les performances.
 </para>

 <para>
  Le reste de cette section souligne différentes solutions de
  <foreignphrase>failover</foreignphrase>, de réplication et de répartition de
  charge. Un <ulink
  url="http://www.postgres-r.org/documentation/terms">glossaire</ulink> est
  aussi disponible.
 </para>

 <variablelist>

 <varlistentry>
  <term><foreignphrase>Failover</foreignphrase> sur disque partagé</term>
  <listitem>

   <para>
    Le <foreignphrase>failover</foreignphrase> (ou bascule sur incident)
    sur disque partagé élimine la surcharge de synchronisation par
    l'existence d'une seule copie de la base de données. Il utilise un
    seul ensemble de disques partagé par plusieurs serveurs. Si le serveur
    principal échoue, le serveur en attente
    est capable de monter et démarrer la base comme s'il récupérait d'un
    arrêt brutal. Cela permet un <foreignphrase>failover</foreignphrase>
    rapide sans perte de données.
   </para>

   <para>
    La fonctionnalité de matériel partagé est commune aux périphériques de
    stockage en réseau. Il est également possible d'utiliser un système de
    fichiers réseau bien qu'il faille porter une grande attention au système de
    fichiers pour s'assurer qu'il a un comportement <acronym>POSIX</acronym>
    complet (voir <xref linkend="creating-cluster-nfs"/>). Cette méthode
    comporte une limitation significative&nbsp;: si les disques ont un
    problème ou sont corrompus, le serveur primaire et le serveur en attente sont tous
    les deux non fonctionnels. Un autre problème est que le serveur en attente
    ne devra jamais accéder au stockage partagé tant que le serveur principal
    est en cours d'exécution.
   </para>

   </listitem>
  </varlistentry>

  <varlistentry>
   <term>Réplication de système de fichiers (périphérique bloc)</term>
   <listitem>

   <para>
    Il est aussi possible d'utiliser cette fonctionnalité d'une autre façon
    avec une réplication du système de fichiers, où toutes les modifications
    d'un système de fichiers sont renvoyées sur un système de fichiers situé
    sur un autre ordinateur. La seule restriction est que ce miroir doit être
    construit de telle sorte que le serveur en attente dispose d'une
    version cohérente du système de fichiers &mdash; spécifiquement, les
    écritures sur le serveur en attente doivent être réalisées dans le même
    ordre que celles sur le maître. <productname>DRBD</productname> est une
    solution populaire de réplication de systèmes de fichiers pour Linux.
   </para>

<!--
https://forge.continuent.org/pipermail/sequoia/2006-November/004070.html

Oracle RAC is a shared disk approach and just send cache invalidations
to other nodes but not actual data. As the disk is shared, data is
only committed once to disk and there is a distributed locking
protocol to make nodes agree on a serializable transactional order.
-->

  </listitem>
 </varlistentry>

 <varlistentry>
  <term><foreignphrase>Warm Standby</foreignphrase> en utilisant
    <acronym>PITR</acronym></term>
  <listitem>

   <para>
    Un serveur <foreignphrase>warm standby</foreignphrase> (voir <xref
    linkend="warm-standby"/>) peut conserver sa cohérence en lisant un flux
    d'enregistrements de <acronym>WAL</acronym>. Si le serveur principal
    échoue, le serveur
    <foreignphrase>warm standby</foreignphrase> contient pratiquement toutes
    les données du serveur principal et peut rapidement devenir le nouveau
    serveur maître. Ceci est asynchrone et ne peut se faire que pour le
    serveur de bases complet.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term>Réplication maître/esclave</term>
  <listitem>

   <para>
    Une configuration de réplication maître/esclave envoie toutes les requêtes
    de modification de données au serveur maître. Ce serveur envoie les
    modifications de données de façon asynchrone au serveur esclave. L'esclave
    peut répondre aux requêtes en lecture seule alors que le serveur maître
    est en cours d'exécution. Le serveur esclave est idéal pour les requêtes
    vers un entrepôt de données.
   </para>

   <para>
    <productname>Slony-I</productname> est un exemple de ce type de
    réplication, avec une granularité par
    table et un support des esclaves multiples. Comme il met à jour le serveur
    esclave de façon asynchrone (par lots), il existe une possibilité de perte
    de données pendant un <foreignphrase>failover</foreignphrase>.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term><foreignphrase>Middleware</foreignphrase> de réplication basé sur les
    instructions</term>
  <listitem>

   <para>
    Avec les <foreignphrase>middleware</foreignphrase> de réplication basés
    sur les instructions, un programme intercepte chaque requête SQL et
    l'envoie à un ou tous les serveurs. Chaque serveur opère indépendamment.
    Les requêtes en lecture/écriture sont envoyées à tous les serveurs alors
    que les requêtes en lecture seule ne peuvent être envoyées qu'à un seul
    serveur, ce qui permet de distribuer la charge de lecture.
   </para>

   <para>
    Si les requêtes sont envoyées sans modification, les fonctions comme
    <function>random()</function>, <function>CURRENT_TIMESTAMP</function> ainsi
    que les séquences ont des valeurs différentes sur les différents serveurs.
    Cela parce que chaque serveur opère indépendamment alors que
    les requêtes SQL sont diffusées (et non les données
    modifiées). Si cette solution est inacceptable, le
    <foreignphrase>middleware</foreignphrase> ou l'application doivent
    demander ces valeurs à un seul serveur, et les utiliser dans
    des requêtes d'écriture. De plus, il est impératif que
    toute transaction soit validée ou annulée sur tous les serveurs,
    éventuellement par validation en deux phases (<xref
    linkend="sql-prepare-transaction"
    endterm="sql-prepare-transaction-title"/> et <xref
    linkend="sql-commit-prepared" endterm="sql-commit-prepared-title"/>.
    <productname>Pgpool-II</productname> et <productname>Sequoia</productname>
    sont des exemples de ce type de réplication.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term>Réplication asynchrone multi-maîtres</term>
  <listitem>

   <para>
    Pour les serveurs qui ne sont pas connectés en permanence, comme les
    ordinateurs portables ou les serveurs distants, conserver la cohérence des données
    entre les serveurs est un challenge. L'utilisation de la réplication asynchrone
    multi-maîtres permet à chaque serveur de fonctionner indépendamment. Il
    communique alors périodiquement avec les autres serveurs pour identifier les transactions
    conflictuelles. La gestion des conflits est alors confiée aux utilisateurs
    ou à un système de règles de résolution.
     Bucardo is an example of this type of replication.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term>Réplication synchrone multi-maîtres</term>
  <listitem>

   <para>
    Dans les réplications synchrones multi-maîtres, tous les serveurs acceptent
    les requêtes en écriture. Les données modifiées sont transmises
    du serveur d'origine à tous les autres serveurs avant toute validation de
    transaction.
   </para>
   <para>
    Une activité importante en écriture peut être la cause d'un
    verrouillage excessif et conduire à un effondrement des performances. Dans
    les faits, les performances en écriture sont souvent pis que celles d'un
    simple serveur.
   </para>
   <para>
    Tous les serveurs acceptent les requêtes en lecture.
   </para>
   <para>
    Certaines implantations utilisent les disques partagés pour réduire la surcharge
    de communication.
   </para>
   <para>
    Les performances de la réplication synchrone multi-maîtres sont meilleures lorsque
    les opérations de lecture représentent l'essentiel de la charge, alors que
    son gros avantage est l'acceptation des requêtes d'écriture par tous les
    serveurs &mdash; 
    il n'est pas nécessaire de répartir la charge entre les serveurs
    maîtres et esclaves et, parce que les modifications de données sont envoyées
    d'un serveur à l'autre, les fonctions non déterministiques, comme
    <function>random()</function>, ne posent aucun problème.
   </para>

   <para>
    <productname>PostgreSQL</productname> n'offre pas ce type de réplication,
    mais la validation en deux phases de <productname>PostgreSQL</productname>
    (<xref linkend="sql-prepare-transaction"
    endterm="sql-prepare-transaction-title"/> et <xref
    linkend="sql-commit-prepared" endterm="sql-commit-prepared-title"/>)
    autorise son intégration dans une application ou un
    <foreignphrase>middleware</foreignphrase>.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term>Solutions commerciales</term>
  <listitem>

   <para>
    Parce que <productname>PostgreSQL</productname> est libre et facilement
    extensible, certaines sociétés utilisent <productname>PostgreSQL</productname>
    dans des solutions commerciales fermées
    (<foreignphrase>closed-source</foreignphrase>) proposant des fonctionnalités de
    bascule sur incident (<foreignphrase>failover</foreignphrase>),
    réplication et répartition de charge.
   </para>
  </listitem>
 </varlistentry>

 </variablelist>

 <para>
  La <xref linkend="high-availability-matrix"/> résume les
  possibilités des différentes solutions listées plus-haut.
 </para>

 <table id="high-availability-matrix">
  <title>Matrice de fonctionnalités&nbsp;: haute disponibilité, répartition de
    charge et réplication</title>
  <tgroup cols="8">
   <thead>
    <row>
     <entry>Fonctionnalité</entry>
     <entry>Bascule par disques partagés (<foreignphrase>Shared Disk
     Failover</foreignphrase>)</entry>
     <entry>Réplication par système de fichiers</entry>
     <entry>Secours semi-automatique (<foreignphrase>Warm
     Standby</foreignphrase>) par <acronym>PITR</acronym></entry>
     <entry>Réplication maître/esclave</entry>
     <entry><foreignphrase>Middleware</foreignphrase> de réplication
       sur instructions</entry>
     <entry>Réplication asynchrone multi-maîtres</entry>
     <entry>Réplication synchrone multi-maîtres</entry>
    </row>
   </thead>

   <tbody>

    <row>
     <entry>Most Common Implementation</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">PITR</entry>
     <entry align="center">Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>Méthode de communication</entry>
     <entry align="center">Disque partagé</entry>
     <entry align="center">Blocs disque</entry>
     <entry align="center">WAL</entry>
     <entry align="center">Lignes de tables</entry>
     <entry align="center">SQL</entry>
     <entry align="center">Lignes de tables</entry>
     <entry align="center">Lignes de tables et verrous de ligne</entry>
    </row>

    <row>
     <entry>No special hardware required</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>Allows multiple master servers</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>No master server overhead</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>No waiting for multiple servers</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>Master failure will never lose data</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>Slaves accept read-only queries</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>Per-table granularity</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>No conflict resolution necessary</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
    </row>

   </tbody>
  </tgroup>
 </table>

 <para>
  Certaines solutions n'entrent pas dans les catégories ci-dessus&nbsp;:
 </para>

 <variablelist>

 <varlistentry>
  <term>Partitionnement de données</term>
  <listitem>

   <para>
    Le partitionnement des données divise les tables en ensembles de données.
    Chaque ensemble ne peut être modifié que par un seul serveur. Les
    données peuvent ainsi être partitionnées par bureau, Londres et
    Paris, par exemple, avec un serveur dans chaque bureau. Si certaines
    requêtes doivent combiner des données de Londres et Paris, il est possible
    d'utiliser une application qui requête les deux serveurs ou d'implanter une
    réplication maître/esclave pour conserver sur chaque serveur une copie en lecture
    seule des données de l'autre bureau.
   </para>
  </listitem>
 </varlistentry>

 <varlistentry>
  <term>Exécution de requêtes en parallèle sur plusieurs serveurs</term>
  <listitem>

   <para>
    La plupart des solutions ci-dessus permettent à plusieurs serveurs de
    répondre à des requêtes multiples, mais aucune ne permet à une seule requête
    d'être exécutée sur plusieurs serveurs pour se terminer plus rapidement.
    Cette solution autorisent plusieurs serveurs à travailler ensemble sur une
    seule requête. Ceci s'accomplit habituellement en répartissant les données
    entre les serveurs, chaque serveur exécutant une partie de la
    requête pour renvoyer les résultats à un serveur central qui les combine
    et les renvoie à l'utilisateur. <productname>Pgpool-II</productname>
    offre cette possibilité. Cela peut également être implanté en utilisant les
    outils <productname>PL/Proxy</productname>.
   </para>
  </listitem>
 </varlistentry>

 </variablelist>

</chapter>
