<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

<sect1 id="maintenance">
<title>Maintenance</title>
<indexterm><primary>maintenir &slony1;</primary></indexterm>

<para>
  &slony1; effectue une grande partie de sa maintenance lui-même, dans un
  processus de <quote>nettoyage</quote> qui&nbsp;:

  <itemizedlist>
    <listitem>
      <para>
        supprime les anciennes données sur les différentes tables du schéma
        de <productname>Slony-I</productname>, notamment &sllog1;, &sllog2;
	et &slseqlog;&nbsp;;
      </para>
    </listitem>

    <listitem>
      <para>
        effectue un VACUUM sur certaines tables utilisées par &slony1;. À
	partir de la version 1.0.5, ceci inclut &pglistener;&nbsp;; dans les
	versions antérieures, vous devez lancer souvent des VACUUM sur cette
	table, sinon vous verrez votre réplication ralentir car &slony1; lève
	beaucoup d'événements, qui mènent à ce que la table contienne de
	nombreuses lignes mortes.
      </para>

      <para>
        Avec certaines versions (la 1.1, peut-être la 1.0.5), il est possible
	de ne plus s'embarrasser avec les VACUUM sur ces tables si vous
	utilisez quelque chose comme <application>pg_autovacuum</application>
        pour gérer le nettoyage de ces tables. Malheureusement, il est possible
	que <application>pg_autovacuum</application> ne nettoie pas assez
	fréquemment, vous pourrez donc préférer utiliser les VACUUM internes.
	Nettoyer la table &pglistener; <quote>trop souvent</quote> est moins
	risqué que de ne pas la nettoyer assez.
      </para>

      <para>
        Malheureusement, si vous avez de longues transactions, les VACUUM ne
	peuvent pas nettoyer les lignes mortes qui sont plus récentes que les
	anciennes transactions toujours en cours. Ceci conduira en particulier
	à une forte croissance de &pglistener; et ralentira la réplication.
      </para>
    </listitem>

    <listitem>
      <para>
        Le bogue <link linkend="dupkey">violation par clef dupliquée</link> a
	permis d'isoler a number of rather obscure
        &postgres; race conditions, so that in modern versions of &slony1; and
	&postgres;, there should be little to worry about.
      </para>
    </listitem>

    <listitem>
      <para>
        À partir de la version 1.2, la fonctionnalité <quote>log
	switching</quote> est arrivée&nbsp;;de temps en temps (by default, once per week,
        though you may induce it by calling the stored
        function <function>logswitch_start()</function>), elle tente
	d'interchanger les données entre &sllog1; et &sllog2; afin de réaliser
	un <command>TRUNCATE</command> sur les <quote>plus vieilles</quote>
	données.
      </para>

      <para>
        Cela signifie que, de manière régulière, ces tables sont complètement
	nettoyées ce qui évite qu'elles ne grossissent trop lors d'une charge
	importante et qu'elles deviennent impossibles à nettoyer.
      </para>
      
<para> In version 2.0, <command>DELETE</command> is no longer used to
clear out data in &sllog1; and &sllog2;; instead, the log switch logic
is induced frequently, every time the cleanup loop does not find a
switch in progress, and these tables are purely cleared out
via <command>TRUNCATE</command>.  This eliminates the need to vacuum
these tables. </para>

    </listitem>
  </itemizedlist>
</para>

<sect2 id="maintenance-autovac"> <title> Interaction with &postgres;
autovacuum </title>

<indexterm><primary>autovacuum interaction</primary></indexterm>

<para> Recent versions of &postgres; support an
<quote>autovacuum</quote> process which notices when tables are
modified, thereby creating dead tuples, and vacuums those tables,
<quote>on demand.</quote> It has been observed that this can interact
somewhat negatively with &slony1;'s own vacuuming policies on its own
tables. </para>

<para> &slony1; requests vacuums on its tables immediately after
completing transactions that are expected to clean out old data, which
may be expected to be the ideal time to do so.  It appears as though
autovacuum may notice the changes a bit earlier, and attempts
vacuuming when transactions are not complete, rendering the work
pretty useless.  It seems preferable to configure autovacuum to avoid
vacuum &slony1;-managed configuration tables. </para>

<para> The following query (change the cluster name to match your
local configuration) will identify the tables that autovacuum should
be configured not to process: </para>

<programlisting>
mycluster=# select oid, relname from pg_class where relnamespace = (select oid from pg_namespace where nspname = '_' || 'MyCluster') and relhasindex;
  oid  |   relname    
-------+--------------
 17946 | sl_nodelock
 17963 | sl_setsync
 17994 | sl_trigger
 17980 | sl_table
 18003 | sl_sequence
 17937 | sl_node
 18034 | sl_listen
 18017 | sl_path
 18048 | sl_subscribe
 17951 | sl_set
 18062 | sl_event
 18069 | sl_confirm
 18074 | sl_seqlog
 18078 | sl_log_1
 18085 | sl_log_2
(15 rows)
</programlisting>

<para> The following query will populate
<envar>pg_catalog.pg_autovacuum</envar> with suitable configuration
information: <command> INSERT INTO pg_catalog.pg_autovacuum (vacrelid, enabled, vac_base_thresh, vac_scale_factor, anl_base_thresh, anl_scale_factor, vac_cost_delay, vac_cost_limit, freeze_min_age, freeze_max_age) SELECT oid, 'f', -1, -1, -1, -1, -1, -1, -1, -1 FROM pg_catalog.pg_class WHERE relnamespace = (SELECT OID FROM pg_namespace WHERE nspname = '_' || 'MyCluster') AND relhasindex; </command>
</para>
</sect2>

<sect2><title>Chiens de garde&nbsp;: garder les Slons en vie</title>
<indexterm><primary>Chiens de garde pour garder en vie les démons slon</primary></indexterm>

<para>
  Il y a deux scripts <quote>chiens de garde</quote> disponibles pour surveiller
  la réplication et relancer les processus <application>slon</application>
  lorsqu'ils meurent pour telle ou telle raison, par exemple une
  <quote>coupure</quote> réseau qui provoque une perte de connectivité.
</para>

<para>
  Ils pourraient vous être utiles...
</para>

<para>
  La <quote>meilleure et nouvelle</quote> façon de gérer les processus <xref
  linkend="slon"/> se fait via une combinaison de  <xref linkend="mkslonconf"/>,
  qui crée un fichier de configuration pour chaque n&oelig;ud d'un cluster, et
  <xref linkend="launchclusters"/> qui utilise ces fichiers de configuration.
</para>

<para>
  Cette approche est préférable aux anciens systèmes de <quote>chiens de
  garde</quote> car vous pouvez <quote>pointer</quote> précisément, dans chaque
  fichier de configurationn, le paramètrage désiré pour chaque n&oelig;ud, sans
  avoir à vous préoccuper des options que le script chien de garde vous propose
  (ou pas). Ceci est particulièrement important si vous utilisez le <link
  linkend="logshipping">log shipping</link>, auquel cas oublier l'option
  <command>-a</command> peut ruiner le n&oelig;ud destinataire du log shipping
  et ruiner par là-même votre journée.
</para>

</sect2>

<sect2 id="gensync"><title>En parallèle aux chiens de garde&nbsp;:
generate_syncs.sh</title>

<indexterm><primary>generate SYNCs</primary></indexterm>
<para>
  Un nouveau script est apparu dans &slony1; 1.1, il s'agit de
  <application>generate_syncs.sh</application>, qui est utilise dans les
  situations suivantes.
</para>

<para>
  Supposons que vous avez un serveur non fiable sur lequel le démon
  <application>slon</application> ne fonctionne pas en continu, en rentrant de
  week-end vous vous trouverez peut-être la situation suivante&nbsp;:
</para>

<para>
  Le vendredi soir, quelque chose s'est <quote>cassé</quote> et le temps que la
  base de donnée redémarre, aucun des démons <application>slon</application>
  n'a survécu. Votre application en ligne a ensuite connu trois jours
  de charge transactionnelle relativement forte.
</para>

<para>
  Lorsque vous redémarrez <application>slon</application> le lundi, il n'y a
  pas eu de synchronisation sur le maître depuis vendredi, ce qui fait que le
  prochain <quote>ensemble de SYNC</quote> comprendra toutes les modifications
  entre vendredi et lundi. Aïe&nbsp;!</para>

<para>
  Si vous lancez <application>generate_syncs.sh</application> via une tache cron
  toute les 20 minutes, cela créera de force des événements
  <command>SYNC</command> sur l'origine, ce qui implique qu'entre vendredi et
  lundi, les nombreuses mises à jour seront découpées en plus de 100 ensembles
  de SYNC, qui pourront être appliqués de manière incrémentale, rendant la
  restauration moins déplaisante.
</para>

<para>
  Notez que si les <command>SYNC</command> <emphasis>sont</emphasis> exécutés
  régulièrement, ce scripts ne fera rien de particulier.
</para>

</sect2>

<sect2><title>Tester l'état de &slony1;</title>
<indexterm><primary>tester le statut du cluster</primary></indexterm>

<para>
  Dans le répertoire <filename>tools</filename>, vous trouverez les scripts
  &lteststate; nommés <filename>test_slony_state.pl</filename> et
  <filename>test_slony_state-dbi.pl</filename>. Le premier utilise l'interface
  Perl/DBI, l'autre utilise l'interface PostgreSQL.
</para>

<para>
  Les deux font essentiellement la même chose, c'est-à-dire se connecter à un
  n&oelig;ud &slony1; (celui de votre choix) et, à partir de là, détermine la
  liste des n&oelig;uds du cluster. Ensuite ils lancent une série de requêtes
  (en lecture seule, donc sans danger) afin de parcourir différentes tables à
  la recherche de différentes conditions susceptibles de revéler des problèmes,
  telles que&nbsp;:
</para>

<itemizedlist>
  <listitem>
    <para>
      Gonflement des tables comme pg_listener, sl_log_1, sl_log_2, sl_seqlog&nbsp;;
    </para>
  </listitem>
  
  <listitem>
    <para>
      Voies d'écoute&nbsp;;
    </para>
  </listitem>
  
  <listitem>
    <para>
      Analyse de la propagation des événements&nbsp;;
    </para>
  </listitem>
  
  <listitem>
    <para>
      Analyse de la propagation des confirmations.
    </para>

    <para>
      Si la communication est <emphasis>légèrement</emphasis> perturbée, la
      réplication peut fonctionner, mais les confirmations peuvent ne pas être
      retournées, ce qui empêche les n&oelig;uds de nettoyer les vieux
      événements et les anciennes données de réplication.
    </para>
  </listitem>
</itemizedlist>

<para>
  Lancer ce script une fois par heure ou une fois par jour peut vous aider à
  détecter les symptomes précurseurs de certains problèmes, avant même que
  cela conduise à une dégradation des performances.
</para>

</sect2>

<sect2><title>Scripts de test de la réplication</title>

<para>
  Dans le répertoire <filename>tools</filename>, on peut trouver quatre scripts
  qui peuvent être utilisés pour surveiller des instances &slony1;&nbsp;:

  <itemizedlist>
    <listitem>
      <para>
        <command>test_slony_replication</command> est un script Perl auquel
	vous pouvez passer les informations de connexion d'un n&oelig;ud
	&slony1;. Il teste alors la table <xref linkend="table.sl-path"/> et
	d'autres informations sur ce n&oelig;ud afin de déterminer la forme de
	l'ensemble de réplication choisi.
      </para>

      <para>
        Ensuite il injecte des requêtes de test dans la table nommée
	<envar>slony_test</envar> qui est définie comme ci-dessous, et qui doit
	être ajoutée à l'ensemble des tables répliquées&nbsp;:

        <programlisting>CREATE TABLE slony_test (
    description text,
    mod_date timestamp with time zone,
    "_Slony-I_testcluster_rowID" bigint DEFAULT nextval('"_testcluster".sl_rowid_seq'::text) NOT NULL
);</programlisting>
      </para>

      <para>
        La dernière colonne de la table est définie par &slony1; comme une clé
	primaire manquante...
      </para>

      <para>
        Ce script génère une ligne de sortie pour chaque n&oelig;ud &slony1;
	actif pour l'ensemble de réplication défini dans un fichier nommé
        <filename>cluster.fact.log</filename>.
      </para>

      <para>
        Il y a une option additionelle, <option>finalquery</option>, qui vous
	permet de passer une requête SQL spécifique à votre application pour
	déterminer l'état de votre application.
      </para>
    </listitem>

    <listitem>
      <para>
        <command>log.pm</command> est un module Perl module qui gère les logs
	des scripts Perl.
      </para>
    </listitem>

    <listitem>
      <para>
        <command>run_rep_tests.sh</command> est un script <quote>wrapper</quote>
        qui lance <command>test_slony_replication</command>.
      </para>

      <para>
        Si vous avez plusieurs clusters &slony1;, vous pouvez placer dans ce
	fichier la configuration pour se connecter à tous ces clusters.
      </para>
    </listitem>

    <listitem>
      <para>
        <command>nagios_slony_test</command> est un script qui a été construit
	pour interroger les fichiers logs afin de pouvoir lancer le test de
	réplication régulièrement (nous le laissons toutes les six minutes) et
	qu'un outil de supervision tel que <ulink
        url="http://www.nagios.org/"> <productname>Nagios</productname></ulink>
	puisse utiliser le script pour surveiller l'état indiqué dans ces logs.
      </para>

      <para>
        Il semble plus efficace qu'une tache <application>cron</application>
	lance les tests et que <productname>Nagios</productname> vérifie le
	résultat plutôt que de voir <productname>Nagios</productname> lancer
	directement les tests. Ces tests peuvent vérifier l'ensemble du cluster
	&slony1; d'un seul coup, plutot que de voir <productname>Nagios</productname>
        provoquer des mises à jour en permanence.
      </para>
    </listitem>
  </itemizedlist>
</para>

</sect2>

<sect2><title>Autres tests de réplication</title>

<indexterm><primary>testing replication</primary></indexterm>

<para>
  La méthodologie de la section précédente est conçu avec un vue pour minimiser
  le coût des requêtes de tests&nbsp;; sur un cluster très chargé, supportant
  des centaines d'utilisateurs, le coût associé aux quelques requêtes de test
  n'est pas un point important et le temps de configuration des tables et des
  injecteurs de données est très élevé.
</para>

<para>
  Trois autres méthodes sont apparus pour analyser l'état de la
  réplication&nbsp;:
</para>

<itemizedlist>
  <listitem>
    <para>
      Pour un test orienté sur l'application, il est utile de créer une vue
      sur une table fréquemment mise à jour pour remonter des informations
      spécifiques à l'application.
    </para>

    <para>
      Par exemple, on peut chercher soit des statistiques sur les objets
      applicatifs les plus récents, soit les transactions de l'application.
      Par exemple&nbsp;:
    </para>

    <para>
      <command>CREATE VIEW replication_test AS
SELECT now() - txn_time AS age, object_name
FROM transaction_table
ORDER BY txn_time DESC
LIMIT 1;</command>
    </para>

    <para>
      <command>CREATE VIEW replication_test AS
SELECT now() - created_on AS age, object_name
FROM object_table
ORDER BY id DESC
LIMIT 1;</command>
    </para>

    <para>
      Il y a un inconvénient&nbsp;: cette approche nécessite que vous ayez une
      activité constante sur le système impliquant la création de nouvelles
      transactions de manière régulière. Si quelque chose ne fonctionne pas
      dans votre application, vous obtiendrez des fausses alertes en provenance
      de la réplication alors même que la réplication fonctionne correctement.
    </para>
  </listitem>

  <listitem>
    <para>
      La vue &slony1; nommée <envar>sl_status</envar> fournit des informations
      sur la synchronisation des différents n&oelig;uds. Son contenu n'est
      intéressant que sur les n&oelig;uds origine car les événements générés
      sur les autres n&oelig;uds peuvent généralement être ignorés.
    </para>
  </listitem>

  <listitem>
    <para>
      Voir également la discussion sur <xref linkend="slonymrtg"/>.
    </para>
  </listitem>
</itemizedlist>

</sect2>

<sect2><title>Journaux applicatifs</title>
<indexterm><primary>journaux applicatifs</primary></indexterm>

<para>
  Les démons <xref linkend="slon"/> génère des journaux applicatifs plus ou
  moins verbeux, selon le niveau de débogage activé. Dans ce cas, vous
  pouvez&nbsp;:

  <itemizedlist>
    <listitem>
      <para>
        Utiliser un programme de rotation des journaux applicatifs comme
        <application>rotatelogs</application> d'<productname>Apache</productname>
        pour avoir une séquence de journaux applicatifs et éviter d'avoir des
	journaux trop gros&nbsp;;
      </para>
    </listitem>

    <listitem>
      <para>
        Purgez régulièrement les vieux journaux applicatifs.
      </para>
    </listitem>
  </itemizedlist>
</para>

</sect2>

<sect2><title>mkservice </title>
<indexterm><primary>mkservice for BSD </primary></indexterm>

<sect3><title>slon-mkservice.sh</title>

<para> Create a slon service directory for use with svscan from
daemontools.  This uses multilog in a pretty basic way, which seems to
be standard for daemontools / multilog setups. If you want clever
logging, see logrep below. Currently this script has very limited
error handling capabilities.</para>

<para> For non-interactive use, set the following environment
variables.  <envar>BASEDIR</envar> <envar>SYSUSR</envar>
<envar>PASSFILE</envar> <envar>DBUSER</envar> <envar>HOST</envar>
<envar>PORT</envar> <envar>DATABASE</envar> <envar>CLUSTER</envar>
<envar>SLON_BINARY</envar> If any of the above are not set, the script
asks for configuration information interactively.</para>

<itemizedlist>
<listitem><para>
<envar>BASEDIR</envar> where you want the service directory structure for the slon
to be created. This should <emphasis>not</emphasis> be the <filename>/var/service</filename> directory.</para></listitem>
<listitem><para>
<envar>SYSUSR</envar> the unix user under which the slon (and multilog) process should run.</para></listitem>
<listitem><para>
<envar>PASSFILE</envar> location of the <filename>.pgpass</filename> file to be used. (default <filename>~sysusr/.pgpass</filename>)</para></listitem>
<listitem><para>
<envar>DBUSER</envar> the postgres user the slon should connect as (default slony)</para></listitem>
<listitem><para>
<envar>HOST</envar> what database server to connect to (default localhost)</para></listitem>
<listitem><para>
<envar>PORT</envar> what port to connect to (default 5432)</para></listitem>
<listitem><para>
<envar>DATABASE</envar> which database to connect to (default dbuser)</para></listitem>
<listitem><para>
<envar>CLUSTER</envar> the name of your Slony1 cluster? (default database)</para></listitem>
<listitem><para>
<envar>SLON_BINARY</envar> the full path name of the slon binary (default <command>which slon</command>)</para></listitem>
</itemizedlist>
</sect3>

<sect3><title>logrep-mkservice.sh</title>

<para>This uses <command>tail -F</command> to pull data from log files allowing
you to use multilog filters (by setting the CRITERIA) to create
special purpose log files. The goal is to provide a way to monitor log
files in near realtime for <quote>interesting</quote> data without either
hacking up the initial log file or wasting CPU/IO by re-scanning the
same log repeatedly.
</para>

<para>For non-interactive use, set the following environment
variables.  <envar>BASEDIR</envar> <envar>SYSUSR</envar> <envar>SOURCE</envar>
<envar>EXTENSION</envar> <envar>CRITERIA</envar> If any of the above are not set,
the script asks for configuration information interactively.
</para>

<itemizedlist>
<listitem><para>
<envar>BASEDIR</envar> where you want the service directory structure for the logrep
to be created. This should <emphasis>not</emphasis> be the <filename>/var/service</filename> directory.</para></listitem>
<listitem><para><envar>SYSUSR</envar> unix user under which the service should run.</para></listitem>
<listitem><para><envar>SOURCE</envar> name of the service with the log you want to follow.</para></listitem>
<listitem><para><envar>EXTENSION</envar> a tag to differentiate this logrep from others using the same source.</para></listitem>
<listitem><para><envar>CRITERIA</envar> the multilog filter you want to use.</para></listitem>
</itemizedlist>

<para> A trivial example of this would be to provide a log file of all slon
ERROR messages which could be used to trigger a nagios alarm.
<command>EXTENSION='ERRORS'</command>
<command>CRITERIA="'-*' '+* * ERROR*'"</command>
(Reset the monitor by rotating the log using <command>svc -a $svc_dir</command>)
</para>

<para> A more interesting application is a subscription progress log.
<command>EXTENSION='COPY'</command>
<command>CRITERIA="'-*' '+* * ERROR*' '+* * WARN*' '+* * CONFIG enableSubscription*' '+* * DEBUG2 remoteWorkerThread_* prepare to copy table*' '+* * DEBUG2 remoteWorkerThread_* all tables for set * found on subscriber*' '+* * DEBUG2 remoteWorkerThread_* copy*' '+* * DEBUG2 remoteWorkerThread_* Begin COPY of table*' '+* * DEBUG2 remoteWorkerThread_* * bytes copied for table*' '+* * DEBUG2 remoteWorkerThread_* * seconds to*' '+* * DEBUG2 remoteWorkerThread_* set last_value of sequence*' '+* * DEBUG2 remoteWorkerThread_* copy_set*'"</command>
</para>

<para>If you have a subscription log then it's easy to determine if a given
slon is in the process of handling copies or other subscription activity.
If the log isn't empty, and doesn't end with a 
<command>"CONFIG enableSubscription: sub_set:1"</command>
(or whatever set number you've subscribed) then the slon is currently in
the middle of initial copies.</para>

<para> If you happen to be monitoring the mtime of your primary slony logs to 
determine if your slon has gone brain-dead, checking this is a good way
to avoid mistakenly clobbering it in the middle of a subscribe. As a bonus,
recall that since the the slons are running under svscan, you only need to
kill it (via the svc interface) and let svscan start it up again laster.
I've also found the COPY logs handy for following subscribe activity 
interactively.</para>
</sect3>

</sect2>

</sect1>
