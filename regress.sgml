<!-- $Header: /var/lib/cvs/pgsql-fr/sgml/regress.sgml,v 1.8 2005/09/15 07:03:22 guillaume Exp $ -->

 <chapter id="regress">
  <title id="regress-title">Tests de régression</title>

  <indexterm zone="regress">
   <primary>tests de régression</primary>
  </indexterm>

  <indexterm zone="regress">
   <primary>test</primary>
  </indexterm>

  <para>
   Les tests de régression composent un ensemble exhaustif de tests pour
   l'implémentation SQL dans <productname>PostgreSQL</productname>. Ils testent
   les opérations SQL standards ainsi que les fonctionnalités étendues de
   <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="regress-run">
   <title>Lancer les tests</title>

  <para>
   Les tests de régression peuvent être lancés sur un serveur déjà installé et
   fonctionnel ou en utilisant une installation temporaire à l'intérieur du
   répertoire de construction. De plus, ils peuvent être lancés en mode
   <quote>parallèle</quote> ou en mode <quote>séquentiel</quote>. Le mode
   séquentiel lance les scripts de test en série, tandis que le mode
   parallèle lance plusieurs processus serveurs pour parallèliser l'exécution des
   groupes de tests. Les tests parallèles permettent de s'assurer du
   bon fonctionnement des communications interprocessus et du verrouillage.
   Pour des raisons historiques, les tests séquentiels sont habituellement lancés
   sur une installation existante et la méthode parallèle préférentiellement
   sur une installation temporaire, mais il n'y a aucune raison technique à cela.
  </para>

  <para>
   Pour lancer les tests de régression après la construction mais avant l'installation,
   il suffit de saisir
<screen>
gmake check
</screen>
   dans le répertoire de premier niveau (on peut aussi se placer dans le répertoire
   <filename>src/test/regress</filename> et y lancer la commande). En premier lieu
   seront construits différents fichiers auxiliaires, tels des exemples de
   fonctions de déclencheurs utilisateur, puis le script de pilotage des tests
   sera exécuté. Au final, la sortie devrait ressembler à quelque chose comme
<screen>
<computeroutput>
======================
 All 98 tests passed.
======================
</computeroutput>
</screen>
   ou une note indiquant l'échec des tests.  Voir la <xref
   linkend="regress-evaluation"> avant de supposer qu'un <quote>échec</quote>
   représente un problème sérieux.
  </para>

   <para>
    Comme cette méthode de tests fonctionne sur un serveur temporaire, elle 
    ne fonctionnera pas en tant qu'utilisateur root (car le serveur refusera de
    se lancer en tant qu'utilisateur root) Si vous avez lancé la construction en
    tant que root, vous n'avez pas besoin de tout recommencer. À la place,
    rendez le répertoire des tests de régression modifiable par un autre
    utilisateur, devenez cet utilisateur et relancez les tests. Par exemple
<screen>
<prompt>root# </prompt><userinput>chmod -R a+w src/test/regress</userinput>
<prompt>root# </prompt><userinput>chmod -R a+w contrib/spi</userinput>
<prompt>root# </prompt><userinput>su - joeuser</userinput>
<prompt>joeuser$ </prompt><userinput>cd <replaceable>répertoire
construction haut niveau</></userinput>
<prompt>joeuser$ </prompt><userinput>gmake check</userinput>
</screen>
    (le seul <quote>risque en terme de sécurité</quote> est que les
    autres utilisateurs pourraient modifier les résultats des tests de
    régression dans votre dos. Utilisez le bon sens pour gérer les droits des
    utilisateurs.)
   </para>

   <para>
    Autrement, lancez les tests après l'installation.
   </para>

   <para>
    Si vous avez configuré <productname>PostgreSQL</productname> pour qu'il
    s'installe dans un emplacement où existe déjà une ancienne installation de
    <productname>PostgreSQL</productname> et que vous lancez <literal>gmake
    check</> avant d'installer la nouvelle version, vous pourriez trouver que
    les tests échouent parce que les nouveaux programmes essaient d'utiliser les
    bibliothèques partagées déjà installées (les symptômes typiques sont des
    plaintes concernant des symboles non définis). Si vous souhaitez lancer les
    tests avant d'écraser l'ancienne installation, vous devrez construire avec
    <literal>configure --disable-rpath</>. Néanmoins, il n'est pas recommandé
    d'utiliser cette option pour l'installation finale.
   </para>

   <para>
    Les tests de régression en parallèle lancent quelques processus avec
    votre utilisateur. Actuellement, le nombre maximum est de vingt scripts de
    tests en parallèle, ce qui signifie 60 processus&nbsp;: il existe un
    processus serveur, un <application>psql</> et habituellement un processus
    parent pour le <application>psql</> de chaque script de tests. Si votre
    système force une limite par utilisateur sur le nombre de processus,
    assurez-vous que cette limite est d'au moins 65, sinon vous pourriez obtenir
    des échecs hasardeux dans les tests en parallèle. Si vous ne pouvez pas
    augmenter cette limite, vous pouvez diminuer le degré de parallélisme en
    initialisant le paramètre <literal>MAX_CONNECTIONS</>. Par
exemple,
<screen>
gmake MAX_CONNECTIONS=10 check
</screen>
    ne lance pas plus de dix tests en même temps.
   </para>

   <para>
    Sur certains systèmes, le shell par défaut compatible Bourne
    (<filename>/bin/sh</filename>) a du mal à gérer autant de processus fils
    en parallèle. Cela pourrait causer des blocages ou des échecs dans les
    tests en parallèle. Dans de tels cas, spécifiez un shell compatible Bourne
    différent sur la liste de commande, par exemple&nbsp;:
<screen>
gmake SHELL=/bin/ksh check
</screen>
    Si aucun shell ne le permet, vous pouvez contourner le problème en diminuant
    le nombre de connexions comme indiqué ci-dessus.
   </para>

  <para>
   Pour lancer les tests après l'installation<![%standalone-ignore;[ (voir le <xref
   linkend="installation">)]]>, initialisez un espace de données et lancez le
   serveur <![%standalone-ignore;[comme expliqué dans le <xref
   linkend="runtime">,]]> puis lancez
<screen>
gmake installcheck
</screen>
ou pour un test parallèle
<screen>
gmake installcheck-parallel
</screen>
   Les tests s'attendront à contacter le serveur sur l'hôte local et avec le
   numéro de port par défaut, sauf en cas d'indication contraire avec les
   variables d'environnement <envar>PGHOST</envar> et <envar>PGPORT</envar>.
  </para>

  <para>
   La distribution source contient aussi les tests de régression pour les
   langages de procédures et pour certains des modules de <filename>contrib</>.
   Actuellement, ces tests peuvent seulement être utilisés avec un serveur
   déjà installé. Pour exécuter les tests pour tous les langages de procédure
   qui ont été construits et installés, placez-vous dans le sous-répertoire
   <filename>src/pl</> du répertoire de construction et lancez
<screen>
gmake installcheck
</screen>
   Vous pouvez aussi le faire dans tous les sous-répertoires de
   <filename>src/pl</> pour lancer les tests pour un seul langage de procédure.
   Pour lancer les tests sur tous les modules <filename>contrib</> qui les ont,
   placez-vous dans le répertoire <filename>contrib</> du répertoire de
   construction et exécutez
<screen>
gmake installcheck
</screen>
   Les modules <filename>contrib</> doivent avoir été construits et installés
   tout d'abord. Vous pouvez aussi le faire dans un sous-répertoire de
   <filename>contrib</> pour exécuter les tests pour un seul module.
  </para>
  </sect1>

  <sect1 id="regress-evaluation">
   <title>Évaluation des tests</title> 

   <para>
    Quelques installations de <productname>PostgreSQL</productname>
    proprement installées et totalement fonctionnelles peuvent
    <quote>échouer</quote> sur certains des tests de régression à cause de
    certains points spécifiques à la plateforme comme une représentation de
    nombres à virgules flottantes ou <quote>message wording</quote>. Les tests
    sont actuellement évalués en utilisant une simple comparaison
    <command>diff</command> avec les sorties générées sur un système de
    référence, donc les résultats sont sensibles aux petites différences
    système. Quand un test est rapporté comme <quote>échoué</quote>, toujours
    examiner les différences entre les résultats attendus et ceux obtenus&nbsp;;
    vous pourriez très bien trouver que les différences ne sont pas significatives.
    Néanmoins, nous nous battons toujours pour maintenir des fichiers de
    références précis et à jour pour toutes les plateformes supportés de façon à
    ce que tous les tests puissent réussir.
   </para>

   <para>
    Les sorties actuelles des tests de régression sont dans les fichiers du
    répertoire <filename>src/test/regress/results</filename>. Le script de test
    utilise <command>diff</command> pour comparer chaque fichier de sortie avec
    les sorties de référence stockées dans le répertoire
    <filename>src/test/regress/expected</filename>. Toutes les différences sont
    conservées pour que vous puissiez les regarder dans
    <filename>src/test/regress/regression.diffs</filename> (ou vous pouvez
    lancer <command>diff</command> vous-même, si vous préférez).
   </para>

   <para>
    Si, pour certaines raisons, une plateforme particulière génère un 
    <quote>échec</> pour un test donné mais qu'une revue de la sortie vous
    convaint que le résultat est valide, vous pouvez ajouter un nouveau fichier
    de comparaison pour annuler le rapport d'échec pour les prochains lancements
    du test. Voir la <xref linkend="regress-variant"> pour les détails.
   </para>

   <sect2>
    <title>Différences dans les messages d'erreurs</title>

    <para>
     Certains des tests de régression impliquent des valeurs en
     entrée intentionnellement invalides. Les messages d'erreur peuvent
     provenir soit du code de <productname>PostgreSQL</productname> soit des
     routines système de la plateforme hôte. Dans ce dernier cas, les messages
     pourraient varier entre plateformes mais devraient toujours refléter des
     informations similaires. Ces différences dans les messages résulteront en
     un échec du test de régression qui pourrait être validé après vérification.
    </para>
   </sect2>

   <sect2>
    <title>Différences au niveau des locales</title>

    <para>
     Si vous lancez des tests sur un serveur déjà installé mais initialisé avec
     une locale autre que C, alors il pourrait y avoir des différences dans les
     ordres de tris. La suite de tests de régression est initialisée pour gérer
     ce problème en fournissant des fichiers de résultats alternatifs qui
     gèrent ensemble un grand nombre de locales.
    </para>
   </sect2>

   <sect2>
    <title>Différences au niveau des dates/heures</title>

    <para>
     La plupart des résultats date/heure sont dépendants de l'environnement
     de zone horaire. Les fichiers de référence sont générés pour la zone
     horaire <literal>PST8PDT</literal> (Berkeley, Californie), et il y aura
     des échecs apparents si les tests ne sont pas lancés avec ce paramétrage de
     fuseau horaire. Le pilote des tests de régression initialise la variable
     d'environnement <envar>PGTZ</envar> à <literal>PST8PDT</literal> ce qui
     nous assure normalement de bons résultats.
    </para>
   </sect2>
    
   <sect2>
    <title>Différences sur les nombres à virgules flottantes</title>
      
    <para>
     Quelques tests impliquent des calculs sur des nombres flottants à 64 bits
     (<type>double precision</type>) à partir de colonnes de tables. Des
     différences dans les résultats appliquant des fonctions mathématiques à des
     colonnes <type>double precision</type> ont été observées. Les tests de
     <literal>float8</> et <literal>geometry</> sont particulièrement sensibles
     aux différences entre plateformes, voire aux différentes options
     d'optimisation des compilateurs. L'&oelig;il humain
     est nécessaire pour déterminer la véritable signification de ces différences,
     habituellement situées après la dixième décimale.
    </para>

    <para>
     Certains systèmes affichent moins zéro comme <literal>-0</> alors que
     d'autres affichent seulement <literal>0</>.
    </para>

    <para>
     Certains systèmes signalent des erreurs avec <function>pow()</function> et
     <function>exp()</function> différemment suivant le mécanisme attendu du
     code de <productname>PostgreSQL</productname>.
    </para>
   </sect2>

   <sect2>
    <title>Différences dans l'ordre des lignes</title>
      
    <para>
     Vous pourriez voir des différences dans lesquelles les mêmes lignes sont
     affichées dans un ordre différent de celui qui apparaît dans le fichier de
     référence. Dans la plupart des cas, ce n'est pas à strictement parlé un
     bogue. La plupart des scripts de tests de régression ne sont pas assez
     stricts pour utiliser un <literal>ORDER BY</> sur chaque
     <literal>SELECT</> et, du coup, l'ordre des lignes pourrait ne pas être
     correctement défini suivant la spécification SQL. En pratique, comme nous
     sommes avec les mêmes requêtes sur les mêmes données avec le même logiciel,
     nous obtenons habituellement le même résultat sur toutes les plateformes et
     le manque d'<literal>ORDER BY</> n'est pas un problème. Quelques requêtes
     affichent des différences d'ordre entre plateformes. Lors de tests avec un
     serveur déjà installé, les différences dans l'ordre des lignes peuvent
     aussi être causées par un paramètrage des locales à une valeur différente
     de C ou par un paramètrage personnalisé, comme des valeurs personnalisées
     de <varname>work_mem</> ou du coût du planificateur.
    </para>

    <para>
     Du coup, si vous voyez une différence dans l'ordre, vous n'avez pas à vous
     inquiéter sauf si la requête possède un <literal>ORDER BY</> que votre
     résultat ne respecte pas. Mais rapportez tout de même ce problème que nous
     ajoutions un <literal>ORDER BY</> à cette requête pour éliminer les faux
     <quote>échecs</quote> dans les versions suivantes.
    </para>

    <para>
     Vous pourriez vous demander pourquoi nous n'ordonnons pas toutes les
     requêtes des tests de régression explicitement pour supprimer ce problème
     une fois pour toutes. La raison est que cela rendrait les tests de
     régression moins utiles car ils tendraient à exercer des types de plans de
     requêtes produisant des résultats ordonnés à l'exclusion de celles qui ne
     le font pas.
    </para>
   </sect2>

   <sect2>
    <title>Profondeur insuffisante de la pile</title>

    <para>
     Si les tests d'<literal>erreurs</literal> se terminent avec un arrêt
     brutal du serveur pendant la commande <literal>select
     infinite_recurse()</>, cela signifie que la limite de la plateforme pour
     la taille de pile du processus est plus petite que le paramètre
     <xref linkend="guc-max-stack-depth"> ne l'indique. Ceci est corrigeable
     en exécutant le postmaster avec une limite pour la taille de pile plus
     importante (4&nbsp;Mo est recommandé avec la valeur par défaut de
     <varname>max_stack_depth</>). Si vous n'êtes pas capables de le faire, une
     alternative est de réduire la valeur de <varname>max_stack_depth</>.
    </para>
   </sect2>

   <sect2>
    <title>Test <quote>random</quote></title>

    <para>
     Le script de tests <literal>random</literal> a pour but de produire
     des résultats aléatoires. Dans de rares cas, ceci fait échouer random
     aux tests de régression. Saisir
<programlisting>
diff results/random.out expected/random.out
</programlisting>
ne devrait produire au plus que quelques lignes différentes. Cela est normal
     et ne devient préoccupant que si les tests random échouent en permanence
     lors de tests répétés
    </para>
   </sect2>
  </sect1>

<!-- We might want to move the following section into the developer's guide. -->
  <sect1 id="regress-variant">
   <title>Fichiers de comparaison de variants</title>

   <para>
    Comme certains de ces tests produisent de façon inhérente des résultats
    dépendants de l'environnement, nous avons fourni des moyens de spécifier
    des fichiers résultats alternatifs <quote>attendus</>. Chaque test de
    régression peut voir plusieurs fichiers de comparaison affichant les
    résultats possibles sur différentes plateformes. Il existe deux mécanismes
    indépendants pour déterminer quel fichier de comparaison est utilisé pour
    chaque test.
   </para>

   <para>
    Le premier mécanisme permet de sélectionner les fichiers de comparaison
    suivant des plateformes spécifiques. Le fichier de correspondance
    <filename>src/test/regress/resultmap</filename> définit le fichier de
    comparaison à utiliser pour chaque plateforme. Pour éliminer les tests
    <quote>échoués</quote> par erreur pour une plateforme particulière, vous
    choisissez ou vous créez un fichier variant de résultat, puis vous ajoutez
    une ligne au fichier <filename>resultmap</filename>.
   </para>

   <para>
    Chaque ligne du fichier de correspondance est de la forme
<synopsis>
nomtest/modeleplateform=fichiercomparaison
</synopsis>
    Le nom de tests est juste le nom du module de tests de régression
    particulier. Le modèle de plateforme est un modèle dans le style des outils
    Unix <command>expr</> (c'est-à-dire une expression rationnelle avec une
    ancre implicite <literal>^</literal> au début). Il est testé avec le nom de
    plateforme affiche par <command>config.guess</command> suivi par
    <literal>:gcc</literal> ou <literal>:cc</literal>, suivant que vous utilisez
    un compilateur GNU ou le compilateur de base de votre système (sur les
    systèmes où il y a une différence). Le nom du fichier de comparaison est le
    nom de base du fichier de comparaison substitué.
   </para>

   <para>
    Par exemple&nbsp;: certains systèmes interprètent les très petites valeurs
    en virgule flottante comme zéro, plutôt que de rapporter une erreur. Ceci
    fait quelques petites différences dans le test de régression
    <filename>float8</>. Du coup, nous fournissons un fichier de comparaison
    variable, <filename>float8-small-is-zero.out</filename>, qui inclut les
    résultats attendus sur ces systèmes. Pour faire taire les messages
    d'<quote>échec</quote> erronés sur les plateformes
    <systemitem>OpenBSD</systemitem>, <filename>resultmap</filename> inclut
<programlisting>
float8/i.86-.*-openbsd=float8-small-is-zero
</programlisting>
    qui se déclenche sur toute machine où la sortie de
    <command>config.guess</command> correspond à
    <literal>i.86-.*-openbsd</literal>. D'autres lignes dans
    <filename>resultmap</> sélectionnent le fichier de comparaison variable pour
    les autres plateformes si c'est approprié.
   </para>
   
   <para>
    Le second mécanisme de sélection des fichiers de comapraison variants est
    bien plus automatique&nbsp;: il utilise simplement la <quote>meilleure
    correspondance</> parmi les différents fichiers de comparaison fournis.
    Le script pilote des tests de régression considère le fichier de comparaison
    standard pour un test, <literal><replaceable>nomtest</>.out</>, et les
    fichiers variants nommés 
    <literal><replaceable>nomtest</>_<replaceable>chiffre</>.out</>
    (où <replaceable>chiffre</> est un seul chiffre compris entre
    <literal>0</> et <literal>9</>). Si un tel fichier établit une
    correspondance exacte, le test est considéré réussi&nbsp;; sinon, celui qui
    génère la plus petite différence est utilisé pour créer le rapport d'échec.
    (Si <filename>resultmap</filename> inclut une entrée pour le test
    particulier, alors le <replaceable>nomtest</> de base est le nom de
    substitut donné dans <filename>resultmap</filename>.)
   </para>

   <para>
    Par exemple, pour le test <literal>char</literal>, le fichier de comparaison
    <filename>char.out</filename> contient des résultats qui sont attendus dans
    les locales <literal>C</> et <literal>POSIX</>, alors que le fichier
    <filename>char_1.out</filename> contient des résultats triés comme ils
    apparaissent dans plusieurs autres locales.
   </para>

   <para>
    Le mécanisme de meilleure correspondance a été conçu pour se débrouiller
    avec les résultats dépendant de la locale mais il peut être utilisé dans
    toute situation où les résultats des tests ne peuvent pas être prédits
    facilement à partir de la plateforme seule. Une limitation de ce mécanisme
    est que le pilote test ne peut dire quelle variante est en fait
    <quote>correcte</> dans l'environnement en cours&nbsp;; il récupèrera la
    variante qui semble le mieux fonctionner. Du coup, il est plus sûr
    d'utiliser ce mécanisme seulement pour les résultats variants que vous
    voulez considérer comme identiquement valides dans tous les contextes.
   </para>
    
  </sect1>
  
</chapter>

<!-- Keep this comment at the end of the file
Local variables:
mode:sgml
sgml-omittag:nil
sgml-shorttag:t
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:1
sgml-indent-data:t
sgml-parent-document:nil
sgml-default-dtd-file:"./reference.ced"
sgml-exposed-tags:nil
sgml-local-catalogs:("/usr/lib/sgml/catalog")
sgml-local-ecat-files:nil
End:
-->